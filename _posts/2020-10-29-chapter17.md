---
title: ุงูุชุตููู
show_title: true
chapter_number: 17
chapter_text: ุงููุตู ุงูุณุงุจุน ุนุดุฑ
chapter_lessons: [[0, 'ููุฏูุฉ'], [1, 'ุงูุงูุญุฏุงุฑ ูู ุงูุงุญุชูุงูุงุช'], [2, 'ุงููููุฐุฌ ุงูููุฌุณุชู'], [3, 'ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูููููุฐุฌ ุงูููุฌุณุชู'], [4, 'ุงุณุชุฎุฏุงู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู'], [5, 'ุชูุฑูุจ ุงูุชูุฒูุน ุงูุงุญุชูุงูู ุงูุชุฌุฑูุจู'], [6, 'ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู'], [7, 'ุชูููู ุงููููุฐุฌ ุงูููุฌุณุชู'], [8, 'ุงูุชุตููู ูุชุนุฏุฏ ุงูุงุญุชูุงูุงุช']]
chapter_sublessons: [
    [],
    ['ูุดุงูู ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูู ุงูุงุญุชูุงูุงุช'],
    ['ุงูุงุนุฏุงุฏ ุงูุญููููู ุฅูู ุงุญุชูุงูุงุช', 'ุงูุฏุงูู ุงูููุฌุณุชูู', 'ุชุนุฑูู ุงููููุฐุฌ ุงูููุฌุณุชู', 'ููุฎุต ุงููููุฐุฌ ุงูููุฌุณุชู'],
    ['ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู', 'ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ', 'ููุฎุต ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ'],
    ['ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนูู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู', 'ุชูููู ุงููุตูู', 'ูููุฐุฌ ููุฌุณุชู ูุชุนุฏุฏ ุงููุชุบูุฑุงุช', 'ููุฎุต ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู'],
    ['ุชุนุฑูู ูุชูุณุท ุชุจุงุนุฏ KL', 'ุงุณุชูุชุงุฌ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู ูู ุชุจุงุนุฏ KL', 'ุชุจุฑูุฑ ุงุญุตุงุฆู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู', 'ููุฎุต ุชุจุฑูุฑ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู'],
    ['ุงููุฒูู ุงูุฅุดุชูุงูู ุจุฏูุนุงุช', 'ุงููุฒูู ุงูุฅุดุชูุงูู ุงูุนุดูุงุฆู', 'ุงููุฒูู ุงูุฅุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉ', 'ุงูุชุทุจูู ูู ููุชุจุฉ Scikit-learn', 'ููุฎุต ุงูุชุฎุตูุต ูููููุฐุฌ ุงูููุฌุณุชู'],
    ['ุงูุญุณุงุณูุฉ', 'ุงูููุนูุฉ', 'ุญุฏ ูุตู ุงูุชุตููู', 'ููุญููุงุช ROC', 'AUC', 'ููุฎุต ุชูููู ุงููููุฐุฌ ุงูููุณุฌุชู'],
    ['ุชุทุจูู ุนููู: ุจูุงูุงุช Iris', 'ุงูุชุตููู ูุชุนุฏุฏ ุงููุชุงุฆุฌ', 'ููุฎุต ุงูุชุตููู ูุชุนุฏุฏ ุงูุงุญุชูุงูุงุช'],
    

]
layout: default
---

## ููุฏูุฉ

ุญุชู ุงูุขู ุฃููููุง ูุธุฑุฉ ุนูู ููุงุฐุฌ ููุฅูุญุฏุงุฑุ ุทุฑููุฉ ููููุงู ุจุชููุนุงุช ูุณุชูุฑู ูุจุงูุฃุฑูุงู ุจูุงุกูุง ุนูู ุงูุจูุงูุงุช. ุงูุขู ููุชูู ุฅูู **ุงูุชุตููู Classification**ุ ููู ุทุฑููุฉ ููููุงู ุจุชููุนุงุช ุชุตููููุฉ ุจูุงุกูุง ุนูู ุงูุจูุงูุงุช. ูุซูุงูุ ูููุงุช ุชููุนุงุช ุงูุทูุณ ููุชูู ุจุชููุน ูุง ุฅุฐุง ุณูููู ุบุฏุงู ููู ูุงุทุฑ ุฃู ุบูุฑ ุฐูู ุจูุงุกูุง ุนูู ุญุงู ุงูุทูุณ ุงูููู.

ูุนุงูุ ุงูุชุตููู ูุงูุฅูุญุฏุงุฑ ุชุนุชุจุฑ ูู ุงูููุงุฐุฌ ุงูุฃูููุฉ ูุงูุชู ููุชูุฌุฉ ููุง ูู *ุงูุชุนููู ุงูููุฌููู Supervised Learning*ุ ูุงูุฐู ููู ูุชุนูู ุงููููุฐุฌ ุนู ุทุฑูู ุชูุฑูุฑ ุงูุจูุงูุงุช ููุชุงุฆุฌูุง ุนููู.

ูููููุง ุฅุนุงุฏุฉ ุชุดููู ุงูุชุตููู ุนูู ุฃูู ููุน ูู ุฃููุงุน ุงูุฅูุญุฏุงุฑ. ุจุฏูุงู ูู ุฃู ูุจูู ูููุฐุฌ ููุชููุน ุฃุฑูุงูุ ููุดุฃ ูููุฐุฌ ููุชููุน ุฅุญุชูุงููุฉ ุฃู ูููุฉ ูู ุงูุจูุงูุงุช ุชูุชูู ูุตูู ูุง. ูุณูุญ ููุง ุฐูู ุจุฅุนุงุฏุฉ ุฅุณุชุฎุฏุงู ุชูููุงุช ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ูู ุงูุฅูุญุฏุงุฑ ุนูู ุงูุฅุญุชูุงูุงุช ุฃู ูุง ูุณูู **ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู Logistic Regression**. [๐][LogisticRegression]

## ุงูุงูุญุฏุงุฑ ูู ุงูุงุญุชูุงูุงุช

ูู ูุฑุฉ ุงูุณูุฉุ ุชุญุณุจ ููุงุท ุงููุจุงุฑูุงุช ุนูุฏูุง ูููู ุงููุงุนุจ ุจุฅุฏุฎุงู ุงููุฑู ูู ุงูุณูุฉ. ุฃุญุฏ ุงููุงุนุจููุ ููุจุฑูู ุฌููุณุ ูุนุฑู ุจุฃูู ุฃุญุฏ ุฃูุถู ูู ูุนุจู ูุฑุฉ ุงูุณูุฉ ุจุณุจุจ ูุฏุฑุงุชุฉ ูู ุชุณุฌูู ุงูููุงุท.

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter17/LeBron_James_(31944491583).jpg'>
</p>

ููุนุจ ููุจุฑูู ูู ุงูุฏูุฑู ุงูุฃูุฑููู ููุฑุฉ ุงูุณูุฉ ูููุญุชุฑููู (NBA). ูููุง ุจุฌูุน ุฌููุน ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ูู ุงููุจุงุฑูุงุช ุงูุฃูุตุงุฆูุฉ ูุนุงู 2017 ุจุฅุณุชุฎุฏุงู ูููุน [stats.nba.com](https://stats.nba.com/).

> ูุชุญููู ุงูุจูุงูุงุช lebron.csv [ุงุถุบุท ููุง]({{ site.baseurl }}/files/chapter17/lebron.csv).

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
sns.set()
sns.set_context('talk')
np.set_printoptions(threshold=20, precision=2, suppress=True)
pd.options.display.max_rows = 7
pd.options.display.max_columns = 8
pd.set_option('precision', 2)

lebron = pd.read_csv('lebron.csv')
lebron
```

**shot\_made**|**shot\_distance**|**shot\_type**|**action\_type**|**opponent**|**minute**|**game\_date**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
0|0|2PT Field Goal|Driving Layup Shot|IND|10|20170415|0
1|0|2PT Field Goal|Driving Layup Shot|IND|11|20170415|1
1|0|2PT Field Goal|Layup Shot|IND|14|20170415|2
...|...|...|...|...|...|...|...
1|1|2PT Field Goal|Driving Layup Shot|GSW|46|20170612|381
0|14|2PT Field Goal|Turnaround Fadeaway shot|GSW|47|20170612|382
1|2|2PT Field Goal|Driving Layup Shot|GSW|48|20170612|383

```ruby
384 rows ร 7 columns
```

ูู ุณุทุฑ ูู ูุฐู ุงูุจูุงูุงุช ูุญุชูู ุนูู ุงููุนูููุงุช ุงูุชุงููุฉ ุนู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ุฌููุณ:

- `game_date`: ุชุงุฑูุฎ ุงููุจุงุฑุงุฉ.
- `minute`: ุงูุฏูููุฉ ุงูุชู ุญุงูู ูููุง ุงูุชุณุฌูู (ูุฏุฉ ูู ูุจุงุฑุฉ ูู ูุฑุฉ ุงูุณูุฉ ุงูุฃูุฑูููุฉ 48 ุฏูููุฉ).
- `opponent`: ุฅุฎุชุตุงุฑ ูุฃุณู ุงููุฑูู ุงูููุงูุณ.
- `action_type`: ุงูุทุฑููุฉ ุงูุชู ุชูุช ูููุง ูุญุงููุฉ ุงูุชุณุฌูู.
- `shot_type`: ููุน ุงูุฑููุฉ (ุฅูุง ุฑููุฉ ููุทุชูู ุฃู ุซูุงุซ ููุงุท).
- `shot_distance`: ูุณุงูุฉ ููุจุฑูู ุนู ุงูุณูุฉ ุนูุฏูุง ูุงู ุจูุญุงููุฉ ุงูุชุณุฌูู.
- `shot_made`: ุชููู 0 ุนูุฏูุง ุชููู ูุญุงููุฉ ุงูุชุณุฌูู ูุงุดูุฉ ู 1 ุนูุฏูุง ุชููู ูุญุงููุฉ ุงูุชุณุฌูู ูุงุฌุญุฉ.

ูุฑูุฏ ุฃู ูุณุชุฎุฏู ูุฐู ุงูุจูุงูุงุช ูุฅุฌุฑุงุก ุงูุชููุนุงุช ุนู ุฅุญุชูุงููุฉ ุชุณุฌูู ููุจุฑูู ูููุฒูุฏ ูู ุงูููุงุท. ุชุนุชุจุฑ ูุฐู ูุดููุฉ *ุชุตููู Classification*ุ ูุชููุน ุตูููุ ูููุณ ุฑูู ููุง ููุนู ูู ุงูุฅูุญุฏุงุฑ>

ูููููุง ุฅุนุงุฏุฉ ุตูุงุบุฉ ูุดููุฉ ุงูุชุตููู ูุฐู ุฅูู ูุดููุฉ ุฅูุญุฏุงุฑ ูุชููุน ูููุง *ุงูุฅุญุชูุงููุฉ Probability* ุฅุฐุง ูุงูุช ุงููุฑุฉ ุณุชุฏุฎู ูู ุงูุณูุฉ ุฃู ูุง. ูุซูุงูุ ูุชููุน ุฃู ูุญุงููุงุช ููุจุฑูู ููุชุณุฌูู ุณุชุฎุทุฃ ุงูุณูุฉ ุนูุฏูุง ุชููู ุงููุญุงููุฉ ูู ูุณุงูุฉ ุจุนูุฏุฉ.

ูููู ุจุฑุณู ูุญุงููุงุช ุงูุชุณุฌููุ ูุธูุฑ ูููุง ุงููุณุงูุฉ ุนู ุงูุณูุฉ ูู ุงููุญูุฑ $ x $ ู ูุง ุฅุฐุง ุชู ุชุณุฌูู ุชูู ุงููุญุงููุฉ ุฃู ูุง ูู ุงููุญูุฑ $ y $.

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=jitter_df(lebron, 'shot_distance', 'shot_made'),
           fit_reg=False,
           scatter_kws={'alpha': 0.3})
plt.title('LeBron Shot Make vs. Shot Distance');
```

> ุฅุณุชุฎุฏู ุงููุงุชุจ ุงูุฏุงูุฉ `jutter_df` ูุชุญููู ุงูุจูุงูุงุช ุฅูู ููู ุนุดูุงุฆูุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ูููุฉ ุนุดูุงุฆูุฉ ููุงุ ูุนุฑููุง ูุงูุชุงูู:
> 
> ```python
> def jitter_df(df, x_col, y_col):
>    x_jittered = df[x_col] + np.random.normal(scale=0, size=len(df))
>    y_jittered = df[y_col] + np.random.normal(scale=0.05, size=len(df))
>    return df.assign(**{x_col: x_jittered, y_col: y_jittered})
> ```
>

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_prob_8_0.png'>
</p>

ูููู ุฃู ูุฑู ุฃู ููุจุฑูู ูุณุฌู ุฃูุซุฑ ุนูุฏูุง ูููู ุจุญูุงูู 5 ุฃูุฏุงู ุฃู ูู ุฅูู ุงูุณูุฉ. ุนูุฏ ุถุจุท ูููุฐุฌ ุจุณูุท ููุฅูุญุฏุงุฑ ุงูุฎุทู ูู ุงููุฑุจุนุงุช ุงูุตุบุฑู ุนูู ูุฐู ุงูุจูุงูุงุช ููุชุฌ ููุง ุงูุชููุนุงุช ุงูุชุงููุฉ:

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=jitter_df(lebron, 'shot_distance', 'shot_made'),
           ci=None,
           scatter_kws={'alpha': 0.4})
plt.title('Simple Linear Regression');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_prob_10_0.png'>
</p>

ูุณุชุฎุฏู ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ูุชููุน ููู ุฑูููุฉ. ูููู ุนูุฏูุง ูุฑูุฏ ุชุทุจููู ุนูู ุงูุชุตูููุ ูุฑูุฏ ุชุญููู ูุฐู ุงูููู ุงูุฑูููุฉ ุฅูู ุชุตููู: ุชุณุฌูู ุงููุฑุฉ ุฃู ูุง. ูููููุง ุชุทุจูู ุฐูู ุนู ุทุฑูู ุชุญุฏูุฏ ุฎุท ูููุทุนุ ุฃู **ุญุฏ ูุตู ุงูุชุตููู Classification Threshold**. ุฅุฐุง ุชููุน ุงูุฅูุญุฏุงุฑ ูููุฉ ุฃูุจุฑ ูู 0.5ุ ููุนูู ุฐูู ุฃู ุงูุชููุน ูู ุฃู ุงููุฑุฉ ุณุชุฏุฎู ุงูุณูุฉ. ุนูู ุนูุณ ุฐููุ ุฅุฐุง ุชููุน ุฃูู ูู 0.5 ูุฃู ุงููุฑุฉ ุณุชุฎุทุฃ ุงูุณูุฉ.

ุฑุณููุง ุญุฏ ุงููุตู ูู ุงูุฑุณู ุงูุจูุงูู ุจุงูููู ุงูุฃุฎุถุฑ ุงููุชูุทุน. ุจูุงุกูุง ุนูู ูุฐุง ุงูุญุฏ ุงููุงุตูุ ูุฃู ูููุฐุฌูุง ูุชููุน ุฃู ููุจุฑูู ุณูุฌู ุงููุฑุฉ ุฅุฐุง ูุงู ุนูู ุจุนุฏ 15 ูุฏู ุฃู ุฃูู ุนู ุงูุณูุฉ.

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=jitter_df(lebron, 'shot_distance', 'shot_made'),
           ci=None,
           scatter_kws={'alpha': 0.4})
plt.axhline(y=0.5, linestyle='--', c='g')
plt.title('Cutoff for Classification');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_prob_12_0.png'>
</p>

ูู ุงูุฎุทูุงุช ุงูุณุงุจูุฉุ ุญุงูููุง ุชุทุจูู ุงูุฅูุญุฏุงุฑ ูุชููุน ุฅุญุชูุงููุฉ ุฃู ูุฑุฉ ุณุชุตูุจ ุงููุฏู. ุฅุฐุง ูุงู ุฅูุญุฏุงุฑูุง ููุชุฌ ุฅุญุชูุงููุฉุ ูุฅู ุชุญุฏูุฏ ุงูุญุฏ ุงููุงุตู ุนูู 0.5 ูุนูู ุฃููุง ูููุน ุฃู ุงููุฑุฉ ุณุชุตูุจ ุงููุฏู ุนูุฏูุง ูุชููุน ุงููููุฐุฌ ูููุฉ ุฃุนูู ูู ุฐูู. ุณูุนูุฏ ูููุถูุน ุญุฏ ูุตู ุงูุชุตููู ูู ุฌุฒุก ุขุฎุฑ ูู ูุฐุง ุงููุตู.

### ูุดุงูู ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูู ุงูุงุญุชูุงูุงุช

ููุฃุณูุ ูุง ูููููุง ุฃุนุชูุงุฏ ูุชุงุฆุฌ ูููุฐุฌูุง ุงูุฎุทู ุนูู ุฃููุง ุฅุญุชูุงูุงุช. ุงูุฅุญุชูุงูุงุช ุงูุตุญูุญู ูุฌุจ ุฃู ุชููู ุจูู 0 ู 1ุ ูููู ูููุฐุฌูุง ุงูุฎุทู ูุฎุงูู ูุฐุง ุงูุดุฑุท. ูุซูุงูุ ุฅุญุชูุงููุฉ ุฃู ูุณุฌู ููุจุฑูู ูุฑุฉ ูู ุนูู ุจุนุฏ 100 ูุฏู ุนู ุงูุณูุฉ ูุฌุจ ุฃู ุชููู ุฃูุฑุจ ุฅูู ุงูุตูุฑ. ููููุ ูู ุญุงูุชูุง ููุงุ ุงููููุฐุฌ ุณูุชููุน ูููุฉ ุณูุจูุฉ.

ุฅุฐุง ูููุง ุจุงูุชุนุฏูู ุนูู ูููุฐุฌูุง ุงูุฎุทู ูุชููู ุชููุนุงุชู ุนุจุงุฑุฉ ุนู ุฅุญุชูุงูุงุชุ ูู ุชููู ูุฏููุง ูุดุงูู ูู ุฅุณุชุฎุฏุงู ุชููุนุงุชู ูู ุงูุชุตููู. ูููููุง ุงูููุงู ุจุฐูู ุจุฅุณุชุฎุฏุงู ุจุฅุณุชุฎุฏุงู ุฏุงูุฉ ุชููุน ูุฏุงูุฉ ุฎุณุงุฑุฉ ุฌุฏูุฏ. ูุทูู ุนูู ุงููููุฌ ุจู **ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู Logistic Regression**. 

## ุงููููุฐุฌ ุงูููุฌุณุชู

ูู ูุฐุง ุงูุฌุฒุกุ ุณูุชุนุฑู ุนูู **ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู**ุ ูููุฐุฌ ุฎุทู ูุณุชุฎุฏูุฉ ูุชููุน ุงูุฅุญุชูุงูุงุช.

ููุชุฐูุฑ ุฃู ูุถุจุท ูููุฐุฌ ูุญุชุงุฌ ูุซูุงุซ ุนูุงุตุฑ: ูููุฐุฌ ูููู ุจุงูุชููุนุ ุฏุงูุฉ ุฎุณุงุฑุฉุ ูุทุฑููุฉ ูุชุญุณูู ูุชุงุฆุฌ ุงููููุฐุฌ. ุณูุณุชุฎุฏู ุงููููุฐุฌ ุงูุฐู ูุนุฑูุฉ ุงูุขูุ ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ูููุฑุจุนุงุช ุงูุตุบุฑู:

$$ \begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) &= \hat{\boldsymbol{\theta}} \cdot \textbf{x}
\end{aligned} $$

ูุฏุงูุฉ ุงูุฎุณุงุฑุฉ:

$$ \begin{split}
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_{i}(y_i - f_\boldsymbol{\theta} (\textbf{X}_i))^2\\
\end{aligned}
\end{split} $$

ุณูุณุชุฎุฏู ุงููุฒูู ุงูุฅุดุชูุงูู ูุฃุฏุงุฉ ูุชุญุณูู ุงููุชุงุฆุฌ. ูู ุงูุชุนุฑูู ุงูุณุงุจูุ $ X $ ุชูุซู ูุตูููุฉ ุงูุจูุงูุงุช $ n \times p $ (ููููุง $ n $ ูู ุนุฏุฏ ุงูุจูุงูุงุช ู $ p $ ุนุฏุฏ ุงูุนูุงุตุฑ / ุงูุฃุนูุฏุฉ)ุ ุชูุซู $ \textbf{x} $ ุณุทุฑ ูู $ X $ุ ู $ y $ ูุชูุฌู ูููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุง. ุงููุชูุฌู $ \hat{\boldsymbol{\theta}} $ ุงููุฒู ุงููุซุงูู ูููููุฐุฌ ู $ \boldsymbol{\theta} $ ุชูุซู ุงููุฒู ุงููุชูุณุท ุงูุฐู ุฃูุดุฆ ุฃุซูุงุก ูุญุงููุฉ ุชุญุณูู ุงููููุฐุฌ.

### ุงูุงุนุฏุงุฏ ุงูุญููููู ุฅูู ุงุญุชูุงูุงุช

ููุฑู ุฃู ูููุฐุฌูุง $ f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \hat{\boldsymbol{\theta}} \cdot \textbf{x} $ ูููู ุฃู ูุชููุน ุฃู ุฑูู ุญูููู $ \mathbb{R} $ ุจูุง ุฃูู ููุชุฌ ูุฌููุนุฉ ูู ุงูุงุฑูุงู ุฎุทูุฉ ูู $ \textbf{x} $ุ ูุงูุชู ุจููุณูุง ูููู ุฃู ุชุญุชูู ุนูู ุฃู ุฑูู ูู $ \mathbb{R} $.

ูููููุง ุจุณููู ุฑุณู ุฐูู ุจูุงููุงู ุนูุฏูุง ุชููู $ x $ ุฑูู ูุชุฏุฑุฌ. ุฅุฐุง ูุงูุช $ \hat \theta = 0.5 $ ูุฃู ุงููููุฐุฌ ุณูููู $ f_\hat{\theta} (\textbf{x}) = 0.5 x $. ูููู ูุชููุนุงุช ูุฐุง ุงููููุฐุฌ ุฃู ุชููู ุงู ุฑูู ูู ุณุงูุจ ูุงูุง ููุงูุฉ ุญุชู ููุฌุจ ูุงูุง ููุงูุฉ:

```python
xs = np.linspace(-100, 100, 100)
ys = 0.5 * xs
plt.plot(xs, ys)
plt.xlabel('$x$')
plt.ylabel(r'$f_\hat{\theta}(x)$')
plt.title(r'Model Predictions for $ \hat{\theta} = 0.5 $');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_model_6_0.png'>
</p>

ูููุงู ุงูุชุตูููุ ูุฑูุฏ ุชูููุฏ $ f_\hat{\boldsymbol{\theta}}(\textbf{x}) $ ุจุญูุซ ุชููู ูุชุงุฆุฌูุง ุนุจุงุฑุฉ ุนู ุฅุญุชูุงููุฉ. ูุนูู ุฐูู ุฃู ูุชุงุฆุฌูุง ุชููู ูู ุงููุฏู $ [0, 1] $ ุฃูุถุงูุ ูุฑูุฏ ุฃู ุชุชุทุงุจู ุงูููู ุงููุจุฑู ูู $ f_\hat{\boldsymbol{\theta}}(\textbf{x}) $ ูุน ููู ูุจุฑู ูู ุงูุฅุญุชูุงููุฉ ูุงูุนูุณ ููููู ุงูุตุบุฑู ูุน ูููุฉ ุฅุญุชูุงููุฉ ุตุบุฑู.

### ุงูุฏุงูู ุงูููุฌุณุชูู

ูุฅูุฌุงุฒ ุฐููุ ุณูุชุนุฑู ุนูู **ุงูุฏุงูุฉ ุงูููุฌุณุชูู Logistic Function**ุ ููุทูู ุนูููุง ูู ุจุนุถ ุงูุฃุญูุงู **ุงูุฏุงูุฉ ุงูุณูููุฉ Sigmoid Function**: [๐][Sigmoid]

$$ \begin{aligned}
\sigma(t) = \frac{1}{1 + e^{-t}}
\end{aligned} $$

ูุชุณููู ุงููุฑุงุกุฉุ ุนุงุฏุฉ ูุง ูููู ุจุชุบูุฑ $ e^x $ ุฅูู $ \text{exp}(x) $:

$$ \begin{aligned}
\sigma (t) = \frac{1}{1 + \text{exp}(-t)}
\end{aligned} $$

ูููุง ุจุฑุณู ุงูุฏุงูุฉ ุงูุณูููุฉ ููููู ุงูุชุงููุฉ $ t \in [-10, 10] $:

```python
from scipy.special import expit
xs = np.linspace(-10, 10, 100)
ys = expit(xs)
plt.plot(xs, ys)
plt.title(r'Sigmoid Function')
plt.xlabel('$ t $')
plt.ylabel(r'$ \sigma(t) $');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_model_10_0.png'>
</p>

ููุงุญุธ ุงู ุงูุฏุงูุฉ ุงูุณูููุฉ $ \sigma(t) $ ุชุฃุฎุฑ ุฃู ุฑูู ุญูููู $ \mathbb{R} $ ูุชููู ูุชุงุฆุฌูุง ููุท ุฃุฑูุงู ุจูู 0 ู 1. ุชููู ุงูุฏุงูุฉ ุชุฏุฑูุฌูุงู ุจุงูุตุนูุฏ ุจูุงุกูุง ุนูู ุงูููู ุงููุฏุฎูุฉ $ t $ุ ุงูููู ุงููุจูุฑุฉ ูู $ t $ ูู ุงูููู ุงููุฑูุจุฉ ูู 1ุ ููุง ุฑุบุจูุงูุง ุฃู ุชุนูู. ูู ูุชู ุฐูู ุจุงูุตุฏูุฉุ ุงูุฏุงูุฉ ุงูุณูููุฉ ูููู ุฅุดุชูุงููุง ูู ูุณุจุฉ ููุบุงุฑูุชููุงุช ุงูุฅุญุชูุงูุงุชุ ูููู ูููุง ุจุฅุฎูุงุก ุงูุฅุดุชูุงู ูุชุณููู ุงูุดุฑุญ

### ุชุนุฑูู ุงููููุฐุฌ ุงูููุฌุณุชู

ูููููุง ุงูุขู ุฃุฎุฐ ุงููููุฐุฌ ุงูุฎุทู $ \hat{\boldsymbol{\theta}} \cdot \textbf{x} $ ูุฅุณุชุฎุฏุงูุฉ ูููุฏุฎู ููุฏุงูุฉ ุงูุณูููุฉ ูุฅูุดุงุก **ุงููููุฐุฌ ุงูููุฌุณุชู**:

$$
\begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \sigma(\hat{\boldsymbol{\theta}} \cdot \textbf{x})
\end{aligned}
$$

ุจูุนูู ุขุฎุฑุ ูุฃุฎุฐ ูุชูุฌุฉ ุงูุฅูุญุฏุงุฑ ุงูุฎุทูุ ุฃู ุฑูู ุญูููู $ \mathbb{R} $ุ ููุณุชุฎุฏูุฉ ูู ุงูุฏุงูุฉ ุงูุณูููุฉ ูุชูููุฏ ูุชุงุฆุฌ ุงููููุฐุฌ ุงูููุงุฆูุฉ ูุชููู ูุชูุฌุฉ ุฅุญุชูุงููุฉ ุตุญูุญ ูุฑูู ุจูู ุตูุฑ ููุงุญุฏ.

ููุนุฑูุฉ ุทุฑููุฉ ุนูู ุงููููุฐุฌ ุงูููุฌุณุชู ุจุดูู ุจุณูุทุ ุณูููู ุจุชูููุฏ ูููุฉ $ x $ ูุชููู ุฑูู ูุชุฏุฑุฌ ูุฑุณู ูุชูุฌุฉ ุงููููุฐุฌ ุงูููุฌุณุชู ูุนุฏุฉ ููู ูู $ \hat{\theta} $:

```python
# ูุง ุญุงุฌุฉ ูููู ุงูููุฏ ุงูุจุฑูุฌู ูุฃู ุงููุงุชุจ ุงุณุชุฎุฏูุฉ ูุจูุงุก ุงูุฑุณู ุงูุจูุงูู ุงูุชูุถูุญู
def flatten(li): return [item for sub in li for item in sub]

thetas = [-2, -1, -0.5, 2, 1, 0.5]
xs = np.linspace(-10, 10, 100)

fig, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(10, 6))
for ax, theta in zip(flatten(axes), thetas):
    ys = expit(theta * xs)
    ax.plot(xs, ys)
    ax.set_title(r'$ \hat{\theta} = $' + str(theta))


fig.add_subplot(111, frameon=False)
plt.tick_params(labelcolor='none', top='off', bottom='off',
                left='off', right='off')
plt.grid(False)
plt.xlabel('$x$')
plt.ylabel(r'$ f_\hat{\theta}(x) $')
plt.tight_layout()
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_model_14_0.png'>
</p>

ููุงุญุธ ุฃู ุงูุชุบูุฑ ูู ูููุฉ $ \hat{\theta} $ ูุบูุฑ ูู ุญูุฏุฉ ุงูููุญููุ ูููุง ุฃุจุนุฏูุง ุนู $ 0 $ุ ูููุง ุฒุงุฏุช ุญุฏุฉ ุงูููุญูู. ุชุบูุฑ ุงูุฅุดุงุฑุฉ ูู $ \hat{\theta} $ ูุน ุงูุฅุจูุงุก ุนูู ููุณ ุงููููุฉ ุงูุฑูููุฉ ููุชุฌ ููุง ููุณ ุงููุชุงุฆุฌ ููู ุจุดูู ุนูุณู.

### ููุฎุต ุงููููุฐุฌ ุงูููุฌุณุชู

ุชุนุฑููุง ุนูู ุงููููุฐุฌ ุงูููุฌุณุชูุ ุทุฑููุฉ ุฌุฏูุฏุฉ ููุชููุน ุงูุชู ุชููุชูุฌ ููุง ุชููุนุงุช ูุฅุญุชูุงูุงุช. ูุจูุงุก ุงููููุฐุฌุ ูุณุชุฎุฏู ูุฎุฑุฌุงุช ุงููููุฐุฌ ุงูุฎุทู ููุฏุฎูุงุช ุฅูู ุงูุฏุงูุฉ ุงูููุฌุณุชูุฉ ุบูุฑ ุงูุฎุทูุฉ.

## ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูููููุฐุฌ ุงูููุฌุณุชู

ูููุง ุจุชุนุฑูู ุงููููุฐุฌ ุงูุฎุทู ููุฅุญุชูุงูุงุชุ ุงููููุฐุฌ ุงูููุฌุณุชู:

$$
\begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \sigma(\hat{\boldsymbol{\theta}} \cdot \textbf{x})
\end{aligned}
$$

ููุง ูู ุงููููุฐุฌ ุงูุฎุทูุ ูุญุชูู ุงููููุฐุฌ ุนูู ูุชุบูุฑุงุช $ \hat{\boldsymbol{\theta}} $ุ ูุตูููุฉ ุชุญุชูู ุนูู ูุชุบูุฑ ูุงุญุฏ ููู ุฎุงุตูุฉ ูู $ \textbf{x} $. ุณูููู ุงูุขู ุจุญู ูุดููุฉ ุชุนุฑูู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ููุฐุง ุงููููุฐุฌ ูุงูุชู ุณุชุณูุญ ููุง ุจุถุจุท ูุชุบูุฑุงุช ุงููููุฐุฌ ููุฐุฉ ุงูุจูุงูุงุช.

ูุง ูุฑูุฏุฉ ูู ุฃู ูููู ุงููููุฐุฌ ุจุชููุนุงุช ูุทุงุจูุฉ ุจุดูู ูุจูุฑ ููุจูุงูุงุช. ูู ุงูุฃุณูู ูููุง ุจุฑุณู ุจูุงูู ููุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ูู ุงููุจุงุฑูุงุช ุงูุฃูุตุงุฆูุฉ ูุนุงู 2017 ุจุฅุณุชุฎุฏุงู ุจุนุฏ ููู ุชุณุฏูุฏุฉ ุนู ุงูุณูุฉ:

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=lebron,
           fit_reg=False, ci=False,
           y_jitter=0.1,
           scatter_kws={'alpha': 0.3})
plt.title('LeBron Shot Attempts')
plt.xlabel('Distance from Basket (ft)')
plt.ylabel('Shot Made');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_cost_4_0.png'>
</p>

ููุงุญุธ ุงูุชุฌูุน ููุซูุฑ ูู ุงููุญุงููุงุช ุงูุชู ุชู ุชุณุฌูููุง ูุงูุชู ูุงูุช ูุฑูุจุฉ ูู ุงูุณูุฉ ูุชุฌูุน ูููู ูู ุงูุจูุงูุงุช ููุญุงููุงุช ุชู ุชุณุฌูููุง ูู ูุณุงูุงุช ุจุนูุฏุฉ ุนู ุงูุณูุฉุ ูุชููุน ุนูุฏูุง ูุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ุนูู ูุฐู ุงูุจูุงูุงุช ุฃู ุดููุฉ ุณูููู ูุงูุชุงูู:

```python
from scipy.special import expit

sns.lmplot(x='shot_distance', y='shot_made',
           data=lebron,
           fit_reg=False, ci=False,
           y_jitter=0.1,
           scatter_kws={'alpha': 0.3})

xs = np.linspace(-2, 32, 100)
ys = expit(-0.15 * (xs - 15))
plt.plot(xs, ys, c='r', label='Logistic model')

plt.title('Possible logistic model fit')
plt.xlabel('Distance from Basket (ft)')
plt.ylabel('Shot Made');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_cost_6_0.png'>
</p>

ุนูู ุงูุฑุบู ุฃู ุจุฅููุงููุง ุฅุณุชุฎุฏุงู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ููุง ูุนููุง ูู ูููุฐุฌ ุงูุฅูุญุฏุงุฑ ุงูุฎุทูุ ูู ููุณุช ููุงุฆูุฉ ูููููุฐุฌ ุงูููุฌุณุชู ููุตุนุจ ุชุญุณูู ูุชุงุฆุฌูุง.

### ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู

ุจุฏูุงู ูู ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุทุ ุณูุณุชุฎุฏู **ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู Cross-Entropy Loss**. ูุชูุซู $ \textbf{X} $ ูุตูููุฉ ุงูุจูุงูุงุช $ n \times p $ุ ู $ \textbf{y} $ ูุชูุฌู ูููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุงุ ู $ f_\boldsymbol{\theta}(\textbf{x}) $ ุชูุซู ุงููููุฐุฌ ุงูููุฌุณุชู. ุชุญุชูู $\boldsymbol{\theta}$ ุนูู ููู ุงููุชุบูุฑุงุช ุงูุญุงููุฉ. ุจุฅุณุชุฎุฏุงู ูุฐุง ุงูุชุนุฑููุ ูููููุง ุชุนุฑูู ูุนุงุฏูุฉ ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู ูุงูุชุงูู:

$$
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) = \frac{1}{n} \sum_i \left(- y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) \right)
\end{aligned}
$$

ูููู ุฃู ุชูุงุญุธุ ููุง ูุนููุง ูุณุจูุงูุ ุฃููุง ุฃุฎุฐูุง ูุชูุณุท ุงูุฎุณุงุฑุฉ ููู ููุทุฉ ูุนููุฉ ูู ุงูุจูุงูุงุช. ูุง ูู ุฏุงุฎู ุงูุชุนุฑูู ุงูุณุงุจู ููุซู ุงูุฎุณุงุฑุฉ ูููุทุฉ ูุนููุฉ $(\textbf{X}_i, y_i)$:

$$
\begin{aligned}
\ell(\boldsymbol{\theta}, \textbf{X}_i, y_i) = - y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) )
\end{aligned}
$$

ููุชุฐูุฑ ุฃู ูู ูููุฉ $ y_i $ ุณุชููู ุฅูุง 0 ุฃู 1. ุฅุฐุง ูุงูุช $ y_i = 0 $ุ ูุฃูู ูุตุทูุญ ูู ุงูุฎุณุงุฑุฉ ูุณุงูู ุตูุฑ. ุฅุฐุง ูุงูุช $ y_i = 1 $ุ ูุฃู ุซุงูู ูุตุทูุญ ูู ุงูุชุนุฑูู ุงูุณุงุจู ูุณุงูู ุตูุฑ. ูุฐุงุ ููู ููุทุฉ ูู ุจูุงูุงุชูุงุ ูุฃู ููุท ุฌุฒุก ูุงุญุฏ ูู ุชุนุฑูู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุณุงูู ูู ุญุณุงุจ ูููุฉ ุงูุฎุณุงุฑุฉ ุงูููุงูุฉ.

ูููุชุฑุถ ุฃู $ y_i = 0 $ ูุงูุฅุญุชูุงููุฉ ุงููุชููุนุฉ ูุงูุช $ f_\boldsymbol{\theta}(\textbf{X}_i) = 0 $ุ ูุฃู ูููุฐุฌูุง ูุงู ุชููุนุฉ ุตุญูุญ. ุณุชููู ุงูุฎุณุงุฑุฉ ููุฐุฉ ุงูููุทุฉ ูุงูุชุงูู:

$$
\begin{aligned}
\ell(\boldsymbol{\theta}, \textbf{X}_i, y_i)
&= - y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) ) \\
&= - 0 - (1 - 0) \ln (1 - 0 ) \\
&= - \ln (1) \\
&= 0
\end{aligned}
$$

ููุง ูู ูุชููุนุ ุงูุฎุณุงุฑุฉ ููุชููุน ุงูุตุญูุญ ูู $ 0 $. ููููู ุงูุชุฃูุฏ ูู ุฐูู ุนูุฏูุง ุชููู ูุชุงุฆุฌ ุชููุน ุงูุฅุญุชูุงููู ุฃุจุนุฏ ูู ุงููููุฉ ุงูุญูููุฉุ ูุฃู ุงูุฎุณุงุฑุฉ ุชููู ุนุงููุฉ.

ุงูุชูููู ูู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู ูุญุชุงุฌ ุฃู ูููู ุงููููุฐุฌ $ f_\boldsymbol{\theta}(\textbf{x}) $ ุจุฃุฏู ุงูุชููุนุงุช ุงูุตุญูุญู ุงูููููุฉ. ูุฐููุ ูุฃู ุฏุงูุฉ ุงูุฎุงุณุฑุฉ ูุฐู ููุญุฏุจุฉุ ููุง ูุฌุนู ุงููุฒูู ุงูุฅุดุชูุงูู ููุงุณุจ ูุชุญุณูู ุงููุชุงุฆุฌ.

### ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ูุชุทุจูู ุงููุฒูู ุงูุฅุดุชูุงูู ุนูู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูููููุฐุฌ ูุฌุจ ุนูููุง ุญุณุงุจ ูุดุชูุฉ ุงูุฎุณุงุฑุฉ. ุฃููุงูุ ูููู ุจุญุณุงุจ ูุดุชูุฉ ุงูุฏุงูุฉ ุงูุณูููุฉ ุจูุง ุฃููุง ุณูุณุชุฎุฏููุง ูู ุนูููุฉ ุญุณุงุจ ุงูุฅุดุชูุงู:

$$
\begin{aligned}
\sigma(t) &= \frac{1}{1 + e^{-t}} \\
\sigma'(t) &= \frac{e^{-t}}{(1 + e^{-t})^2} \\
\sigma'(t) &= \frac{1}{1 + e^{-t}} \cdot \left(1 - \frac{1}{1 + e^{-t}} \right) \\
\sigma'(t) &= \sigma(t) (1 - \sigma(t))
\end{aligned}
$$

ูููููุง ูุตู ูุดุชูุฉ ุงูุฏุงูุฉ ุงูุณูููุฉ ูู ุงูุฏุงูุฉ ุงูุณูููุฉ ููุณูุง.

ููุฅุฎุชุตุงุฑุ ูููู ุจุชุนุฑูู $ \sigma_i = f_\boldsymbol{\theta}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) $. ุณูุญุชุงุฌ ูุฑูุจุงู ุฅูู ูุดุชูุฉ $ \sigma_i $ ููููุชุฌูุฉ $ \boldsymbol{\theta} $ ูุฐุง ุณูููู ุจุญุณุงุจุฉ ุงูุขู ุจุฅุณุชุฎุฏุงู ูุงุนุฏุฉ ุงูุณูุณูุฉ: [๐][ChainRule]

$$
\begin{aligned}
\nabla_{\boldsymbol{\theta}} \sigma_i
&= \nabla_{\boldsymbol{\theta}} \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) \\
&= \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) (1 - \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}))  \nabla_{\boldsymbol{\theta}} (\textbf{X}_i \cdot \boldsymbol{\theta}) \\
&= \sigma_i (1 - \sigma_i) \textbf{X}_i 
\end{aligned}
$$

ูุงูุขูุ ุณููุฌุฏ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ููุชุบูุฑุงุช ุงููููุฐุฌ $ \boldsymbol{\theta} $. ูู ุชูุตูู ุญู ุงููุดุชูุฉ ูู ุงูุฃุณููุ ุฌุนููุง $ \sigma_i = f_\boldsymbol{\theta}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) $: 

$$
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_i \left(- y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) \right) \\
&= \frac{1}{n} \sum_i \left(- y_i \ln \sigma_i - (1 - y_i) \ln (1 - \sigma_i) \right) \\
\nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_i \left(
    - \frac{y_i}{\sigma_i} \nabla_{\boldsymbol{\theta}} \sigma_i
    + \frac{1 - y_i}{1 - \sigma_i} \nabla_{\boldsymbol{\theta}} \sigma_i \right) \\
&= - \frac{1}{n} \sum_i \left(
    \frac{y_i}{\sigma_i} - \frac{1 - y_i}{1 - \sigma_i}
\right) \nabla_{\boldsymbol{\theta}} \sigma_i \\
&= - \frac{1}{n} \sum_i \left(
    \frac{y_i}{\sigma_i} - \frac{1 - y_i}{1 - \sigma_i}
\right) \sigma_i (1 - \sigma_i) \textbf{X}_i \\
&= - \frac{1}{n} \sum_i \left(
    y_i - \sigma_i
\right) \textbf{X}_i \\
\end{aligned}
$$

ุงูุชุนุฑูู ุงูุจุณูุท ูููุดุชูุฉ ูุณูุญ ููุง ุจุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ุจุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู:

$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\boldsymbol{\theta}}}  L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})$$

ูุงุญูุงู ุณูุชุนูู ููุญุฏุซ ูู ุงููุนุงุฏูุฉ ูุฃููุงุน ูุฎุชููุฉ ูู ุงููุฒูู ุงูุฅุดุชูุงูู ุงูุฏููุนุงุชุ ุงูุนุดูุงุฆู ูุงูุฏูุนุงุช ุงูุตุบูุฑุฉ.

### ููุฎุต ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ุจูุง ุฃู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ููุญุฏุจุฉุ ูููู ุจุชูููููุง ุจุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู ูุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ุนูู ุงูุจูุงูุงุช. ูุฏููุง ุงูุขู ุงูุนูุงุตุฑ ุงููููู ููุฅูุญุฏุงุฑ ุงูููุฌุณุชู: ุงููููุฐุฌุ ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูุทุฑููุฉ ูุชุณุญูู ุงููุชุงุฆุฌ. ูู ุฌุฒุก ูุงุญู ุณูุชุนูู ุฃูุซุฑ ููุนุฑูุฉ ุณุจุจ ุฅุณุชุฎุฏุงููุง ููุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูู ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู

## ุงุณุชุฎุฏุงู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู

ุชุนุฑููุง ุนูู ุฌููุน ุงูุนูุงุตุฑ ุงููุทููุจุฉ ูู ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชูุ ุฃููุงูุ ุงููููุฐุฌ ุงูููุฌุณุชู ุงููุณุชุฎุฏู ูุฅุฌุฑุงุก ุชููุนุงุช ุงูุฅุญุชูุงููุงุช:

$$ \begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \sigma(\hat{\boldsymbol{\theta}} \cdot \textbf{x})
\end{aligned} $$

ุซู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ:

$$ \begin{split}
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) = &= \frac{1}{n} \sum_i \left(- y_i \ln \sigma_i - (1 - y_i) \ln (1 - \sigma_i ) \right) \\
\end{aligned}
\end{split} $$

ูุฃุฎูุฑุงูุ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูููุฒูู ุงูุฅุดุชูุงูู:

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= - \frac{1}{n} \sum_i \left(
    y_i - \sigma_i
\right) \textbf{X}_i \\
\end{aligned}
\end{split} $$

ูู ุงููุนุงุฏูุฉ ุงูุณุงููุฉุ ุฌุนููุง $ \textbf{X} $ ุชูุซู ูุตูููุฉ ุงูุจูุงูุงุช $ n \times p $ ุ ุชูุซู $ \textbf{x} $ ุณุทุฑ ูู $ \textbf{X} $ุ ู $ y $ ูุชูุฌู ูููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุง. ู $ f_\hat{\boldsymbol{\theta}}(\textbf{x}) $ ูู ุงููููุฐุฌ ุงูููุฌุณุชู ุงููุซุงูู ูุฐู ูุชุบูุฑุงุช ูุซุงููุฉ $ \hat{\boldsymbol{\theta}} $. ููุฅุฎุชุตุงุฑุ ูุนุฑู $ \sigma_i = f_\hat{\boldsymbol{\theta}}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \hat{\boldsymbol{\theta}}) $.

### ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนูู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู

ููุนูุฏ ูููุดููุฉ ุงูุชู ูุงุฌููุงูุง ูู ุจุฏุงูุฉ ูุฐุง ุงููุตู: ููุชููุน ุฃู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ุฌููุณ ุณุชุตูุจ ุงููุฏู. ุฃููุงู ูุญูู ุจูุงูุงุช ูุญุงููุงุช ุงูุชุตููุจ ูููุจุฑูู ูู ุงููุจุงุฑูุงุช ุงูุฅูุตุงุฆูุฉ ูุนุงู 2017:

```python
lebron = pd.read_csv('lebron.csv')
lebron
```

**shot\_made**|**shot\_distance**|**shot\_type**|**action\_type**|**opponent**|**minute**|**game\_date**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
0|0|2PT Field Goal|Driving Layup Shot|IND|10|20170415|0
1|0|2PT Field Goal|Driving Layup Shot|IND|11|20170415|1
1|0|2PT Field Goal|Layup Shot|IND|14|20170415|2
...|...|...|...|...|...|...|...
1|1|2PT Field Goal|Driving Layup Shot|GSW|46|20170612|381
0|14|2PT Field Goal|Turnaround Fadeaway shot|GSW|47|20170612|382
1|2|2PT Field Goal|Driving Layup Shot|GSW|48|20170612|383

```ruby
384 rows ร 7 columns
```

ููููู ูุธุฑุฉ ุจุดูู ุชูุงุนูู ุนูู ูุฐู ุงูุจูุงูุงุช:

```python
df_interact(lebron)
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/lebron-data-sample.gif'>
</p>

```ruby
(384 rows, 7 columns) total
```


> ุดูุฑุญุช ูุฐู ุงูุฏุงูุฉ ูู ูุตู ุณุงุจู ููุธููุชูุง ูู ุชูููู ุงููุณุชุฎุฏู ูู ุชุตูุญุฉ ุงูุจูุงูุงุช ุจุดูู ุชูุงุนูู ูุชู ุชุนุฑูููุง ูุงูุชุงูู:
>
>```python
>import numpy as np
>import matplotlib.pyplot as plt
>import pandas as pd
>import seaborn as sns
>%matplotlib inline
>import ipywidgets as widgets
>from ipywidgets import interact, interactive, fixed, interact_manual
>
>def peek(row=0, col=0):
>        return df.iloc[row:row + nrows, col:col + ncols]
>    if len(df.columns) <= ncols:
>        interact(peek, row=(0, len(df) - nrows, nrows), col=fixed(0))
>    else:
>        interact(peek,
>                 row=(0, len(df) - nrows, nrows),
>                 col=(0, len(df.columns) - ncols))
>    print('({} rows, {} columns) total'.format(df.shape[0], df.shape[1]))
>```

ูุจุฏุฃ ุฃููุงู ุจุฅุณุชุฎุฏุงู ูุณุงูุฉ ูุญุงููุฉ ุงูุชุณุฌูู ูุชููุน ูุง ุฅุฐุง ุชู ุชุณุฌูู ุงููุญุงููุฉ ุฃู ูุง. ุชููุฑ ููุง ููุชุจุฉ `scikit-learn` ุงููููุฐุฌ ุงูููุฌุณุชู ุจุดูู ุณูู ุนุจุฑ ุงูููุงุณ [sklearn.linear_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). ูุฅุณุชุฎุฏุงูุฉุ ูุจุฏุฃ ุฃููุงู ุจุฅูุดุงุก ูุตูููุฉ ุงูุจูุงูุงุช `X`ุ ูููุชุฌูุฉ ุงููุชุงุฆุฌ ุงูุชู ุงูููุทูุน ุนูููุง `y`.

```python
X = lebron[['shot_distance']].as_matrix()
y = lebron['shot_made'].as_matrix()
print('X:')
print(X)
print()
print('y:')
print(y)
```

```ruby
X:
[[ 0]
 [ 0]
 [ 0]
 ...
 [ 1]
 [14]
 [ 2]]

y:
[0 1 1 ... 1 0 1]
```

ููุงููุนุชุงุฏุ ุณููุณู ุจูุงูุงุชูุง ุฅูู ุจูุงูุงุช ุชุฏุฑูุจ ูุฅุฎุชุจุงุฑ:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=40, random_state=42
)
print(f'Training set size: {len(y_train)}')
print(f'Test set size: {len(y_test)}')
```

```ruby
Training set size: 344
Test set size: 40
```

ุชุฌุนู ููุชุจุฉ `scikit-learn` ุฅูุดุงุก ูุถุจุท ุงููููุฐุฌ ุนูู `X_train` ู `y_train` ุนูููุฉ ุณููุฉ ุฌุฏุงู: 

```python
from sklearn.linear_model import LogisticRegression
simple_clf = LogisticRegression()
simple_clf.fit(X_train, y_train)
```

```ruby
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
```

ูุนุฑุถ ุฃุฏุงุก ุงููููุฐุฌ ูู ุฑุณู ุจูุงููุ ุณูุชุนุฑุถ ุงูููุงุท ุงูุฃุตููุฉ ูุชููุนุงุช ุงููููุฐุฌ ููุฅุญุชูุงููุฉ:

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=lebron,
           fit_reg=False, ci=False,
           y_jitter=0.1,
           scatter_kws={'alpha': 0.3})

xs = np.linspace(-2, 32, 100)
ys = simple_clf.predict_proba(xs.reshape(-1, 1))[:, 1]
plt.plot(xs, ys)

plt.title('LeBron Training Data and Predictions')
plt.xlabel('Distance from Basket (ft)')
plt.ylabel('Shot Made');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_reg_16_0.png'>
</p>

### ุชูููู ุงููุตูู

ุฃุญุฏู ุงูุทุฑู ูุชูููู ุฃุฏุงุก ุงููููุฐุฌ ูู ุจููุงุณ ุฏูุฉ ุงูุชููุนุงุช: ูุง ูู ูุณุจุฉ ุงูุชููุนุงุช ุงูุตุญูุญุฉุ

```python
simple_clf.score(X_test, y_test)
```

```ruby
0.6
```

ูุจุฏู ุฃู ุฃุฏุงุก ุงููููุฐุฌ ูุชุฏูู ููููุงู ุจุฏูุฉ 0.6 ุนูู ุจูุงูุงุช ุงูุฅุฎุชุจุงุฑ. ุฅุฐุง ูุงู ูููุฐุฌูุง ุจุงูุชููุน ุนูู ูู ุงูููุงุท ุจุดูู ุนุดูุงุฆูุ ุณูุชููุน ูุชูุฌุฉ ุงูุฏูุฉ ุณุชููู 0.50. ุจุงูุฃุตุญุ ุฅุฐุง ูุงู ูููุฐุฌูุง ุจุจุณุงุทุฉ ุจุชููุน ูู ูุญุงููุฉ ูููุจุฑููุ ุณูุญุตู ุนูู ููุณ ูุณุจุฉ ุงูุฏูุฉ:

```python
# ุญุณุงุจ ุงูุฏูุฉ ุฅุฐุง ูุงู ุงูุชููุน 1
np.count_nonzero(y_test == 1) / len(y_test)
```

```ruby
0.6
```

ููุฐุง ุงููููุฐุฌุ ุฅุณุชุฎุฏููุง ูุชุบูุฑ ูุงุญุฏ ูู ุนุฏุฏ ูุฎุชูู ูู ุงููุชุบูุฑุงุช ูู ูุฐู ุงูุจูุงูุงุช. ูู ุงููููุฐุฌ ุงูููุฌุณุชู ูุชุนุฏุฏ ุงููุชุบูุฑุงุชุ ุณูุญุตู ุนูู ูุชุงุฆุฌ ุฃูุซุฑ ุฏูุฉ ุจุฅุณุชุฎุฏุงู ุฃูุซุฑ ูู ูุชุบูุฑ.

### ูููุฐุฌ ููุฌุณุชู ูุชุนุฏุฏ ุงููุชุบูุฑุงุช

ุงูุฒูุงุฏุฉ ูู ุนุฏุฏ ุงููุชุบูุฑุงุช ุงูุฑูููุฉ ูู ุงููููุฐุฌ ุณูู ุฌุฏุงู. ุนูู ุงูุนูุณุ ูููุชุบูุฑุงุช ูู ุงูููุน ุงูููุนู/ุงูุชุตููููุฉุ ูุญุชุงุฌ ูุชุทุจูู One-hot encoding. ูู ุงูููุฏ ุงูุจุฑูุฌู ุงูุชุงููุ ุฃุถููุง ุงููุฒูุฏ ูู ุงููุชุบูุฑุงุช ูููููุฐุฌ ููู `minute`ุ `opponent`ุ `action_type` ู `shot_type` ุจุฅุณุชุฎุฏุงู ููุงุณ `DictVectorizer` ูู ููุชุจุฉ `scikit-learn` ูุชุทุจูู `One-hot encoding` ุนูู ุงููุชุบูุฑุงุช ุงูููุนูุฉ:

```python
from sklearn.feature_extraction import DictVectorizer

columns = ['shot_distance', 'minute', 'action_type', 'shot_type', 'opponent']
rows = lebron[columns].to_dict(orient='row')

onehot = DictVectorizer(sparse=False).fit(rows)
X = onehot.transform(rows)
y = lebron['shot_made'].as_matrix()

X.shape
```

```ruby
(384, 42)
```

ุณูููู ูุฑู ุฃุฎุฑู ุจุชูุณูู ุงูุจูุงูุงุช ุฅูู ุจูุงูุงุช ุชุฏุฑูุจ ูุฅุฎุชุจุงุฑ:

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=40, random_state=42
)
print(f'Training set size: {len(y_train)}')
print(f'Test set size: {len(y_test)}')
```

```ruby
Training set size: 344
Test set size: 40
```

ุฃุฎูุฑุงูุ ูููู ุจุถุจุท ุงููููุฐุฌ ูุฑู ุฃุฎุฑู ููุชุญูู ูู ุงูุฏูุฉ:

```python
clf = LogisticRegression()
clf.fit(X_train, y_train)
print(f'Test set accuracy: {clf.score(X_test, y_test)}')
```

```ruby
Test set accuracy: 0.725
```

ุฏูุฉ ูุฐุง ุงููููุฐุฌ ุฃูุซุฑ ุจู 12% ูู ุงููููุฐุฌ ุงูุณุงุจู ุงูุฐู ูุณุชุฎุฏู ูุชุบูุฑ ูุงุญุฏ. ูู ุฌุฒุก ูุงุญูุ ุณูุณุชุฎุฏู ูุฒูุฏุงู ูู ุงูุงุฏูุงุช ูุชูููู ุฃุฏุงุก ุงููููุฐุฌ.

### ููุฎุต ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู

ูููุง ุจุชุทููุฑ ุนูููุงุช ุญุณุงุจูุฉ ุฑูุงุถูุฉ ูุญุงุณูุจูุฉ ูุฅุณุชุฎุฏุงู ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู ูู ุงูุชุตููู. ูุณุชุฎุฏู ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู ุจุดูู ูุจูุฑ ูุณูููุชู ููุงุนููุชู ูู ุงูุชููุนุงุช.

## ุชูุฑูุจ ุงูุชูุฒูุน ุงูุงุญุชูุงูู ุงูุชุฌุฑูุจู

ูู ูุฐุง ุงูุฌุฒุก ูู ุงููุตูุ ุณูุชุนุฑู ุนูู **ุชุจุงุนุฏ KL (KL divergence)** ููุธูุฑ ููู ุฃู ุงูุชูููู ูู ูุชูุณุท ุงูุชุจุงุนุฏ KL ูู ุงูุชุตููู ุฐู ุงููุชุงุฆุฌ ุงูุซูุงุฆูุฉ (Binary 0/1) ููุงุซู ูุฅุณุชุฎุฏุงู ุชูููู ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ.

ุจูุง ุฃู ุงููุชุงุฆุฌ ูู ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู ุนุจุงุฑุฉ ุนู ุฅุญุชูุงูุงุชุ ุงููููุฐุฌ ุงูููุฌุณุชู ููุชุฌ ููุง ููุนุงู ูุนูู ูู ุชูุฒูุน ุงูุฅุญุชูุงูุงุช. ุจุดูู ุฎุงุตุ ุจูุงุกูุง ุนูู ุงููุชุบูุฑุงุช ุงููุซุงููุฉ $ \hat{\boldsymbol{\theta}} $ุ ูุฃูู ูููู ุจุชูููู ุฅุญุชูุงููุฉ ุฃู ุงููุชูุฌุฉ $ y $ ุณุชููู $ 1 $ ููููุฉ ุงุฏุฎููุงูุง ูููููุฐุฌ $ \textbf{x} $.

ูุซูุงูุ ูููุชุฑุถ ุฃู $ x $ ูููู ุฑูููุฉ ุชุณุฌู ุฅุญุชูุงููุฉ ุณููุท ุฃูุทุงุฑ ุงูููู ู $ y = 1 $ ุชุนูู ุฃู ุงูุณูุฏ ุฏู ูุญุชุงุฌ ูุฃุฎุฐ ูุธูุชู ูุนู ููุนูู. ุงููููุฐุฌ ุงูููุฌุณุชู ุฐู ุงููุชุบูุฑุงุช ุงูุฑูููุฉ $ \hat{\theta} $ ูุชููุน ุฅุญุชูุงููุฉ ุฅุญุชูุงุฌ ุงูุณูุฏ ุฏู ูุฃุฎุฐ ูุธูุชู ูุนู ุฅูู ุงูุนูู ุจูุงุกูุง ุนูู ุชููุน ุณููุท ุงูุฃูุทุงุฑ ูุฐุง ุงูููู: $ \hat{P_\theta}(y = 1 \| x) $.

ุฌูุน ุจูุงูุงุช ุงุณุชุฎุฏุงู ุงูุณูุฏ ุฏู ููุธูุชู ูููุฑ ููุง ุทุฑููุฉ ูุจูุงุก ุชูุฒูุน ุฅุญุชูุงูู ุชุฌุฑูุจู $ P(y = 1 \| x) $. ูุซูุงูุ ุฅุฐุง ูุงู ููุงู ุฎูุณ ุฃูุงู ูุงูุช ูููุง ุฅุญุชูุงููุฉ ุฃู ุญุงูุฉ ุงูุทูุณ ุณุชููู ูุงุทุฑ ูู $ x = 0.60 $ ููุงู ุงูุณูุฏ ุฏู ุจุฃุฎุฐ ูุธูุชู ูุฑู ูุงุญุฏุฉุ ูุฃู $ P(y = 1 \| x = 0.60) = 0.20 $. ูููููุง ุญุณุงุจ ุชูุฒูุน ููุงุซู ููุฅุญุชูุงููุฉ ููู ูููุฉ $ x $ ุชุธูุฑ ูู ุจูุงูุงุชูุง. ุจุดูู ุทุจูุนูุ ุจุนุฏ ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ูุฑูุฏ ุงู ุชููู ุชููุนุงุช ูููุฐุฌูุง ูุฑูุจุฉ ุฌุฏุงู ุฅูู ุงูุชูุฒูุน ุงูุฅุญุชูุงูู ุงูุชุฌุฑูุจู ูู ุงูุจูุงูุงุช. ูุนูู ุฐููุ ููู ุงูููู $ x $ ูู ุงูุจูุงูุงุชุ ูุฑูุฏ:

$$ \hat{P_\theta}(y = 1 \| x) \approx P(y = 1 | x) $$

ุฃุญุฏ ุทุฑู ุงูููุงุณ ุงูุฃูุซุฑ ุฅุณุชุฎุฏุงูุงู ูุชุญุฏูุฏ ูุฏู ูุฑุจ ูุชุงุฆุฌ ุชูุฒูุนุงุช ุงูุฅุญุชูุงูุงู ูู **ุชุจุงุนุฏ ูููุจุงู - ููุจููุฑ KullbackโLeibler divergence** ุฃู ุชุจุงุนุฏ KL.

### ุชุนุฑูู ูุชูุณุท ุชุจุงุนุฏ KL

ูููู ุชุจุงุนุฏ KL ุจุญุณุงุจ ุงููุฑู ุจูู ุชูุฒูุน ุฅุญุชูุงููุฉ $\hat{P_\boldsymbol{\theta}}$ ุงูุชู ูุงู ุจุญุณุงุจูุง ุงููููุฐุฌ ุงูููุณุฌุชู ุจุงููุชุบูุฑุงุช $ \boldsymbol{\theta} $ ูุน ุงูุชูุฒูุน ุงูุญูููู ููููุงุท $ P $ ูู ุงูุจูุงูุงุช. ูููู ุจุญุณุงุจ ูุฏู ุนุฏู ุฏูุฉ ุชููุนุงุช ุงููููุฐุฌ ุงูููุณุฌุชู ูุชูุฒูุนุงุช ุงูุจูุงูุงุช.

ุชุจุงุนุฏ KL ูุชุตููู ุซูุงุฆู ูุชูุฒูุนูู $P$ ู $\hat{P_\boldsymbol{\theta}}$ ูููุทุฉ ูุงุญุฏุฉ $(\textbf{x}, y)$ ูู:

$$D(P || \hat{P_\boldsymbol{\theta}}) = P(y = 0 | \textbf{x}) \ln \left(\frac{P(y = 0 | \textbf{x})}{\hat{P_\boldsymbol{\theta}}(y = 0 | \textbf{x})}\right) + P(y = 1 | \textbf{x}) \ln \left(\frac{P(y = 1 | \textbf{x})}{\hat{P_\boldsymbol{\theta}}(y = 1 | \textbf{x})}\right)$$

ุชุจุงุนุฏ KL ููุณุช ูุชูุงุณูุฉุ ูุซูุงู ุชุงุจุนุฏ $\hat{P_\boldsymbol{\theta}}$ ุนู $P$ ููุณุช ููุณ ุชุจุงุนุฏ $P$ ุนู $\hat{P_\boldsymbol{\theta}}$: 

$$D(P || \hat{P_\boldsymbol{\theta}}) \neq D(\hat{P_\boldsymbol{\theta}} || P)$$

ุจูุง ุฃู ูุฏููุง ูู ุฅุณุชุฎุฏุงู $\hat{P_\boldsymbol{\theta}}$ ููุชููุน ุงูุชูุฑูุจู ูู $P$ุ ููุญู ููุชููู ุจู $ D(P \\| \hat{P_\boldsymbol{\theta}}) $.

ุงูููู ุงููุซุงููุฉ ูู $\boldsymbol{\theta}$ุ ูุงูุชู ุฃุดุฑูุง ููุง ุจู $\hat{\boldsymbol{\theta}}$ุ ุชููู ูู ูุชูุณุท ุชุจุงุนุฏ KL ูุฌููุน ููุงุท ุงูุจูุงูุงุช $ n $:

$$ \text{Average KL Divergence} = \frac{1}{n} \sum_{i=1}^{n} \left(P(y_i = 0 | \textbf{X}_i) \ln \left(\frac{P(y_i = 0 | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = 0 | \textbf{X}_i)}\right) + P(y_i = 1 | \textbf{X}_i) \ln \left(\frac{P(y_i = 1 | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = 1 | \textbf{X}_i)}\right)\right)$$

$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\boldsymbol{\theta}}} (\text{Average KL Divergence}) $$

ูู ุงููุนุงุฏูุฉ ุงูุณุงุจูุฉุ ุงูููุทุฉ $i^{\text{th}}$ ูู ููุงุท ุงูุจูุงูุงุช ุฃุดูุฑ ููุง ุจู ($ \textbf{X}_i $, $ y_i $) ูููุง $ \textbf{X}_i $ ูู ุงูุณุทุฑ $i^{\text{th}}$ ูู ุงูุจูุงูุงุช $n \times p$ ูู ูุตูููุฉ ุงูุจูุงูุงุช $\textbf{X}$ ู $ y_i $ ูู ุงููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุง.

ูุง ูุนุงูุจ ุชุจุงุนุฏ KL ุงูููู ุงูุดุงุฐุฉ ูุงููุงุฏุฑ ุญุฏูุซูุง ูู $ P $. ุฅุฐุง ุชููุน ุงููููุฐุฌ ุฅุญุชูุงููุฉ ุนุงููุฉ ูุญุฏุซ ูุงุฏุฑ ุงูุญุฏูุซุ ูุฃู ูููููุง $P(k)$ ู $\ln \left(\frac{P(k)}{\hat{P_\boldsymbol{\theta}}(k)}\right)$ ุงูุชุงุจุนุฏ ุจููููุง ูููู. ููููุ ุงุฐุง ุชููุน ุงููููุฐุฌ ุฅุญุชูุงููุฉ ุถุฆููุฉ ูุญุฏุซ ูุซูุฑ ุงูุญุฏูุซุ ูุฃู ุงูุชุจุงุนุฏ ููู ุนุงูู. ูููู ุฃู ูุณุชูุชุฌ ุฃู ุงููููุฐุฌ ุงูููุฌุณุชู ุงูุฐู ูููู ุจุชููุนุงุช ุตุญูุญุฉ ูุฃุญุฏุงุซ ูุซูุฑุฉ ุงูุญุฏูุซ ูุฏูุฉ ุชุจุงุนุฏ ูููู ูู $P$ ุนูู ุนูุณ ูููุฐุฌ ูุชููุน ุฃุญุฏุงุซ ูุงุฏุฑุฉ ุงูุญุฏูุฏ ูููู ูุฎุชูู ุจุดูู ูุจูุฑ ูู ุงูุฃุญุฏุงุซ ูุซูุฑุฉ ุงูุญุฏูุซ.

### ุงุณุชูุชุงุฌ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู ูู ุชุจุงุนุฏ KL

ุชุชุดุงุจู ุจุดูู ูุจูุฑ ุงููุนุงุฏูุฉ ุงูุณุงุจูุฉ ูุชุจุงุนุฏ KL ูุน ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู. ุณูุนุฑุถ ุงูุขู ูู ุจุนุถ ุงูุนูููุงุช ุงูุฑูุงุถูุฉ ุงูุฌุจุฑูู ุฃู ุชูููู ูุชูุณุท ุชุจุงุนุฏ KL ูุดุงุจู ุชูููู ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู.

ุจุฅุณุชุฎุฏุงู ุฎุตุงุฆุต ุงูููุบุงุฑูุชูุงุชุ ูููููุง ุฅุนุงุฏุฉ ูุชุงุจุฉุ ูููููุง ุฅุนุงุฏุฉ ุงููุชุงุจุฉ ูุงูุชุงูู:

$$P(y_i = k | \textbf{X}_i) \ln \left(\frac{P(y_i = k | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = k | \textbf{X}_i)}\right) = P(y_i = k | \textbf{X}_i) \ln P(y_i = k | \textbf{X}_i) - P(y_i = k | \textbf{X}_i) \ln \hat{P_\boldsymbol{\theta}}(y_i = k | \textbf{X}_i)$$

ูุงุญุธ ุจูุง ุฃู ุงููุตุทูุญ ุงูุฃูู ูุง ูุนุชูุฏ ุนูู $\boldsymbol{\theta}$ุ ูุฃูู ูุง ูุฃุซุฑ ุนูู $\displaystyle\arg \min_{\substack{\boldsymbol{\theta}}}$ ููููู ุญุฐูุฉ ูู ุงููุนุงุฏูุฉ. ุงููุนุงุฏูุฉ ุงููุงุชุฌุฉ ุจุนุฏ ุฐูู ุญู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู ูููููุฐุฌ $\hat{P_\boldsymbol{\theta}}$:

$$ \text{Average Cross-Entropy Loss} = \frac{1}{n} \sum_{i=1}^{n} - P(y_i = 0 | \textbf{X}_i) \ln \hat{P_\theta}(y_i = 0 | \textbf{X}_i) - P(y_i = 1 | \textbf{X}_i) \ln \hat{P_\theta}(y_i = 1 | \textbf{X}_i)$$

$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\theta}} (\text{Average Cross-Entropy Loss}) $$

ุจูุง ุฃู $y_i$ ูู ูููู ูุนุฑููุฉุ ูุฅู ุงุญุชูุงููุฉ $y_i = 1$ุ $P(y_i = 1 \| \textbf{X}_i)$ ุชุณุงูู $y_i$ ู $P(y_i = 0 \| \textbf{X}_i)$ ุชุณุงูู $1 - y_i$. ุชูุฒูุน ุฅุญุชูุงููุงุช ุงููููุฐุฌ $\hat{P_\boldsymbol{\theta}}$ ูุนุทุงุฉ ูู ูุชุงุฆุฌ ุงูุฏุงูุฉ ุงูุณูููุฉ ุงูุชู ุณุจู ุฃู ุชุนุฑููุง ุนูููุง ูู ุฌุฒุฆูุฉ ุณุงุจูุฉ. ุจุนุฏ ุงูููุงู ุจุชูู ุงูุชุนููุถุงุช ูู ุงููุนุงุฏูุฉุ ูุตู ุฅูู ูุนุงุฏูุฉ ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู:

$$ \text{Average Cross-Entropy Loss} = \frac{1}{n} \sum_i \left(- y_i \ln (f_\hat{\boldsymbol{\theta}}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\hat{\boldsymbol{\theta}}(\textbf{X}_i) \right) $$

$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\theta}} (\text{Average Cross-Entropy Loss}) $$

### ุชุจุฑูุฑ ุงุญุตุงุฆู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู

ูุฏู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู ุฃูุถุงู ุฃุณุณ ุฃุณุงุณูุฉ ูู ุนูู ุงูุฅุญุตุงุก. ุจูุง ุฃู ุงูุฅูุญุฏุงุฑ ุงูููุณุฌุชู ูุชููุน ุฅุญุชูุงูุงุชุ ูู ุณููู ููุง ูููุฐุฌ ููุณุฌุชู ูููููุง ุฃู ูุณุฃูุ "ูุง ูู ุฅุญุชูุงููุฉ ุฃู ูุฐุง ุงููููุฐุฌ ูููู ููุง ุชูู ุงููุฌููุนู ูู ุงูุจูุงูุงุช ุงูุชู ุณุจู ุฃู ุงุทูุน ุนูููุง $ y $ุ" ูููููุง ุจุดูู ุทุจูุนู ุงูุชุนุฏูู ูู ุงููุชุบูุฑุงุช ูููููุฐุฌ ุญุชู ุชููู ุฅุญุชูุงููุฉ ุญุตูููุง ุนูู ุจูุงูุงุชูุง ููุชุงุฆุฌ ูู ุงููููุฐุฌ ุนุงููุฉ ุฌุฏุงู. ุจุงูุฑุบู ูู ุฃููุง ูู ูุซุจุช ุฐูู ูู ูุฐุง ุงููุตูุ ูููู ุชุทุจูู ุฐูู ูุดุงุจู ููุชูููู ูู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนููุ ูุฐุง ุงูุชูุณูุฑ ุงูุฅุญุตุงุฆู ูู *ุฃูุตู ุงุญุชูุงู maximum likelihood* ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู.
### ููุฎุต ุชุจุฑูุฑ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู

ูููู ุงูููู ุฃู ูุชูุณุท ุชุจุงุนุฏ KL ูู ูุชูุณุท ุงููุฑู ุงูููุบุงุฑุชูู ุจูู ุชูุฒูุนุงู $P$ ู $\hat{P_\boldsymbol{\theta}}$ ุชู ูุฒููุง ุจุฅุณุชุฎุฏุงู $P$. ุงูุชูููู ูู ูุชูุณุท ุชุจุงุนุฏ KL ุฃูุถุงู ูููู ูู ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูู. ูููููุง ุงูุชูููู ูู ุชุจุงุนุฏ ูููุฐุฌ ุงูุฅูุญุฏุงุฑ ุงูููุฌุณุชู ุนู ุทุฑูู ุฅุฎุชูุงุฑ ุงููุชุบูุฑุงุช ุงูุชู ุชุตูู ุงูุจูุงูุงุช ุงูุดุงุฆุนู ุจุดูู ุตุญูุญ.

## ุถุจุท ูููููุฐุฌ ุงูููุฌุณุชู

### ุงููุฒูู ุงูุฅุดุชูุงูู ุจุฏูุนุงุช

### ุงููุฒูู ุงูุฅุดุชูุงูู ุงูุนุดูุงุฆู

### ุงููุฒูู ุงูุฅุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉ

### ุงูุชุทุจูู ูู ููุชุจุฉ Scikit-learn

### ููุฎุต ุงูุชุฎุตูุต ูููููุฐุฌ ุงูููุฌุณุชู

## ุชูููู ุงููููุฐุฌ ุงูููุฌุณุชู

### ุงูุญุณุงุณูุฉ

### ุงูููุนูุฉ

### ุญุฏ ูุตู ุงูุชุตููู

### ููุญููุงุช ROC

### AUC

### ููุฎุต ุชูููู ุงููููุฐุฌ ุงูููุณุฌุชู

## ุงูุชุตููู ูุชุนุฏุฏ ุงูุงุญุชูุงูุงุช

### ุชุทุจูู ุนููู: ุจูุงูุงุช Iris

### ุงูุชุตููู ูุชุนุฏุฏ ุงููุชุงุฆุฌ

### ููุฎุต ุงูุชุตููู ูุชุนุฏุฏ ุงูุงุญุชูุงูุงุช

```python

```
<!-- output of python code to be added in ruby tag -->
```ruby

```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter6/viz_quantitative_25_0.png'>
</p>

[๐][link1]

[LogisticRegression]: https://www.youtube.com/watch?v=yIYKR4sgzI8
[Sigmoid]: https://www.youtube.com/watch?v=WcDtwxi7Ick
[ChainRule]: https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction
