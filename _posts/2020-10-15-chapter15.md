---
title: المقايضة بين الإنحياز والتباين
show_title: true
chapter_number: 15
chapter_text: الفصل الخامس عشر
chapter_lessons: [[0, 'مقدمة'], [1, 'تقليل المخاطر والخسائر'], [2, 'إنحياز وتباين النموذج'], [3, 'التحقق المتقاطع']]
chapter_sublessons: [
    [],
    ['المخاطر', 'الخطر التجريبي', 'ملخص المخاطر'],
    ['تحليل الإنحياز والتباين', 'مشتقة تحليل الإنحياز والتبيان', 'مثال: الإنحدار الخطي وموجات الجيب Sine Waves', 'التطبيق العملي للإنحياز والتباين', 'النقاط الأساسية', 'ملخص إنحياز وتباين النموذج'],
    [['تقسيم بيانات التدريب والتحقق والإختبار', 'حجم تقسيم بيانات التدريب والتحقق والإختبار'],'خطأ التدريب و خطأ الإختبار', 'التحقق المتقاطع K-Flod', 'مقايضة الإنحياز والتباين', 'مثال: اختيار النموذج لبيانات تقييم الآيس كريم', 'ملخص التحقق المتقاطع']
]
layout: default
---

## مقدمة

في بعض الأحيان، نختار نموذج بسيط جداً ليمثل البيانات. وفي بعض المرات، نختار نموذجاً معقد، بسبب ضبطنا على الضوضاء في البيانات بدلاً من البيانات نفسها.

لفهم سبب قيامنا بذلك، نقوم بتحليل النموذج بإستخدام أدوات الإحتمالات والإحصاء. هذه الأدوات تسمح لنا بالتعميم من أمثله بسيطة محدودة حتى وصف المهام الأساسية في النمذجة. بشكل خاص، سنستخدم **التوقع Expectation** و **التباين Variance**  لعرض وفهم المقايضة بين الإنحياز والتباين.

## تقليل المخاطر والخسائر

للقيام بالتوقع بإستخدام البيانات، نقوم بتعريف نموذج، إختيار دالة خساره لجميع البيانات، وضبط النموذج مع المتغيرات عن طريق تقليل الخساره. مثلاً،  للقيام بالإنحدار الخطي للمربعات الصغرى، نختار النموذج:

$$ \begin{aligned}
f_\hat{\theta} (x) &= \hat{\theta} \cdot x
\end{aligned} $$

ودالة الخساره:

$$ \begin{split}
\begin{aligned}
L(\hat{\theta}, X, y)
&= \frac{1}{n} \sum_{i}(y_i - f_\hat{\theta} (X_i))^2\\
\end{aligned}
\end{split} $$

كما فعلنا مسبقاً، نستخدم $ \hat{\theta} $ كمصفوفة لمتغيرات النموذج، و $ x $ متّجه تحتوي على سطر من مصفوفة البيانات $ X $، و $ y $ هي مصفوفة للبيانات التي تعلم عليها لتساعد على التوقع. $ X_i $ هي السطر $ i $ من المصفوفة $ X $ و $ y_i $ هي النتيجة رقم $ i $ في المصفوفة $ y $.

لاحظ أن الخساره لكامل البيانات هي متوسط نتائج دالة الخساره لكل سطر فيها. إذا قمنا بتعريف دالة الخسارة التربيعيه:

$$ \begin{aligned}
\ell(y_i, f_\hat{\theta} (x))
&= (y_i - f_\hat{\theta} (x))^2
\end{aligned} $$

إذاً، يمكننا إعادة كتابة متوسط الخساره بشكل أبسط:

$$ \begin{aligned}
L(\hat{\theta}, X, y)
&= \frac{1}{n} \sum_{i} \ell(y_i, f_\hat{\theta} (X_i))
\end{aligned} $$

التعريف في الأعلى يختصر فكرة دالة الخساره؛ إياً كانت دالة الخساره التي نستخدمها، خسارتنا لكامل البيانات هي متوسط الخساره.

بالتقليل من متوسط الخساره، نختار متغيرات النموذج التي تضبطه بناءاً على البيانات التي يتعلم منها. حتى الآن، لم نقل شيئاً عن المجتمع الأحصائي الذي انشأ البيانات. في الحقيقه، نحن مهتمين بإجراء توقعات على جميع المجتمع الأحصائي، ليس فقط البيانات التي رأيناها.

### المخاطر

اذا كانت البيانات التي رأيناها $ X $ و $ y $ تم جمعها بشكل عشوائي، فأنها تعتبر بياناتنا تعتبر متغيرات عشوائية. واذا كانت متغيرات عشوائية، فأن متغيرات النموذج ايضاً عشوائيه، في كل مره نجمع فيها المزيد من البيانات ونضبط النموذج عليها، متغيرات النموذج $ f_\hat{\theta} (x) $ ستتغير قليلاً.

لنفترض أننا قمنا بسحب أحد المدخلات والمخرجات $ z, \gamma $ من مجتمعنا الإحصائي بشكل عشوائي. الخسارة التي يكونها النموذج لهذه القيم هي:

$$ \begin{aligned}
\ell(\gamma, f_\hat{\theta} (z))
\end{aligned} $$

لاحظ أن هذه الخساره هي متغير عشوائي؛ تتغير الخساره عندما تستقبل قيم جديده من $ X $ و $ y $ ونقاط اخرى من $ z, \gamma $ من المجتمع الإحصائي.

**المخاطر Risk** لنموذج $ f_\hat{\theta} $ هي النتيجة المتوقعه من الخساره السابقه لجميع بيانات التدريب $ X $ و $ y $ وجميع النقاط $ z, \gamma $ في المجتمع الإحصائي:

$$ \begin{aligned}
R(f_\hat{\theta}(x)) = \mathbb{E}[ \ell(\gamma, f_\hat{\theta} (z)) ]
\end{aligned} $$

لاحظ ان المخاطر هي توقع لمتغير عشوائي وليست عشوائيه بحد ذاتها. القيمة المتوقعه من رمي حجر النرد ذو الست جهات بشكل عادل وعشوائي هي 3.5 على الرغم من أن عمليات الرمي نفسها عشوائية.

المثال السابق يطلق علية أحياناً **المخاطر الحقيقه True Risk** لأنها تخبرنا عن أداء النموذج على كامل المجتمع الإحصائي. إذا تمكنا من إيجاد المخاطر الحقيقه لجميع النماذج، يمكننا ببساطة اختيار النموذج الأقل مخاطر ونكون متأكدين أن النموذج سيكون أداة أفضل من بقية النماذج على المدى البعيد على دالة الخسارة التي إخترناها.

### الخطر التجريبي

الواقع ليس بهذه السهوله والروعه. إذا قمنا بتغير تعريف التوقع إلى معادة المخاطر الحقيقه، سنحصل على التالي:

$$ \begin{split}
\begin{aligned}
R(f_\hat{\theta})
&= \mathbb{E}[ \ell(\gamma, f_\hat{\theta} (z)) ] \\
&= \sum_\gamma \sum_z \ell(\gamma, f_\hat{\theta} (z)) P(\gamma, z) \\
\end{aligned}
\end{split} $$

للتبسيط، نريد أن نعرف ما تعنيه $ P(\gamma, z) $، وهي توزيع الإحتمالية العام لأي من النقاط في المجتمع الإحصائي. للأسف، إيجاد ذلك ليس سهلاً. لنفترض أننا نريد أن نتوقع قيمة الإكراميه بناءًا على عدد العملاء في الطاولة. ما هي إحتمالية أن طاولة بثلاث أشخاص يقومون بإعطاء إكرامية بقيمة $14.50؟ إذا كنا نعرف توزيع النقاط بشكل دقيقه، فلا نحتاج لجمع بيانات وضبط النموذج، سيكون لدينا معرفة بالقيمة المحتملة للإكراميه لأي عدد من العملاء في الطاولة.

على الرغم أننا لا نعرف بشكل دقيقه توزيع المجتمع الإحصائي، يمكننا توقعه بناءًا على ما أطلعنا عليه في البيانات $ X $ و $ y $. إذا قمنا بسحب قيم ل $ X $ و  $ y $ بشكل عشوائي من المجتمع الإحصائي، توزيع النقاط في $ X $ و $ y $ سيكون مشابه لتوزيع المجتمع الإحصائي. لذا، نعامل $ X $ و $ y $ كمجتمعنا الإحصائي. لذا، إحتمالية الظهور لإي من المدخلات والمخرجات $ X_i $ و $ y_i $ هي $ \frac{1}{n} $ بما أن كل كلاهما يظهر مره واحده من بين كل النقاط $ n $.

ذلك يسمح لنا بحساب **الخطر التجريبي Empirical Risk**، قيمة تقريبه للخطر الحقيقي:

$$ \begin{split}
\begin{aligned}
\hat R(f_\hat{\theta})
&= \mathbb{E}[ \ell(y_i, f_\hat{\theta} (X_i)) ] \\
&= \sum_{i=1}^n \ell(y_i, f_\hat{\theta} (X_i)) \frac{1}{n} \\
&= \frac{1}{n} \sum_{i=1}^n \ell(y_i, f_\hat{\theta} (X_i)) 
\end{aligned}
\end{split} $$

اذا كانت البيانات لدينا ذات حجم كبير وتم سحبها بشكل عشوائي من المجتمع الإحصائي، فأن الخطر التجريبي $ \hat R(f_\hat{\theta}) $ سيكون قريب جداً من الخطر الحقيقي $ R(f_\hat{\theta}) $. يسمح لنا ذلك بإختيار النموذج الذي يقلل من الخطر التجريبي.

لاحظ أن هذا المصطلح هو متوسط دالة الخساره في بداية هذا القسم! بالتقليل من متوسط الخساره، فأننا ايضاً نقلل من الخطر التجريبي. يوضح ذلك لماذا نستخدم في العادة متوسط الخساره كنتيجة لدالة الخساره بدلاً مثلاً من أعلى قيمة للخساره.

### ملخص المخاطر

الخطر الحقيقي لتنبؤ النموذح يوضح لنا خسارة النموذج على المدى البعيد التي سيحصل عليها من المجتمع الإحصائي. بما أننا عادةً لا نستطيع حساب الخطر الحقيقي بشكل مباشر، فأننا نقوم بحساب الخطر التجريبي ونستخدمه لإيجاد النموذج المناسب لتوقعنا. لأن الخطر التجريبي هو متوسط الخساره على البيانات التي رأيناها، فأننا عادةً نقلل من متوسط الخساره عند ضبط النماذج.

## إنحياز وتباين النموذج

رأينا سابقاً أن لدينا مصدرين لإتخاذ قرار الأفضلية بين النماذج.

النموذج قد يكون بسيط جداً. مثلاً، نموذج خطي بسيط لن يتمكن من ضبط البيانات إذا كانت من الدرجة الثانيه. يظهر هذا الخطأ بسبب **الإنحياز Bias** في النموذج.

النموذج قد يقوم بضبط البيانات العشوائية المجوده في البيانات، حتى لو قمنا بضبط بيانات من الدرجة الثانية على نموذج مماثل، سيتوقع النموذج نتائج مختلفة عن الصحيحه. هذا الخطأ يظخر في النموذج بسبب **التباين Variance**. [📝][BaisVariance]

### تحليل الإنحياز والتباين

يمكننا تحليل التعريفات السابقه وفهمها بشكل أوضح بإستخدام معادلة مخاطر النموذج. لنتذكر أن **المخاطر Risk** للنموذج $ f_\hat{\theta} $ هي الخساره المتوقه لجميع بيانات التدريب $ X $ و $ y $ وجميع النقاط المدخله والمخرجة $ z, \gamma $ في المجتمع الإحصائي:

$$ \begin{aligned}
R(f_\hat{\theta}) = \mathbb{E}[ \ell(\gamma, f_\hat{\theta} (z)) ]
\end{aligned} $$

نرمز لعملية إنشاء بيانات المجتمع الإحصائي الحقيقه ب $ f_\theta(x) $. القيمة الناتجة $ \gamma $ تنتج بواسطة بيانات المجتمع الإحصائي اضافة لقيمة عشوائية مشوشة من البيانات: $ \gamma_i = f_\theta(z_i) + \epsilon $. **التشويش العشوائي Random Noise** $ \epsilon $ هي قيمة عشوائية لديها متوسط يساوي صفر: $ \mathbb{E}[\epsilon] = 0 $. [📝][Noise] [📝][Noise2]

إذا استخدمنا الخطأ التربيعي كدالة الخسارة، تصفح المعادلة السابقة كالتالي:

$$ \begin{aligned}
R(f_\hat{\theta}) = \mathbb{E}[ (\gamma - f_\hat{\theta} (z))^2 ]
\end{aligned} $$

مع قليل من عمليات المعالجة الجبريه، يمكن ان نعرف المعادلة السابقة كالتالي:

$$ \begin{aligned}
R(f_\hat{\theta}) = (\mathbb{E}[f_\hat{\theta}(z)] - f_\theta(z))^2 + \text{Var}(f_\hat{\theta}(z)) + \text{Var}(\epsilon)
\end{aligned} $$

المصطلح الأول في المعادلة، $ (\mathbb{E}[f_\hat{\theta}(z)] - f_\theta(z))^2 $، هي التعبير الرياضي للإنحياز في النموذج. (يمكننا القول تقنياً أن المصطلح هو تربيع الإنحياز $ \text{bias}^2 $ ). الإنحياز سيساوي صفر على المدى البعيد إذا كان إختيارنا للنموذج $ f_\hat{\theta}(z) $ يتوقع نفس النتائج التي تم نتجت من خطوات معالجة المجتمع الإحصائي $ f_\theta(z) $. يكون الإنحياز عالي إذا كان النموذج الذي إخترناه يتوقع نتائج خاطئة في خطوات معالجة المجتمع الإحصائي حتى لو كانت كامل المجتمع الإحصائي كبيانات تدريب.

المصطلح الثاني في المعادلة، $ \text{Var}(f_\hat{\theta}(z)) $، هو تباين النموذج. يكون التباين أقل عندما تكون توقعات النموذج لا تتغير كثيراً عند تدريبه على بيانات مختلفة من المجتمع الإحصائي. يكون التباين عالي عندما يكون التغير كبير عند تدريبه على بيانات مختلفه من المجتمع الإحصائي.

المصطلح الاخير في المعادلة، $ \text{Var}(\epsilon) $، يعني الخطأ الغير قابل للإختزال أو التشويش الناتج عند بناء البيانات أو جمعها. يكون أقل عندما يكون بناء البيانات وجمعها دقيق. والعكس يكون أعلى عندما يكون التشويش عالي في البيانات.

### مشتقة تحليل الإنحياز والتبيان

أولاً، نبدأ بمتوسط الخطأ التربيعي:

$$ \mathbb{E}[(\gamma - f_{\hat{\theta}}(z))^2] $$

ثم نوسع التربيع ونطبق خطية التوقع Linearity of Expectation:

$$ =\mathbb{E}[\gamma^2 -2\gamma f_{\hat{\theta}} +f_\hat{\theta}(z)^2 $$

$$ = \mathbb{E}[\gamma^2] - \mathbb{E}[2\gamma f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] $$

لأن $ \gamma $ و $ f_{\hat{\theta}}(z) $ مستقلان (نتائج النموذج وما اطلع عليه من المجتمع الإحصائي لا يعتمدان على بعضهما)، يمكننا القول أن $ \mathbb{E}[2\gamma f_{\hat{\theta}}(z)] = \mathbb{E}[2\gamma]  \mathbb{E}[f_{\hat{\theta}}(z)] $. ثم نقوم بتعويض $ f_\theta(z) + \epsilon $ بدلاً من $ \gamma $:

$$ =\mathbb{E}[(f_\theta(z) + \epsilon)^2] - \mathbb{E}[2(f_\theta(z) + \epsilon)] \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] $$   

للتبسيط أكثر: (لاحظ أن $ \mathbb{E}[f_\theta(z)] = f_\theta(z) $ لأن $ f_\theta(z) $ دالة حتمية، إذا اعطيت نقطة معينة $ z $.)

$$ =\mathbb{E}[f_\theta(z)^2 + 2f_\theta(z) \epsilon + \epsilon^2] - (2f_\theta(z) + \mathbb{E}[2\epsilon]) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] $$ 

تطبيق خطية التوقع مره أخرى:

$$ = f_\theta(z)^2 + 2f_\theta(z)\mathbb{E}[\epsilon] + \mathbb{E}[\epsilon^2] - (2f_\theta(z) + 2\mathbb{E}[\epsilon]) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] $$   

لاحظ أن $ \big( \mathbb{E}[\epsilon] = 0 \big) => \big( \mathbb{E}[\epsilon^2] = \text{Var}(\epsilon) \big) $ لأن $ \text{Var}(\epsilon) = \mathbb{E}[\epsilon^2]-\mathbb{E}[\epsilon]^2 $:

$$ = f_\theta(z)^2 + \text{Var}(\epsilon) - 2f_\theta(z) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] $$ 

يمكننا الآن إعادة كتابة المعادلة كالتالي:

$$ = f_\theta(z)^2 + \text{Var}(\epsilon) - 2f_\theta(z) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)^2] -  \mathbb{E}[f_{\hat{\theta}}(z)]^2 + \mathbb{E}[f_{\hat{\theta}}(z)]^2 $$

لأن $ \mathbb{E}[f_{\hat{\theta}}(z)^2] -  \mathbb{E}[f_{\hat{\theta}}(z)]^2 = Var(f_{\hat{\theta}}(z)) $:

$$ =  f_\theta(z)^2 - 2f_\theta(z) \mathbb{E}[f_{\hat{\theta}}(z)] + \mathbb{E}[f_{\hat{\theta}}(z)]^2 + Var(f_{\hat{\theta}}(z)) + \text{Var}(\epsilon) $$ 


$$ = (f_\theta(z) - \mathbb{E}[f_{\hat{\theta}}(z)])^2 + Var(f_{\hat{\theta}}(z)) + \text{Var}(\epsilon) $$       

$$= \text{bias}^2 + \text{model variance} + \text{noise} $$


لإختيار نموذج يؤدي بشكل ممتاز، نسعى دائماً أن نحصل على مخاطر أقل. ولتقليلها، نحاول تقليل الإنحياز، التباين والتشويش. تقليل التشويش يتطلب عادةً تحسين في طريقة جمع البيانات. للتقليل من الإنحياز والتباين، يجب علينا ضبط النماذج وتعقيدها. النماذج البسيطه يكون فيها الإنحياز مرتفع؛ النماذج المعقدة جداً لديها تباين عالي. هذا هو مفهوم *المقايضة بين الإنحياز والتباين bias-variance tradeoff*، مشكلة أساسية نواجهها دائماً عند إختيار نماذج التنبؤ.

### مثال: الإنحدار الخطي وموجات الجيب Sine Waves

لنفترض أننا نحاول إنشاء نموذج للدالة المتأرجه التالي:

```python
from collections import namedtuple
from sklearn.linear_model import LinearRegression

np.random.seed(42)

Line = namedtuple('Line', ['x_start', 'x_end', 'y_start', 'y_end'])

def f(x): return np.sin(x) + 0.3 * x

def noise(n):
    return np.random.normal(scale=0.1, size=n)

def draw(n):
    points = np.random.choice(np.arange(0, 20, 0.2), size=n)
    return points, f(points) + noise(n)

def fit_line(x, y, x_start=0, x_end=20):
    clf = LinearRegression().fit(x.reshape(-1, 1), y)
    return Line(x_start, x_end, clf.predict(x_start)[0], clf.predict(x_end)[0])

population_x = np.arange(0, 20, 0.2)
population_y = f(population_x)

avg_line = fit_line(population_x, population_y)

datasets = [draw(100) for _ in range(20)]
random_lines = [fit_line(x, y) for x, y in datasets]
```

> قام الكاتب في الكود البرمجي السابق إنشاء بيانات عشوائية لغرض العمل عليها في هذا الجزء من الدرس، الناتج من هذا الكود يظهر في الرسم البياني التالي

```python
plt.plot(population_x, population_y)
plt.title('True underlying data generation process');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_11_0.png'>
</p>

إذا حاولنا أخذ مجموعه بيانات من المجتمع الإحصائي في هذه الرسم، قد نصل إلى الشكل التالي:

```python
xs, ys = draw(100)
plt.scatter(xs, ys, s=10)
plt.title('One set of observed data');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_13_0.png'>
</p>

لنفترض أننا قمنا بسحب مجموعات مختلفة من البيانات من هذا المجتمع الإحصائي وقمنا بضبط نموذج خطي بسيط لكل مجموعة. في الأسفل، قمنا برسم شكل خطي لبيانات المجتمع الإحصائي الناتجة باللون الأزرق و توقعات النموذج باللون الأخضر:


```python
plt.figure(figsize=(8, 5))
plt.plot(population_x, population_y)

for x_start, x_end, y_start, y_end in random_lines:
    plt.plot([x_start, x_end], [y_start, y_end], linewidth=1, c='g')

plt.title('Population vs. linear model predictions');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_15_0.png'>
</p>

الرسمه السابقه توضح أن توقع النموذج الخطي سينتج أخطاء. يمكننا حل هذه الأخطاء بإستخدام الإنحياز، التباين والتشويش الغير قابل للإختزال. نوضح الإنحياز في نموذجنا عن طريق إظهار ان متوسط النموذج الخطي على المدى البعيد سيتوقع نتائج مختلفة عن تلك في المجتمع الإحصائي:

```python
plt.figure(figsize=(8, 5))
xs = np.arange(0, 20, 0.2)
plt.plot(population_x, population_y, label='Population')

plt.plot([avg_line.x_start, avg_line.x_end],
         [avg_line.y_start, avg_line.y_end],
         linewidth=2, c='r',
         label='Long-run average linear model')
plt.title('Bias of linear model')
plt.legend();
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_17_0.png'>
</p>

التباين للنموذج هو مدى إختلاف توقعات النموذج حول متوسط النموذج على المدى البعيد:

```python
plt.figure(figsize=(8, 5))
for x_start, x_end, y_start, y_end in random_lines:
    plt.plot([x_start, x_end], [y_start, y_end], linewidth=1, c='g', alpha=0.8)
    
plt.plot([avg_line.x_start, avg_line.x_end],
         [avg_line.y_start, avg_line.y_end],
         linewidth=4, c='r')

plt.title('Variance of linear model');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_19_0.png'>
</p>

أخيراً، نستعرض الخطأ الغير قابل للإختزال عن طريق إظهار إنحرافات النقاط في بيانات المجتمع الإحصائي:

```python
plt.plot(population_x, population_y)


xs, ys = draw(100)
plt.scatter(xs, ys, s=10)
plt.title('Irreducible error');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_21_0.png'>
</p>

### التطبيق العملي للإنحياز والتباين

في عالمٍ مثالي، نقوم بالتقليل من الخطأ المتوقع من تنبؤ النموذج لجميع النقاط الداخله والخارجه في المجتمع الإحصائي. ولكن، عملياً، نحن لا نعرف خطوات بناء البيانات ولذلك لن نستطيع بشكل دقيق تحديد إنحياز، تباين والخطأ الغير قابل للإختزال للنموذج. بدلاً من ذلك، نستخدم البيانات التي مرت علينا وقيمه قريبه لما في المجتمع الإحصائي.

كما رأينا في الأعلى، الوصول إلى قيمة أقل للخطأ في بيانات التدريب لا يعني أن النموذج سيحصل على قيمه أقل ايضاً في بيانات الإختبار. من السهل الحصول على نموذج بقيمة إنحياز قليله جداً وبالتالي قيمة خطأ أقل في بيانات التدريق عن طريق ضبط النموذج بإستخدام منحنى يمر على جميع بيانات التدريب. ولكن هذا النموذج سيكون تباينه عالي جداً والذي يؤدي إلى خطأ عالي في بيانات الإختبار. على العكس، النموذج الذي يتوقع قيمه ثابته لدية تباين أقل و إنحياز عالي. أساساً، يحدث ذلك بسبب أن خطأ التدريب يعكس إنحياز النموذج ولكن ليس تباينه؛ ولكن خطأ الإختبار يعكس كليهما. للتقليل من خطأ الإختبار، يحتاج نموذجنا أن يحقق إنحياز وتباين قليلان معاً. للقيام بذلك، نحتاج لطريقة لمحاكاة خطأ الإختبار بدون إستخدام بيانات الإختبار. يتم ذلك عادةً بإستخدام التحقق المتقاطع Cross Validation.

### النقاط الأساسية

المقايضة بين الإنحياز والتباين تسمح لنا بشكل دقيق وصف ظواهر النماذج التي رأيناها سابقاً.

يحدث فرط التعميم Underfitting عادةً بسبب الإنحياز؛ فرط التخصيص يحدث بسبب التباين.

جمع المزيد من البيانات يقلل من التباين. مثلاً، تباين نموذج الإنحدار الخطي يقل بمعدل عامل $ 1/n $، هنا $ n $ هي عدد النقاط في البيانات. لذا، مضاعفة حجم البيانات يقلل التباين إلى النصف، وسحب المزيد من البيانات سيقلل التباين إلى صفر. أحدى الخطوات الشائعه هي إختيار نموذج بإنحياز قليل وتباين عالي (مثلاً شبكة عصبيه) ومن ثم سحب المزيد من البيانات للتقليل من تباين النموذج إلى ان يصل لقيمه قليله تمكنه من القيام بتوقعات صحيحه. على الرغم فاعليتها عملياً، إلى ان جمع المزيد من البيانات لهذه النماذج عادةً ما يأخذ وقت و جهد ومصاريف أكثر.

جمع المزيد من البيانات يقلل الإنحياز إذا تم ضبط النموذج على بيانات المجتمع الإحصائي كاملة. إذا لم نتمكن من ضبط النموذج على كامل المجتمع الإحصائي (كما في المثال السابق)، حتى لو كان لدينا عدد لا نهائي من البيانات لن نتمكن من التخلص من الإنحياز.

إضافة خصائص Features مفيدة للبيانات، مثلاً التربيع عندما تكون البيانات الأساسيه من الدرجة الثانية، تقلل من الإنحياز. إضافة خصائص غير مفيدة نادراً منا تزيد من الإنحياز.

إضافة خصائص سواءًا كانت مفيدة أم لا، عادةً ما تزيد من التباين كون كل خاصية نضيفها تزيد من المتغيرات في النموذج. بشكل عام، النماذج ذات المتغيرات الكثيره لديها أشكال مختلفه من المتغيرات ولذلك  لديها تباين أعلى من نماذج بمتغيرات أقل. للزيادة من دقة توقعات النموذج، إضافة خاصية جديده يجب أن تقلل من الإنحياز أكثر من ما تزيد من التباين.

حذف الخصائص عادةً ما يزيد من الإنحياز وقد يتسبب بفرط التعميم. مثلاً، نموذج خطي بسيط لديه إنحياز أعلى من نفس النموذج إذا إضيفت له خاصية تربيعيه. إذا تم إنشاء البيانات بإستخدام التربيع، فأن النموذج الخطي البسيط سيتناسب مع البيانات.

في الرسم البياني التالي، المحور السيني يقيس تعقيد النموذج والمحور الصادي يقيس حجمه. لاحظ أنه كلما زاد تعقيد النموذج، يقل الإنحياز بشكل واضح وبينما يزيد التباين بنفس الشكل. عندما نختار نموذجاً معقد، خطأ الإختبار في البداية يقل ثم يزيد حتى يصل تباين النموذج ويتجاوز الإنحياز أثناء هبوطه:

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_bias_var_plot.png'>
</p>

كما هو واضح في الرسم، النموذج ذو التعقيد العالي قد يصل إلى خطأ قليل في بيانات التدريب ولكن قد يفشل في تعميم هذه النتائج على بيانات الإختبار بسبب تباينه العالي. بشكل آخر، النموذج بتعقيد أقل سيكون ذو تباين أقل ولكن قد يفشل أيضاً في التعميم بسبب إنحيازة العالي. لإختيار النموذج المفيد، يجب أن نصل إلى التوازن بين إنحياز وتباين النموذج.

كلما أضفنا المزيد إلى البيانات، نقوم بتحريك المنحنى في رسمنا البياني إلى اليمين والأسفل، نقلل من الإنحياز والتباين:

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_modeling_bias_var_shift.png'>
</p>

### ملخص إنحياز وتباين النموذج

مقايضة الإنحياز والتبيان تكشف لنا عن مشكلة أساسية في النمذجة. من أجل التقليل من مخاطر النموذج، فعلينا ان نستخدم مزيجاً من هندسة الخصائص، إختيار النماذج والتحقق المتقاطع للوصول إلى توازن بين الإنحياز والتباين.

## التحقق المتقاطع

في الجزء السابق، رأيننا أننا نحتاج لطريقة أدق لمحاكاة خطأ الإختبار للتحكم بالمقايضة بين الإنحياز والتباين. للتأكيد، خطأ التدريب قليل جداً، لأننا نضبط النموذج على بيانات التدريب. نريد إختيار نموذج دون الحاجه لإستخدام بيانات الإختبار، لذا نقسم بيانات التدريب مره أخرى إلى بيانات تحقق. يسمح لنا التحقق المتقاطع بتوقع خطأ النموذج بإستخدام بيانات يطلع عليها مره واحد عن طريق فصل بين البيانات المستخدمه في التدريب والبيانات المستخدمه لإختيار النموذج ودقته.

### تقسيم بيانات التدريب والتحقق والإختبار

أحدى الطرق لتطبيق ذلك على البيانات هي تقسيمها إلى ثلاث أقسام:

- بيانات التدريب: البيانات التي ستستخدم لضبط النموذج.
- بيانات التحقق: البيانات التي ستستخدم لإختيار الخصائص.
- بيانات الإختبار: البيانات التي ستقرر النتيجة النهائية لدقة النموذج.

بعد التقسيم، نختار الخصائص والنموذج بناءًا على:

- لكل خاصية محتملة في البيانات، نقوم بضبطها على النموذج بإستخدام بيانات التدريب. الخطأ في هذا النموذج هو *خطأ التدريب Training Error*.
- تحقق من كل نتيجة خطأ لكل نموذج في بيانات التحقق: يطلق على ذلك *خطأ التحقق Validation Error*. قم بإختيار النموذج صاحب أقل خطأ تحقق. سيكون ذلك هو الخيار النهائي للنموذج وخصائصه.
- قم بحساب *خطأ الإختبار Test Error*، الخطأ في النموذج النهائي على بيانات الإختبار. هذه هي الدقة النهائية للنموذج. محظور لنا من التعديل الخصائص أو النموذج للتقليل من خطأ الإختبار؛ فعل ذلك سيحول بيانات الإختبار إلى بيانات تحقق. بدلاً من ذلك، يجب علينا جمع بيانات جديده للإختبار بعد القيام بالتعديلات على الخصائص أو النموذج.

تسمح لنا هذه الخطوات بشكل دقيق من تحدي دالنموذج الذي نريد إستخدامه بدلاً من إستخدام خطأ التدريب وحده. بإستخدام التحقق المتقاطع، يمكننا إختبار النموذج على بيانات لم يتم ضبطه عليها، محاكاة خطأ الإختبار بدون إستخدام بيانات الإختبار. يسمح لنا ذلك بمعرفة قدرة النموذج على التعامل مع بيانات لم يرها من قبل.

#### حجم تقسيم بيانات التدريب والتحقق والإختبار

تقسيم بيانات التدريب والتحقق والإختبار عادة ما يكون فيه 70%  بيانات تدريب، 15% بيانات تحقق وال 15% الباقية بيانات إختبار. الزياده في عدد بيانات التدريب يساعد على رفع دقة النموذج ولكنه يسبب مزيداً من الإختلاف في بيانات التحقق والإختبار. ذلك بسبب أن بيانات التحقق والإختبار ذات الحجم الصغير غير كافيه لتمثيل البيانات.

### خطأ التدريب و خطأ الإختبار

النموذج يكون غير مفيد لنا إذا فشل في التعامل مع بيانات من المجتمع الإحصائي لم يرها من قبل. خطأ الإختبار يقدم لنا أدق تمثيل لأداء النموذج على بيانات جديده كوننا لا نستخدم بيانات الإختبار في تدريب النموذج أو أختيار الخصائص.

بشكل عام، يقل خطأ التدريب كلما أضفنا تعقيداً أكثر للنموذج بإضافة المزيد من الخصائص أو خطوات معقدة في التوقع. خطأ الإختبار، يقل حتى نقطة معينه ثم يزيد إلى أن يتم ضبطه على بيانات التدريب. ذلك بسبب أنه في البداية، الإنحياز يقل أكثر من زيادة التباين. في النهاية، تتجاوز الزياده في التباين النزول في الإنحياز.

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_cv_train_test_error.png'>
</p>

### التحقق المتقاطع K-Flod

طريقة تقسيم بيانات التدريب والتحقق والإختبار جيدة لمحاكاة نتيجة خطأ الأختبار بإستخدام بيانات التحقق. ولكن، عند التقسيم سيكون حجم البيانات أقل في التدريب. أيضاً، بهذه الطريقة قد يكون خطأ التحقق يميل إلى الزيادة في التباين بسبب أن تقييم الخطأ قد يعتمد بشكل كبير على مكان تواجد القيم في بيانات التدريب أو التحقق.

لمواجهة هذه المشكلة، يمكننا تطبيق تقيم التدريب والتحقق أكثر من مره على نفس البيانات. يتم تقسيم البيانات إلى تقسيمات بعدد *k* متساوية في الحجم (<span style='font-size:1px'>a</span>$ k $ تقسيمات) ، ويتم اعادة تقسيم التدريب والتحقق بعدد *k* مرات. في كل مره، أحدى التقسيمات في *k* تستخدم كبيانات تحقق، والقيم المتبقية *k-1* تستخدم كبيانات تدريب. نقوم بتحديد النتيجة النهائية لخطأ التحقق للنموذج بإيجاد متوسط خطأ التحقق في كل تقسيم. يطلق على هذه الطريقة بـ **K-Flod التحقق المتقاطع K-Flod cross-validation**. [📝][KFlod]

الرسم التالي يشرح الطريقه عند إستخدامها التقسيم 5 مرات:

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_cv_5_fold_cv.jpg'>
</p>

ما يميز هذه الطريقة أن كل نقطة في البيانات تستخدم مره واحد فقط في بيانات التحقق و في بيانات التدريب *k-1* مرات. عادةً، تكون *k* بين 5 و 10، ولكن تبقى قيمة *k* غير ثابته. عندما تكون *k* رقماً صغيراً، الخطأ يكون تباينة قليلاً (الكثير من بيانات التحقق) ولكن لدية إنحياز عالي (القليل من بيانات التدريب). على العكس، عندما تكون قيمة *k* عالية قيمة الخطأ تكون أقل تحيزاً ولكن تباينها عالي.

التحقق المتقاطع <span style='font-size:1px'>a</span>$ k $-flod يأخذ وقتاً أطول من تقسيم بيانات التدريب والتحقق في عملية الحساب لأننا عادةً نحتاج لإعادة ضبط كل نموذج مع كل عملية تقسيم. ولكن، عملية الحساب تعطي نتائج أكثر دقة لخطأ التحقق عن طريق حساب متوسط أكثر من قيمة خطأ لكل نموذج.

مكتبة `scikit-learn` توفر طريقة جاهزة [`sklearn.model_selection.KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) لتطبيق التحقق المتقاطع <span style='font-size:1px'>a</span>$ k $-flod.

### مقايضة الإنحياز والتباين

يساعدنا التحقق المتقاطع في التحكم بمقايطة الإنحياز والتباين بشكل أكثر دقة. حدسياً، خطأ التحقق يقييم خطأ الإختبار عن طريق التحقق من أداء النموذج على بيانات لم تستخدم في التدريب؛ يسمح لنا ذلك بتوقع إنحياز وتباين النموذج. التحقق المتقاطع K-flod يظهر إيضاً حقيقة أن التشويش في بيانات الإختبار فقط تأثر على التشويش في مصطلح الإنحياز والتباين بينما التشويش في بيانات التدريب يأثر على الإنحياز وتباين النموذج. لإختيار النموذج النهائي للبدء بإستخدامه، نختار النموذج ذو قيمة خطأ تحقق أقل.

### مثال: اختيار النموذج لبيانات تقييم الآيس كريم

سنتعرف على عملية إختيار النموذج الكاملة، بالإضافة للتحقق المتقاطع، لإختيار نموذج يتوقع تقييم الآيس كريم بناءًا على حلاوة نكهة الآيس كريم. جميع بيانات الآيس كريم إضافة لمخطط التشتت والتقييم العام بالإضافة إلى حلاوة نكهة الآيس كريم هي كالتالي:

> لتحميل البيانات icecream.csv [اضغط هنا]({{ site.baseurl }}/files/chapter15/icecream.csv).

```python
ice = pd.read_csv('icecream.csv')
transformer = PolynomialFeatures(degree=2)
X = transformer.fit_transform(ice[['sweetness']])

clf = LinearRegression(fit_intercept=False).fit(X, ice[['overall']])
xs = np.linspace(3.5, 12.5, 300).reshape(-1, 1)
rating_pred = clf.predict(transformer.transform(xs))

temp = pd.DataFrame(xs, columns = ['sweetness'])
temp['overall'] = rating_pred

np.random.seed(42)
x_devs = np.random.normal(scale=0.2, size=len(temp))
y_devs = np.random.normal(scale=0.2, size=len(temp))
temp['sweetness'] = np.round(temp['sweetness'] + x_devs, decimals=2)
temp['overall'] = np.round(temp['overall'] + y_devs, decimals=2)

ice = pd.concat([temp, ice])

ice
```

**overall**|**sweetness**| 
:-----:|:-----:|:-----:
3.09|3.6|0
3.17|3.5|1
3.46|3.69|2
...|...|...
5.9|11|6
5.5|11.7|7
5.4|11.9|8

```ruby
309 rows × 2 columns
```

> في الكود البرمجي السابق قام الكاتب بتوليد بيانات عشوائية مقاربة للبيانات الأصلية في ملف ice.csv

```python
plt.scatter(ice['sweetness'], ice['overall'], s=10)
plt.title('Ice Cream Rating vs. Sweetness')
plt.xlabel('Sweetness')
plt.ylabel('Rating');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_cv_12_0.png'>
</p>

بإستخدام خصائص متعددة الحدود من الدرجة العاشرة على 9 مدخلات في ملف البيانات تكون لنا نموذج مثالي لتلك النقاط. للأسف، سيفشل هذا النموذج في التعميم لبيانات لم يراها من قبل في المجتمع الإحصائي.

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

ice2 = pd.read_csv('icecream.csv')
trans_ten = PolynomialFeatures(degree=10)
X_ten = trans_ten.fit_transform(ice2[['sweetness']])
y = ice2['overall']

clf_ten = LinearRegression(fit_intercept=False).fit(X_ten, y)
```

```python
np.random.seed(1)
x_devs = np.random.normal(scale=0.4, size=len(ice2))
y_devs = np.random.normal(scale=0.4, size=len(ice2))

plt.figure(figsize=(10, 5))

plt.subplot(121)
plt.scatter(ice2['sweetness'], ice2['overall'])
xs = np.linspace(3.5, 12.5, 1000).reshape(-1, 1)
ys = clf_ten.predict(trans_ten.transform(xs))
plt.plot(xs, ys)
plt.title('Degree 10 polynomial fit')
plt.ylim(3, 7);

plt.subplot(122)
ys = clf_ten.predict(trans_ten.transform(xs))
plt.plot(xs, ys)
plt.scatter(ice2['sweetness'] + x_devs,
            ice2['overall'] + y_devs,
            c='g')
plt.title('Degree 10 poly, second set of data')
plt.ylim(3, 7);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_cv_15_0.png'>
</p>

بدلاً من الطريقة السابقة، أولاً نقسم البيانات إلى تدريب، تحقق وإختبار بإستخدام الدالة [`sklearn.model_selection.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) من مكتبة `scikit-learn` للقيام بفصل يساوي 70/30% تدريب-إختبار.

```python
from sklearn.model_selection import train_test_split

test_size = 92

X_train, X_test, y_train, y_test = train_test_split(
    ice[['sweetness']], ice['overall'], test_size=test_size, random_state=0)


print(f'  Training set size: {len(X_train)}')
print(f'      Test set size: {len(X_test)}')
```

```ruby
  Training set size: 217
      Test set size: 92
```

نقوم الآن بضبط نماذج الإنحدار متعددة الحدود بإستخدام بيانات التدريب، واحد لكل درجة في متعددة الحدود من 1 إلى 10.

```python
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

# أولاً، نظيف خصائص متعددة الحدود إلى X_train
transformers = [PolynomialFeatures(degree=deg)
                for deg in range(1, 11)]
X_train_polys = [transformer.fit_transform(X_train)
                 for transformer in transformers]

# عرض X_train
# مع متجهة خصائص من الدرجة الخامسة
X_train_polys[4]
```

```ruby
array([[     1.  ,      8.8 ,     77.44,    681.47,   5996.95,  52773.19],
       [     1.  ,     10.74,    115.35,   1238.83,  13305.07, 142896.44],
       [     1.  ,      9.98,     99.6 ,    994.01,   9920.24,  99003.99],
       ...,
       [     1.  ,      6.79,     46.1 ,    313.05,   2125.59,  14432.74],
       [     1.  ,      5.13,     26.32,    135.01,    692.58,   3552.93],
       [     1.  ,      8.66,     75.  ,    649.46,   5624.34,  48706.78]])
```

ثم نقوم بتطبيق التحقق المتقاطع ب 5 تقسيمات على البيانات العشرة. للقيام بذلك، سنقوم بتعريف دالة تقوم بالتالي:

- إستخدام [`KFold.split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) للحصول على 5 تقسيمات في بيانات التدريب. لاحظ ان `split` تعود لنا بمؤشرات `indices` للبيانات في ذلك الفصل.
- لكل عملية فصل، إستخرج لنا الأسطر والأعمدة بناءاً على مؤشرات الفصل `indices` والخصائص.
- إضبط النموذج الخطي على بيانات التدريب المقسمة.
- إحسب متوسط الخطأ التربيعي في بيانات التحقق المقسمة.
- أوجد لنا متوسط الخطأ لكل تقسيمات التحقق المتقاطع.

```python
from sklearn.model_selection import KFold

def mse_cost(y_pred, y_actual):
    return np.mean((y_pred - y_actual) ** 2)

def compute_CV_error(model, X_train, Y_train):
    kf = KFold(n_splits=5)
    validation_errors = []
    
    for train_idx, valid_idx in kf.split(X_train):
        # تقسيم البيانات
        split_X_train, split_X_valid = X_train[train_idx], X_train[valid_idx]
        split_Y_train, split_Y_valid = Y_train.iloc[train_idx], Y_train.iloc[valid_idx]

        # ضبط النموذج على تقسيمة التدريب
        model.fit(split_X_train,split_Y_train)
        
        # حساب متوسط الخطأ التربيعي على بيانات التحقق
        error = mse_cost(split_Y_valid,model.predict(split_X_valid))
        
        validation_errors.append(error)
    
    # متوسط خطأ بيانات التحقق جميعها
    return np.mean(validation_errors)
```

```python
# قمنا بتدريب نموذج إنحدار خطي لكل البيانات وطبقنا التحقق المتقاطع
# حددنا fit_intercept=False
# في نموذج الإنحدار الخطي لأن محول PolynomialFeatures
# يقوم بإضافة عامود الإنحياز بدلاً عنا.

cross_validation_errors = [compute_CV_error(LinearRegression(fit_intercept=False), X_train_poly, y_train)
                     for X_train_poly in X_train_polys]
```

```python
cv_df = pd.DataFrame({'Validation Error': cross_validation_errors}, index=range(1, 11))
cv_df.index.name = 'Degree'
pd.options.display.max_rows = 20
display(cv_df)
pd.options.display.max_rows = 7
```

**Validation Error**| 
:-----:|:-----:
 |Degree
0.32482|1
0.04506|2
0.045418|3
0.045282|4
0.046272|5
0.046715|6
0.04714|7
0.04754|8
0.048055|9
0.047805|10

يمكن أن نلاحظ أنه عندما نرفع قيمة درجة متعددة الحدود، تقل قيمة خطأ التحقق وتزيد مرة أخرى:

```python
plt.figure(figsize=(10, 5))

plt.subplot(121)
plt.plot(cv_df.index, cv_df['Validation Error'])
plt.scatter(cv_df.index, cv_df['Validation Error'])
plt.title('Validation Error vs. Polynomial Degree')
plt.xlabel('Polynomial Degree')
plt.ylabel('Validation Error');

plt.subplot(122)
plt.plot(cv_df.index, cv_df['Validation Error'])
plt.scatter(cv_df.index, cv_df['Validation Error'])
plt.ylim(0.044925, 0.05)
plt.title('Zoomed In')
plt.xlabel('Polynomial Degree')
plt.ylabel('Validation Error')

plt.tight_layout();
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter15/bias_cv_25_0.png'>
</p>

عند مراجعة نتائج خطأ التحقق يظهر لنا أن النموذج المثالي أستخدم خصائص متعددة الحدود من الدرجة الثانية. لذا، نختار نموذج متعددة الحدود من الدرجة الثانية كنموذجنا النهائي وضبطه على جميع بيانات التدريب. ثم نقوم بحساب خطأ النموذج على بيانات الإختبار:

```python
best_trans = transformers[1]
best_model = LinearRegression(fit_intercept=False).fit(X_train_polys[1], y_train)

training_error = mse_cost(best_model.predict(X_train_polys[1]), y_train)
validation_error = cross_validation_errors[1]
test_error = mse_cost(best_model.predict(best_trans.transform(X_test)), y_test)

print('Degree 2 polynomial')
print(f'  Training error: {training_error:0.5f}')
print(f'Validation error: {validation_error:0.5f}')
print(f'      Test error: {test_error:0.5f}')
```

```ruby
Degree 2 polynomial
  Training error: 0.04409
Validation error: 0.04506
      Test error: 0.04698
```

للتطبيق مستقبلاً، توفر مكتبة `scikit-learn` طريقة [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) للقيام أوتوماتيكياً بالتحقق المتقاطع، لذا لا نحتاج أن نقوم بأنفسنا بفصل بيانات التدريب والتحقق. [📝][KFlod2]

أيضاً، لاحظ أن خطأ الإختبار أعلى من خطأ التحقق والذي أيضاً أعلى من خطأ التدريب. خطأ التدريب يجب ان يكون الأقل لأن النموذج تم ضبطة على بيانات التدريب. ضبط النموذج يقلل من متوسط الخطأ التدريبي للبيانات. خطأ التحقق والإختبار عادةً ما تكون أعلى من خطأ التدريب لأن حساب الخطأ فيها تم على بيانات غير معروفة ولم يسبق أن رءاها على النموذح.

### ملخص التحقق المتقاطع

أستخدمنا الوسيلة المفيدة دائماً التحقق المتقاطع للتحكم بمقايضة الإنحياز والتباين. بعد حساب فصل بيانات التدريب، التحقق والإختبار على البيانات الأصلية، نستخدم الخطوات التالية لتدريب وإختيار النموذج:
- لكل مجموعة من الخصائص، نقوم بضبط بيانات التدريب عليها. خطأ النموذج على بيانات التدريب هو *خطأ التدريب Training Error*.
- تحقق من الخطأ لكل نموذج في بيانات التحقق بإستخدام التحقق المتقاطع <span style='font-size:1px'>a</span>$ k $-flod cross validation: الخطأ هنا هو *خطأ التحقق Validation Error*. نختار النموذج الذي حقق أقل قيمة في خطأ التحقق. هنا نكون قد أخترنا خياراتنا النهائية لخصائص النموذج.
- نحسب *خطأ الإختبار Test Error*، خطأ النموذج النهائي على بيانات الإختبار. هذه آخر خطوه لمعرفة دقة النموذج. يجب أن لا نقوم بأي تعديل في النموذج لزيادة خطأ الإختبار؛ القيام بذلك يحول بيانات الإختبار إلى بيانات تحقق. عند القيام بذلك، نحتاج لجمع بيانات إختبار جديده بعد القيام بأي تعديلات في النموذج.



[BaisVariance]: https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/
[Noise]: https://sci2s.ugr.es/noisydata
[Noise2]: statisticshowto.com/statistical-noise/
[KFlod]: https://machinelearningmastery.com/k-fold-cross-validation/
[KFlod2]: https://www.geeksforgeeks.org/cross-validation-machine-learning/