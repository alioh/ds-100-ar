---
title: ุงูููุงุฐุฌ ุงูุฎุทูุฉ
show_title: true
chapter_number: 13
chapter_text: ุงููุตู ุงูุซุงูุซ ุนุดุฑ
chapter_lessons: [[0, 'ููุฏูุฉ'], [1, 'ุงูุชูุจุค ุจุงูุฅูุฑุงููุงุช'], [2, 'ุถุจุท ุงููููุฐุฌ ุงูุฎุทู ุจุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู'], [3, 'ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ'], [4, 'ุงููุฑุจุนุงุช ุงูุตุบุฑู - ููุธูุฑ ููุฏุณู'], [5, 'ุชุทุจูู ุนููู ููุฅูุญุฏุงุฑ ุงูุฎุทู']]
chapter_sublessons: [
    [],
    [['ุชุนุฑูู ูููุฐุฌ ุฎุทู ุจุณูุท', 'ุชููุน ุงููููุฐุฌ ุงูุฎุทู']],
    [['ุถุจุท ุงููููุฐุฌ ุงูุฎุทู ูุน ุงููุฒูู ุงูุฅุดุชูุงูู', 'ููุงุญุธุฉ ุนู ุฅุณุชุฎุฏุงู ุงูุนูุงูุงุช'],'ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท MSE', 'ุชุทุจูู ุงููุฒูู ุงูุฅุดุชูุงูู'],
    ['ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ูุฅูุญุฏุงุฑูุง', 'ุถุจุท ุงููููุฐุฌ ูุน ุงููุฒูู ุงูุฅุดุชูุงูู', 'ุงูุฑุณู ุงูุจูุงูู ูุชูุจุคุงุชูุง', 'ุงุณุชุฎุฏุงู ูุงูู ุงูุจูุงูุงุช', 'ููุฎุต ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ'],
    ['ุงููุฑุจุนุงุช ุงูุตุบุฑู: ุงููููุฐุฌ ุงูุซุงุจุช', 'ุงููุฑุจุนุงุช ุงูุตุบุฑู: ูููุฐุฌ ุฎุทู ุจุณูุท', 'ุงูููุฑู ุงูููุฏุณูู', 'ุงูุฌุจุฑ ุงูุฎุทู', 'ุงููุงุก ุงูุฏุฑุงุณู', 'ุนูุฏูุง ุชุนุชูุฏ ุงููุชุบูุฑุงุช ุฎุทูุงู', 'ุทุฑููุชูู ููุชูููุฑ'],
    ['ูุธุฑู ุนุงูู ุนูู ุงูุจูุงูุงุช', 'ุชูุธูู ุงูุจูุงูุงุช', 'ูุตู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุงูุฅุฎุชุจุงุฑ', 'ุงุณุชูุดุงู ุงูุจูุงูุงุช ูุชุตููุฑูุง', 'ุงูููุงุฐุฌ ุงูุฎุทูู ุงูุจุณูุทู', 'ุชุญููู ุงููุชุบูุฑุงุช', 'ูููุฐุฌ ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ', 'ุชูููู ูููุฐุฌูุง'],
]
layout: default
---

## ููุฏูุฉ

ุงูุขูุ ุจุนุฏ ุงู ุชุนูููุง ุจุดูู ุนุงู ุงุฏูุงุช ูุถุจุท ุงูููุงุฐุฌ ูุน ุฏูุงู ุงูุชููููุ ูุชุญูู ูุทุฑู ุชุญุณูู ุงููููุฐุฌ. ููุชุจุณูุทุ ูู ุงูุณุงุจู ุญุฏุฏูุง ุนูููุง ุนูู ุงููููุฐุฌ ุงูุซุงุจุช: ูููุฐุฌูุง ููุท ูุชููุน ุฑูู ูุงุญุฏ.

ููููุ ุฅุนุทุงุก ูููุฐุฌ ููุฐุง ูููุถูู ูู ูุฑุถูู. ููุฏ ุงููุถูู ุงู ููุถุญ ุงูู ุญุตู ุนูู ูุนูููุงุช ุงูุซุฑ ูุณุจุฉ ุงูุฅูุฑุงููู ูู ุงูุทุงููุงุช ุงูุชู ุฎุฏููุง. ููุงุฐุง ูุง ูุณุชุฎุฏู ุจูุงูุงุชู ุงูุฃุฎุฑูุ ูุซูุงู ุญุฌู ุงูุนููุงุก ูู ุงูุทุงููู ููุฌููุน ุงููุงุชูุฑูุ ูุบุฑุถ ุฌุนู ุงููููุฐุฌ ุงูุซุฑ ูุงุฆุฏุฉ.

ูู ูุฐุง ุงููุตู ุณูุชุนุฑู ุนูู ุงูููุงุฐุฌ ุงูุฎุทูุฉ ูุงูุฐู ูุณูุญ ููุง ุจุฅุณุชุฎุฏุงู ุฌููุน ุงูุจูุงูุงุช ุงูุชู ูุฏููุง ูุฅุฌุฑุงุก ุชููุนุงุช. ุงูููุงุฐุฌ ุงูุฎุทูุฉ ูุง ุชุณุชุฎุฏู ุจูุทุงูู ูุงุณุน ููุทุ ุจู ุงูุถุงู ูุฏููุง ุงุณุณ ูุธุฑูู ุบููุฉ ุจุงููุนูููุงุช ุงูุชู ุชุฌุนููุง ูููู ุงุฏูุงุช ูุณุชูุจููู ููููุงุฐุฌ. ุณูุชุนุฑู ุนูู ูููุฐุฌ ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงูุจุณูุท ุงูุฐู ูุณุชุฎุฏู ูุชุบูุฑ ูุงุญุฏุ ุณูุชุนูู ููู ูุณุชุฎุฏู ุงููุฒูู ุงูุฅุดุชูุงูู ูุถุจุท ุงููููุฐุฌุ ูุงุฎูุฑุงู ุงูุชูุณุน ูู ุงููููุฐุฌ ูุฅุถุงูุฉ ุงููุฒูุฏ ูู ุงููุชุบูุฑุงุช ูู.

## ุงูุชูุจุค ุจุงูุฅูุฑุงููุงุช

ุณุงุจูุงูุ ุชุนุงูููุง ูุน ุจูุงูุงุช ุชุญุชูู ุนูู ุตู ูุงุญุฏ ููู ุทุงููุฉ ูุงู ุงููุถูู ุจุฎุฏูุชูุง ููุฏุฉ ุงุณุจูุน. ุงููุถูู ูุงู ุจุฌูุน ุงูุจูุงูุงุช ููููุงู ุจุงูุชููุน ุจูููุฉ ุงูุฅูุฑุงููุฉ ุงูุชู ุณูุญุตู ุนูููุง ูู ุงููุณุชูุจู:

```python
tips = sns.load_dataset('tips')
tips.head()
```

|**size**|**time**|**day**|**smoker**|**sex**|**tip**|**total\_bill**| 
|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
|2|Dinner|Sun|No|Female|1.01|16.99|0
|3|Dinner|Sun|No|Male|1.66|10.34|1
|3|Dinner|Sun|No|Male|3.5|21.01|2
|2|Dinner|Sun|No|Male|3.31|23.68|3
|4|Dinner|Sun|No|Female|3.61|24.59|4

<br>
```python
sns.distplot(tips['tip'], bins=25);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_tips_3_0.png'>
</p>

ููุง ุชุญุฏุซูุง ุณุงุจูุงูุ ุงุฐุง ุงุฎุชุฑูุง ุงููููุฐุฌ ุงูุซุงุจุช ูุฏุงูุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุทุ ูุฃู ูููุฐุฌูุง ุณูุชููุน ูุชูุณุท ุงูุฅูุฑุงููุงุช:

```python
np.mean(tips['tip'])
```

```ruby
2.9982786885245902
```

ูุนูู ุฐูู ุงู ุนูุฏูุง ูุฃุชู ูุฌููุนุฉ ูู ุงูุฒุจุงุฆู ูููุถูู ุซู ูุณุฃููุง ุงููุถูู ุนู ูุฌููุนู ุงูุฅูุฑุงููุฉ ุงูุชู ุณูุญุตู ุนูููุงุ ูุณูุฌูุจ ุนููู "ุญูุงูู $ \\$3 $"ุ ุงูุงู ูุงู ุนุฏุฏ ุงูุฒุจุงุฆู ููุฌููุน ุงููุงุชูุฑู.

ููููุ ุนูุฏ ุงูุชุญูู ูู ุจุงูู ุงููุชุบูุฑุงุช ูู ุงูุจูุงูุงุชุ ูููููุง ุงู ูููู ุจุชููุนุงุช ุฏูููู ุฅุฐุง ุงุถููุง ุชูู ุงููุชุบูุฑุงุช ูููููุฐุฌ. ูุซูุงูุ ุงูุฑุณู ุงูุจูุงูู ุงูุชุงูู ููุถุญ ูุฌููุน ุงูุฅูุฑุงููู ููุงุฑูุฉ ุจูุจูุบ ุงููุงุชูุฑุฉ ููุธูุฑ ุงูุนูุงูุฉ ุงูุฅูุฌุงุจูุฉ ุจููููุง:

```python
sns.lmplot(x='total_bill', y='tip', data=tips, fit_reg=False)
plt.title('Tip amount vs. Total Bill')
plt.xlabel('Total Bill')
plt.ylabel('Tip Amount');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_tips_7_0.png'>
</p>

ุนูู ุงูุฑุบู ุงู ูุชูุณุท ุงูุฅูุฑุงููู ูู $ \\$3 $ุ ุงุฐุง ูุงูุช ุงูุทุงููุฉ ุทูุจุช ูุง ูุฌููุนู $ \\$40 $ ูู ุงููุฌุจุงุช ูุฃููุง ูุชุฃูุฏูู ุงู ุงููุถูู ุณูุญุตู ุนูู ุงูุซุฑ ูู $ \\$3 $ ูุฃูุฑุงููุฉ. ูุฐุงุ ูุฑูุฏ ุงูุชุนุฏูู ูู ูููุฐุฌูุง ููุชููู ูู ุงูุชููุน ุจูุงุกูุง ุนูู ูุชุบูุฑุงุช ูู ุจูุงูุงุชูุง ุจุฏูุงู ูู ุชููุน ูุชูุณุท ุงูุฅูุฑุงููุฉ. ููููุงู ุจุฐููุ ุณูุณุชุฎุฏู ุงููููุฐุฌ ุงูุฎุทู ุจุฏูุงู ูู ุงูุซุงุจุช.

ููุฑุงุฌุน ุฃููุงู ุงูุฃุฏูุงุช ุงูุชู ูุฏููุง ูุจูุงุก ุงููููุฐุฌ ูุงูุชููุน ูุชุนุฑูู ุจุนุถ ุงูุฑููุฒ ุงูุฌุฏูุฏู ููุชููู ุจุดูู ุงูุถู ูู ุชูุซูู ุงูุนูููุงุช ุงูุฑูุงุถูู ุงูุฅุถุงููู ูู ุงููููุฐุฌ ุงูุฎุทู.

### ุชุนุฑูู ูููุฐุฌ ุฎุทู ุจุณูุท

ูุญู ููุชููู ุจุชููุน ูููุฉ ุงูุฅูุฑุงููู ุจูุงุกูุง ุนูู ูุฌููุน ุงููุงุชูุฑู. ููุฌุนู $ y $ ุชูุซู ูุฌููุน ุงูุฅูุฑุงูููุ ุงููุชุบูุฑ ุงูุฐู ูุฑูุฏ ุงู ูุชููุนู ุงููููุฐุฌ. ู $ x $ ุชูุซู ูุฌููุน ุงููุงุชูุฑูุ ุงููุชุบูุฑ ุงูุฐู ูุฑูุฏ ุงุณุชุฎุฏุงูู ููุชููุน.

ูููู ุจุชุนุฑูู ุงููููุฐุฌ ุงูุฎุทู $ f_\boldsymbol\theta^* $ ุงูุฐู ูุนุชูุฏ ุนูู $ x $:

$$ f_\boldsymbol\theta^* (x) = \theta_1^* x + \theta_0^* $$

ูุชุนุงูู ูุน $ f_\boldsymbol\theta^* (x) $ ุนูู ุงููุง ุงูุฏุงูุฉ ุงูุชู ุฃูุดุฃุช ุงูุจูุงูุงุช.

ุชูุชุฑุถ $ f_\boldsymbol\theta^* (x) $ ุงู $ y $ ูุฏููุง ุนูุงูู ุฎุทูู ูุงููู ูุน $ x $. ููููุ ูู ุจูุงูุงุชูุง ูุง ูุธูุฑ ููุง ุฎุท ูุณุชููู ุจุณุจุจ ูุฌูุฏ ุจุนุถ ุงูุจูุงูุงุช ุงูุนุดูุงุฆูุฉ ุงููุฒุนุฌู $ \epsilon $. ุฑูุงุถูุงูุ ูุฃุฎุฐ ุจุนูู ุงูุฅุนุชุจุงุฑ ูุฐู ุงููุดููู ุจุฅุถุงูุฉ ุงููุตุทูุญ:

$$ y = f_\boldsymbol\theta^* (x) + \epsilon $$

ุฃุฐุง ูุงูุช ุงูุฅูุชุฑุงุถูู ุงู $ y $ ูุฏููุง ุนูุงูุฎ ุฎุทูุฉ ูุงููู ูุน $ x $ุ ูุชูููุง ุจุทุฑููุฉ ูุง ูู ุชููุน ุงููููุฉ ุงูุตุญูุญู ู $ \theta_1^* $ ู $ \theta_0^* $ุ ูุจุดูู ุบูุฑ ุงุนุชูุงุฏู ูู ูููุง ูุฏููุง ุฃู ุนุดูุงุฆูุฉ ูู ุงูุจูุงูุงุชุ ุณูุชููู ูู ุงูุชููุน ุจุดูู ุฏููู ูููุฉ ุงูุฅูุฑุงููุฉ ุงูุชู ุณูุญุตู ุนูููุง ุงููุถูู ูู ุฌููุน ุงูุฒุจุงุฆูุ ูุจุดูู ุฏุงุฆู. ุจุงูุทุจุนุ ูุง ูููููุง ุชูุจูุฉ ุฌููุน ุงููุนุงููุฑ ูู ุงูุญูุงู ุงููุงูุนูุฉ. ุจุฏูุงู ูู ุฐููุ ูุชููุน $ \theta_1^* $ ู $ \theta_0^* $ ุจุฅุณุชุฎุฏุงู ุงูุจูุงูุงุช ูุฌุนู ุชููุนุงุชูุง ุงูุฑุจ ุฏูู ูููุงูุน.

#### ุชููุน ุงููููุฐุฌ ุงูุฎุทู

ุจูุง ุฃููุง ูุง ูุณุชุทูุน ุฅูุฌุงุฏ ูููุฉ $ \theta_1^* $ ู $ \theta_0^* $ ุจุดูู ุฏูููุ ุณููุชุฑุถ ุงู ุจูุงูุงุชูุง ุชุชููุน ูููุฉ ูุฐู ุงููุชุบูุฑุงุช. ูุดูุฑ ููุชููุนุงุช ุจ $ \theta_1 $ ู $ \theta_0 $ุ ูุชููุนูุง ุงูุฐู ูุชู ุถุจุทู ุจุงููููุฐุฌ ุจ $ \hat{\theta_1} $ ู $ \hat{\theta_0} $ุ ู ุงููููุฐุฌ:

$$ f_\boldsymbol\theta (x) = \theta_1 x + \theta_0 $$

ุฃุญูุงูุงู ุณุชุฑู $ h(x) $ ุจุฏูุงู ูู $ f_\hat{\boldsymbol\theta} (x) $ุ ุงู $ h $ ุชุนูู ุงููุฑุถูุฉ *Hypothesis*ุ ููู $ f_\hat{\boldsymbol\theta} (x) $ ูู ูุฑุถูุชูุง ู $ f_{\boldsymbol\theta^*} (x) $.

ูู ุฃุฌู ุชุญุฏูุฏ ูููุฉ $ \hat{\theta_1} $ ู $ \hat{\theta_0} $ุ ูููู ุจุฅุฎุชูุงุฑ ุฏุงูุฉ ุชูููุฉ ูุชูููููุง ุจุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู.

## ุถุจุท ุงููููุฐุฌ ุงูุฎุทู ุจุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู

ูุฑูุฏ ุถุจุท ูููุฐุฌ ุฎุทู ูุชูุจุฃ ุจูููุฉ ุงูุฅูุฑุงููู ูู ูุฌููุน ุงููุงุชูุฑู:

$$ f_\boldsymbol\theta (x) = \theta_1 x + \theta_0 $$

ููุชุณุญูู ููู $ \theta_1 $ ู $ \theta_0 $ุ ูุญุชุงุฌ ุฃููุงู ูุฅุฎุชูุงุฑ ุฏุงูุฉ ุฎุณุงุฑุฉ. ุณูุฎุชุงุฑ ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท MSE:

$$ \begin{split}
\begin{aligned}
L(\boldsymbol\theta, \textbf{x}, \textbf{y})
&= \frac{1}{n} \sum_{i = 1}^{n}(y_i - f_\boldsymbol\theta (x_i))^2\\
\end{aligned}
\end{split} $$

ูุงุญุธ ุงููุง ุนุฏููุง ุนูู ุฏุงูุฉ ุงูุฎุณุงุฑู ูุชูุถูุญ ุฅุถุงูุชูุง ููุชุบูุฑ ูู ุงููููุฐุฌ. ุงูุขูุ $ \textbf{x} $ ูู ูุตูููู ุฃุญุงุฏูุฉ ุงูุจุนุฏ ุชุญุชูู ุนูู ุฌููุน ุงูููุงุชูุฑุ ู $ \textbf{y} $ ูู ูุตูููุฉ ุฃุญุงุฏูุฉ ุงูุจุนุฏ ุชุญุชูู ุนูู ูููุฉ ูู ุฅูุฑุงูููุ ู $ \boldsymbol\theta $ ูู ูุตูููุฉ ุชุญุชูู ุนูู ุงูุชุงูู: $ \boldsymbol\theta = [ \theta_1, \theta_0 ] $.

ูุทูู ุนูู ุฅุณุชุฎุฏุงู ุงููููุฐุฌ ุงูุฎุทู ูุน ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ุจุฅุณู ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ูููุฑุจุนุงุช ุงูุตุบุฑู Least-squares Linear Regression. ูููููุง ุงุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู ูุฅูุฌุงุฏ ูููุฉ $ \boldsymbol\theta $ ุงูุชู ุชููู ุงูุฎุณุงุฑู. [๐][LinearLeastSquares]

#### ููุงุญุธุฉ ุนู ุฅุณุชุฎุฏุงู ุงูุนูุงูุงุช

ุงุฐุง ุณุจู ุฃู ุฑุฃูุช ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ูููุฑุจุนุงุช ุงูุตุบุฑูุ ูุฏ ุชูุงุญุธ ุงููุง ูุณุชุทูุน ุญุณุงุจ ูุนุงูู ุงูุฅุฑุชุจุงุท ูุฅุณุชุฎุฏุงูู ูุชุญุฏูุฏ ูููุฉ $ \theta_1 $ ู $ \theta_0 $. ูุฐู ุทุฑููุฉ ุงุณูู ูุงุณุฑุน ููุญุณุงุจ ุจุฏูุงู ูู ุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู ูู ุฃู ูุนุงุฏููุ ุชูุงูุงู ููุง ูููู ุงุณูู ููุง ุญุณุงุจ ุงููุชูุณุท ุจุฏูุงู ูู ุญุณุงุจ ุงููุฒูู ุงูุฅุดุชูุงูู ูุถุจุท ุงููููุฐุฌ ุงูุซุงุจุช. ุนูู ุฃูุฉ ุญุงูุ ุณูุณุชุฎุฏู ุงููุฒูู ุงูุฅุดุชูุงูู ูุฃููุง ุทุฑููุฉ ุนุงููู ูุชูููู ุงูุฎุณุงุฑู ูุณุชุนูู ูุนูุง ูุงุญูุงู ุนูุฏูุง ูุชุนุฑู ุนูู ููุงุฐุฌ ูุง ูููู ุญุณุงุจ ุฎุณุงุฑุชูุง ุฅุญุตุงุฆูุงู. ุจุงูุฃุตุญุ ูู ูุซูุฑ ูู ุงููุดุงูู ูู ุงูุนุงูู ุงูุญููููุ ุณูุณุชุฎุฏู ุงููุฒูู ุงูุฅุดุชูุงูู ุญุชู ููู ูุงูุช ููุงู ุทุฑู ุฅุญุตุงุฆูู ุชุญูููู ูุฃู ุญุณุงุจูุง ูุฃุฎุฐ ููุชุงู ุงุทูู ูู ุงููุฒูู ุงูุฅุดุชูุงููุ ุฎุงุตุฉ ุนูุฏูุง ุชููู ุงูุจูุงูุงุช ุฐุงุช ุญุฌู ูุจูุฑ.

### ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท MSE

ูุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงููุ ูุญุชุงุฌ ูุญุณุงุจ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ุจุงููุณุจุฉ ู $ \boldsymbol\theta $. ุงูุขู ุจูุง ุงู $ \boldsymbol\theta $ ุนุจุงุฑุฉ ุนู ูุตูููู ุฐุงุช ุทูู 2 ูููุณุช ูููุฉ ุนุฏุฏูุฉ ูุฏุฑุฌุฉ Scalarุ ู $ \nabla_{\boldsymbol\theta} L(\boldsymbol\theta, \textbf{x}, \textbf{y}) $ ุงูุถุงู ูุตูููู ูู ุงูุญุฌู 2. [๐][Scalar]

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol\theta} L(\boldsymbol\theta, \textbf{x}, \textbf{y})
&= \nabla_{\boldsymbol\theta} \left[ \frac{1}{n} \sum_{i = 1}^{n}(y_i - f_\boldsymbol\theta (x_i))^2 \right] \\
&= \frac{1}{n} \sum_{i = 1}^{n}2 (y_i - f_\boldsymbol\theta (x_i))(- \nabla_{\boldsymbol\theta} f_\boldsymbol\theta (x_i))\\
&= -\frac{2}{n} \sum_{i = 1}^{n}(y_i - f_\boldsymbol\theta (x_i))(\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (x_i))\\
\end{aligned}
\end{split} $$

ูุนุฑู ุงู:

$$ f_\boldsymbol\theta (x) = \theta_1 x + \theta_0 $$

ูุฑูุฏ ุญุณุงุจ ูููุฉ $ \nabla_{\boldsymbol\theta} f_\boldsymbol\theta (x_i) $ ูุงูุชู ูู ูุตูููู ุทูููุง 2:

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (x_i)
&= \begin{bmatrix}
     \frac{\partial}{\partial \theta_0} f_\boldsymbol\theta (x_i)\\
     \frac{\partial}{\partial \theta_1} f_\boldsymbol\theta (x_i)
   \end{bmatrix} \\
&= \begin{bmatrix}
     \frac{\partial}{\partial \theta_0} [\theta_1 x_i + \theta_0]\\
     \frac{\partial}{\partial \theta_1} [\theta_1 x_i + \theta_0]
   \end{bmatrix} \\
&= \begin{bmatrix}
     1 \\
     x_i
   \end{bmatrix} \\
\end{aligned}
\end{split} $$

ุงุฎูุฑุงูุ ูุนูุถูุง ูู ูุนุงุฏูุชูุง ุงูุฃุณุงุณูู ููุญุตู ุนูู ุงูุชุงูู:

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol\theta} L(\theta, \textbf{x}, \textbf{y})
&= -\frac{2}{n} \sum_{i = 1}^{n}(y_i - f_\boldsymbol\theta (x_i))(\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (x_i))\\
&= -\frac{2}{n} \sum_{i = 1}^{n} (y_i - f_\boldsymbol\theta (x_i)) \begin{bmatrix} 1 \\ x_i \end{bmatrix} \\
&= -\frac{2}{n} \sum_{i = 1}^{n} \begin{bmatrix}
    (y_i - f_\boldsymbol\theta (x_i)) \\
    (y_i - f_\boldsymbol\theta (x_i)) x_i
    \end{bmatrix} \\
\end{aligned}
\end{split} $$

ูุฐู ูุตูููุฉ ูู ุทูููุง 2 ููู $ (y_i - f_\boldsymbol\theta (x_i)) $ ูููุฉ ุนุฏุฏูุฉ ูุฏุฑุฌู.

### ุชุทุจูู ุงููุฒูู ุงูุฅุดุชูุงูู

ุงูุขูุ ููููู ุจุถุจุท ุงููููุฐุฌ ุงูุฎุทู ุนูู ุจูุงูุงุช ุงูุฅูุฑุงููุงุช ูุชููุน ูููุฉ ุงูุฅูุฑุงููุฉ ูู ูุฌููุน ุงููุงุชูุฑุฉ.

ุฃููุงูุ ูููู ุจุชุนุฑูู ุฏุงูุฉ ูู ุจุงูุซูู ูุญุณุงุจ ุงูุฎุณุงุฑู:

```python
def simple_linear_model(thetas, x_vals):
    '''ูุชูุฌุฉ ูุฐู ุงูุฏุงูู ูู ุงููููู ุงููุชููุนู ูู ุงููููุฐุฌ ุงูุฎุทู'''
    return thetas[0] + thetas[1] * x_vals

def mse_loss(thetas, x_vals, y_vals):
    return np.mean((y_vals - simple_linear_model(thetas, x_vals)) ** 2)
```

ุซู ูุนุฑู ุทุงูุฉ ุชููู ุจุญุณุงุจ ุฎุทูุฉ ุงูุฎุณุงุฑู:

```python
def grad_mse_loss(thetas, x_vals, y_vals):
    n = len(x_vals)
    grad_0 = y_vals - simple_linear_model(thetas, x_vals)
    grad_1 = (y_vals - simple_linear_model(thetas, x_vals)) * x_vals
    return -2 / n * np.array([np.sum(grad_0), np.sum(grad_1)])
```

ุณูููู ุจุฅุณุชุฎุฏุงู ุงูุฏุงูุฉ `minimize` ุงูุชู ุณุจู ุงู ุนุฑููุงูุง ูุชุทุจูู ุงููุฒูู ุงูุฅุดุชูุงูู:

```python
def minimize(loss_fn, grad_loss_fn, x_vals, y_vals,
             alpha=0.0005, progress=True):
        '''
    ุชุณุชุฎุฏู ุงููุฒูู ุงูุฅุดุชูุงูู ููุชูููู ูู ุฏุงูุฉ ุงูุฎุณุงุฑู loss_fn.
    ุชูุชุฌ ููุง ุงูุฏุงูู ุงููููู ุงูุตุบุฑู ู theta_hat (ฮธ^) ุนูุฏูุง ูููู
    ุงูุชุบููุฑ ุงูู ูู 0.001 ุจูู ุงูุชูุฑุงุฑุงุช.
    '''
    theta = np.array([0., 0.])
    loss = loss_fn(theta, x_vals, y_vals)
    while True:
        if progress:
            print(f'theta: {theta} | loss: {loss}')
        gradient = grad_loss_fn(theta, x_vals, y_vals)
        new_theta = theta - alpha * gradient
        new_loss = loss_fn(new_theta, x_vals, y_vals)
        
        if abs(new_loss - loss) < 0.0001:
            return new_theta
        
        theta = new_theta
        loss = new_loss
```

ูุงูุขู ูููู ุจุชุทูุจู ุงููุฒูู ุงูุฅุดุชูุงูู:

```python
thetas = minimize(mse_loss, grad_mse_loss, tips['total_bill'], tips['tip'])
```

```ruby
theta: [0. 0.] | cost: 10.896283606557377
theta: [0.   0.07] | cost: 3.8937622006094705
theta: [0.  0.1] | cost: 1.9359443267168215
theta: [0.01 0.12] | cost: 1.388538448286097
theta: [0.01 0.13] | cost: 1.235459416905535
theta: [0.01 0.14] | cost: 1.1926273731479433
theta: [0.01 0.14] | cost: 1.1806184944517062
theta: [0.01 0.14] | cost: 1.177227251696266
theta: [0.01 0.14] | cost: 1.1762453624313751
theta: [0.01 0.14] | cost: 1.1759370980989148
theta: [0.01 0.14] | cost: 1.175817178966766
```

ููุงุญุธ ุงู ุงููุฒูู ุงูุฅุดุชูุงูู ููุชุฑุจ ููููุฉ $ \hat\theta_0 = 0.01 $ ู $ \hat\theta_0 = 0.14 $. ูููุฐุฌูุง ุงูุฎุทู ุงูุขู:

$$ y = 0.14x + 0.01 $$

ูููููุง ุงุณุชุฎุฏุงู ุงููุชูุฌุฉ ุงูุณุงุจูู ูุฑุณู ุชููุนุงุชูุง ุจุฌุงูุจ ุงูุจูุงูุงุช ุงูุญููููู:

```python
x_vals = np.array([0, 55])
sns.lmplot(x='total_bill', y='tip', data=tips, fit_reg=False)
plt.plot(x_vals, simple_linear_model(thetas, x_vals), c='goldenrod')
plt.title('Tip amount vs. Total Bill')
plt.xlabel('Total Bill')
plt.ylabel('Tip Amount');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_grad_16_0.png'>
</p>

ููุงุญุธ ุงูู ุนูุฏูุง ุชููู ูููุฉ ุงููุงุชูุฑู $ \\$10 $ุ ูุฃู ูููุฐุฌูุง ูุชููุน ุงู ุงููุถูู ุณูุญุตู ุนูู ุฅูุฑุงููุฉ ุจุญูุงูู $ \\$1.50 $. ุจููุณ ุงูุทุฑููุฉุ ุงุฐุง ูุงูุช ูููุฉ ุงููุงุชูุฑู $ \\$40 $ ูุฃู ุงููููุฐุฌ ูุชููุน ุญุตูู ุงููุถูู ุนูู ุฅูุฑุงููุฉ ุจูููุฉ $ \\$6.00 $.

## ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ

ูููุฐุฌูุง ุงูุฎุทู ุงูุจุณูุท ูููุฒุฉ ุฅุถุงููุฉ ุนู ุงููููุฐุฌ ุงูุซุงุจุชุ ุงูููุฒู ูู ุงุณุชุฎุฏุงูู ุงูุจูุงูุงุช ููุชููุน. ููููุ ูุง ูุฒุงู ุงููููุฐุฌ ูุญุฏูุฏ ูููู ูุณุชุฎุฏู ูุชุบูุฑ ูุงุญุฏ ูู ุจูุงูุงุชูุง. ุงููุซูุฑ ูู ุงูุจูุงูุงุช ุชุญุชูู ุนูู ุงูุซุฑ ูู ูุชุบูุฑ ููู ููููุฏ ููุฅุณุชุฎุฏุงูุ ููููู ููุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ ุงูุฅุณุชูุงุฏู ูู ุฐูู. ูุซูุงูุ ููุฃุฎุฐ ุงูุจูุงูุงุช ุงูุชุงููู ูุฃููุงุน ุงูุณูุงุฑุงุช ููุนูููุงุช ุตุฑู ุงููููุฏ ุจุงูููู ููู ุฌุงููู (Milage Per Gallon MPG):

```python
mpg = pd.read_csv('mpg.csv').dropna().reset_index(drop=True)
mpg
```

| car name                  | origin | model year | \.\.\. | displacement | cylinders | mpg    |        |
|:-------------------------:|:------:|:----------:|:------:|:------------:|:---------:|:------:|:------:|
| chevrolet chevelle malibu | 1      | 70         | \.\.\. | 307          | 8         | 18     | 0      |
| buick skylark 320         | 1      | 70         | \.\.\. | 350          | 8         | 15     | 1      |
| plymouth satellite        | 1      | 70         | \.\.\. | 318          | 8         | 18     | 2      |
| \.\.\.                    | \.\.\. | \.\.\.     | \.\.\. | \.\.\.       | \.\.\.    | \.\.\. | \.\.\. |
| dodge rampage             | 1      | 82         | \.\.\. | 135          | 4         | 32     | 389    |
| ford ranger               | 1      | 82         | \.\.\. | 120          | 4         | 28     | 390    |
| chevy s\-10               | 1      | 82         | \.\.\. | 119          | 4         | 31     | 391    |


```ruby
392 rows ร 9 columns
```

> ูุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช mpg.csv [ุงุถุบุท ููุง]({{ site.baseurl }}/files/chapter13/mpg.csv).

ูุจุฏู ููุง ุฃู ุงูุซุฑ ูู ูุชุบูุฑ ูุฃุซุฑ ุนูู ุตุฑู ุงูุณูุงุฑู ูููููุฏ. ูุซูุงูุ ูุจุฏู ุงู ุตุฑู ุงูููุฏ ููู ุนูุฏูุง ุชุฒูุฏ ููุฉ ุงูุญุตุงู ููุณูุงุฑู:

```python
sns.lmplot(x='horsepower', y='mpg', data=mpg);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_multiple_6_0.png'>
</p>

ููููุ ุงูุณูุงุฑุงุช ุงูุชู ูู ุงูุณููุงุช ุงูุฃุฎูุฑู ูุฏููุง ุตุฑู ูููุฏ ุงูุถู ุจุดูู ุนุงู ุนู ุงูุณูุงุฑุงุช ุงููุฏููู:

```python
sns.lmplot(x='model year', y='mpg', data=mpg);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_multiple_8_0.png'>
</p>

ูุธูุฑ ุฃู ุจุฃููุงููุง ุงูุญุตูู ุนูู ูุชุงุฆุฌ ุงูุซุฑ ุฏูุฉ ูููููุฐุฌ ุฅุฐุง ุงุณุชุทุนูุง ุฅุณุชุฎุฏุงู ููุฉ ุงูุญุตุงู ูุณูุฉ ุตูุงุนุฉ ุงูุณูุงุฑู ููุชูุจุค ุนู ูููุฉ ุตุฑู ุงููููุฏ ุจุงูููู ููู ุฌุงููู MPG. ุจุงูุฃุตุญุ ูุจุฏู ุงู ุงููููุฐุฌ ุงููุซุงูู ูุฃุฎุฐ ุจุนูู ุงูุฅุนุชุจุงุฑ ุฌููุน ุงููุชุบูุฑุงุช ุงูุฑูููู ูู ุจูุงูุงุชูุง. ูููููุง ุชูุณูุน ูููุฐุฌูุง ุงูุฎุทู ุฐู ุงููุชุบูุฑ ุงููุงุญุฏ ููุชููู ูู ุงูุชูุจุค ุจูุงุกูุง ุนูู ุฃู ุนุฏุฏ ูู ุงููุชุบูุฑุงุช.

ุฐูุฑูุง ุงู ุชุนุฑูู ุงููููุฐุฌ ูุงูุชุงูู:

$$ f_\boldsymbol\theta (\textbf{x}) = \theta_0 + \theta_1 x_1 + \ldots + \theta_p x_p $$

ูููุง $ \textbf{x} $ ุชูุซู ูุชูุฌูู Vector ุชุญุชูู ุนูู ุนุฏุฏ $ p $ ูู ุงููุชุบูุฑุงุช ูุณูุงุฑู ูุงุญุฏู. ุงููููุฐุฌ ุงูุณุงุจู ูููู ุงูุชุงููุ "ุฎุฐ ุฃูุซุฑ ูู ูุชุบูุฑ ุนู ุงูุณูุงุฑูุ ุงุถุฑุจูู ุจูุฒู Weight ูุนููุ ุซู ุงุฌูุนูู ูุนุงู ููููุงู ุจุชููุน ุตุฑููุฉ ุงูุณูุงุฑู ูููููุฏ ุจุงูููู ููู ุฌุงููู".

> ุชูุฌุฏ ุงููุงุน ูุชุนุฏุฏุฉ ูู ุทุฑู ุชูุซูู ุงูุฃุฑูุงู: [๐][Vector]
> <p align="center"> 
> <img src='{{ site.baseurl }}/img/chapter13/scalar-vector-matrix.png'>
> </p>
> - ุนุฏุฏ Scalar: ุฑูู ุตุญูุญ ูุซูุงู $ 7, -4, 0.345 $.
> - ุงููุชูุฌู Vector: ูู ูุตูููุฉ ุฃุฑูุงู ุงุญุงุฏูุฉ ุงูุฃุจุนุงุฏุ ุชููู ุงูุง ูู ุตู ูุงุญุฏ ุฃู ุนุงููุฏ ูุงุญุฏ.
> - ูุตูููู Matrix: ูุตูููู ุฃุฑูุงู ุชุญุชูู ุนูู ุงูุซุฑ ูู ุตู ุฃู ุนุงููุฏ.
>


ูุซูุงูุ ุฅุฐุง ุงุฑุฏูุง ุงุฌุฑุงุก ุชููุน ูุฃูู ุณูุงุฑู ูู ุจูุงูุชูุง ุจุฅุณุชุฎุฏุงู ููุฉ ุงูุญุตุงูุ ุงููุฒูุ ูุณูุฉ ุงูุตูุงุนูุ ูุณูููู ุดูู ุงููุชูุฌูู $ \textbf{x} $ ูุงูุชุงูู:

| model year |  weight | horsepower    |        |
|:-------------------------:|:------:|:----------:|:------:|
| 70 | 3504.0      | 130.0         | 0 |

ูู ูุฐุง ุงููุซุงู ุงุจูููุง ุงุณูุงุก ุงูุนูุงููุฏ ููุชูุถูุญุ ูููู ุชุฐูุฑ ุงู $ \textbf{x} $ ุชุญุชูู ููุท ุนูู ุงูููู ุงูุฑูููุฉ ูู ุงูุฌุฏูู ุงูุณุงุจู: $ \textbf{x} = [130.0, 3504.0, 70] $.

ุงูุขูุ ุณูููู ุจุชุนุฑูู ุทุฑููู ุญุณุงุจูู ุณุชุณูู ุงูุนูููุงุช ุงูุญุณุงุจูู ุงููุงุฏูู. ุณูููู ุจุฅุถุงูุฉ ุงูุฑูู $ 1 $ ุฅูู ุงููุชุฌูู $ \textbf{x} $ุ ูุณูููู ุดูู ุงูุตู ูุงูุชุงูู:

| model year |  weight | horsepower    |  bias  ||
|:-------------------------:|:------:|:----------:|:------:|:--:|
| 70 | 3504.0      | 130.0         | 1 |0|

ุงูุขูุ ูุงุญุธ ูุง ุณูุญุฏุซ ููุนูููุฉ ุงูุณุญุงุจูู ููููุฐุฌูุง:

$$ \begin{split}
\begin{aligned}
f_\boldsymbol\theta (\textbf{x})
&= \theta_0 + \theta_1 x_1 + \ldots + \theta_p x_p \\
&= \theta_0 (1) + \theta_1 x_1 + \ldots + \theta_p x_p \\
&= \theta_0 x_0 + \theta_1 x_1 + \ldots + \theta_p x_p \\
f_\boldsymbol\theta (\textbf{x}) &= \boldsymbol\theta \cdot \textbf{x}
\end{aligned}
\end{split} $$

ูููุง $ \boldsymbol\theta \cdot \textbf{x} $ ูู ูุชูุฌู ูุญุงุตู ุถุฑุจ $ \boldsymbol\theta $ ู $ \textbf{x} $. ุตูููุช ุงููุชูุฌูุงุช ูุงููุตูููุงุช ููุชุงุจุฉ ุงูุชุฑููุจุงุช ุงูุฎุทูู ููุฐูู ููู  ููุงุณุจุฉ ุฌุฏุงู ููููุฐุฌูุง ุงูุฎุทู. ููููุ ูุฌุจ ุนููู ูู ุงูุขู ูุตุงุนุฏูุง ุชุฐูุฑ ุงู $ \boldsymbol\theta \cdot \textbf{x} $ ูู ุญุงุตู ุถุฑุจ ูุชูุฌู ุจุฃุฎุฑู. ูููู ุฃูุถุงู ููุฒุน ุงูุดูุ ุชูุณูุน ุนูููุฉ ุถุฑุจ ุงููุชุฌูุชูู  ุฅูู ุนูููุฉ ุฌูุน ูุถุฑุจ ูุจุณุทู.

ุงูุขูุ ูููู ุจุชุนุฑูู ุงููุตูููู $ \textbf{X} $ ูุงูุชู ุณุชููู ุงููุตูููุฉ ุงูุชู ุชุญุชูู ุนูู ุฌููุน ุงููุงุน ุงูุณูุงุฑุงุช ูุตูููุ ูุฃูู ุนุงููุฏ ูู ูููุฉ ุงูุชุญูุฒ Bias. ูุซูุงูุ ูุฐู ุฃูู ุฎูุณ ุงุณุทุฑ ูู ุงููุตูููู $ \textbf{X} $:

| model year |  weight | horsepower    |  bias  ||
|:-------------------------:|:------:|:----------:|:------:|:--:|
| 70 | 3504.0      | 130.0         | 1 |0|
| 70 | 3693.0      | 165.0         | 1 |1|
| 70 | 3436.0	      | 150.0         | 1 |2|
| 70 | 3433.0	      | 150.0         | 1 |3|
| 70 | 3449.0	     | 140.0         | 1 |4|

ููุชุฐููุฑ ูุฑู ุฃุฎุฑูุ ุงููุตูููุฉ ุงูุญูููู $ \textbf{X} $ ููุท ุชุญุชูู ุนูู ุงูููู ุงูุฑูููู ูู ุงูุฌุฏูู ุงูุณุงุจู.

ูุงุญุธ ุงู $ \textbf{X} $ ุชุญุชูู ุนูู ุฃูุซุฑ ูู ููุชุฌูู $ \textbf{x} $ ููู ุจุนุถูุง ุงูุจุนุถ. ููููู ุงููุตู ูุงุถุญุงูุ ูููู ุจุชุนุฑูู $ \textbf{X}\_{i} $ ูุงูุชู ุชุฑูุฒ ูููุชูุฌู ูู ุงูุตู ุฑูู $ i $ ูู ุงููุตูููู $ \textbf{X} $. ูููู ุจุชุนุฑูู $ X_{i,j} $ ูุงูุชู ุชูุซู ุงููููู ุฐุงุช ุงูุฑูู $ j $ ูู ุงูุตู ุฐู ุงูุฑูู $ i $ ูู ุงููุตูููู $ \textbf{X} $. ูุฐุงุ $ \textbf{X}\_{i} $ ูู ูุชูุฌู ุฐุงุช ุงุจุนุงุฏ $ p $ ู $ $ \textbf{X}\_{i,j} $ ูู ุนุฏุฏ. $ $ \textbf{X} $ ูู ูุตูููุฉ $ n \times p $ุ ูููุง $ n $ ูู ุนุฏุฏ ุงูุณูุงุฑุงุช ูุฏููุง ู $ p $ ูู ุนุฏุฏ ุงููุชุบูุฑุงุช ููู ุณูุงุฑู.

ูุซูุงูุ ูู ุงูุฌุฏูู ุงูุณุงุจู ูุฏููุง $ \textbf{X}\_4 = [1, 140, 3449, 70] $ ู $ X_{4,1} = 140 $ ูุฐุง ุงูุฑููุฒ ูู ูููู ุนูุฏ ุชุนุฑูู ุฏูุงู ุงูุฎุณุงุฑู ูุฃููุง ุณูุญุชุงุฌ ุฅูู ููุง ุงููููุชูู $ \textbf{X} $ุ ูุตูููุฉ ุงูุจูุงูุงุช ุงููุฏุฎูู ูููููุฐุฌุ ู $ y $ุ ูุชูุฌู ุตุฑู ุงููููุฏ ุจุงูููู ููู ุฌุงููู.

> - $ \textbf{X} $ ูู ูุตูููู Matrix.
> - $ \textbf{x} $ ูู ูุชูุฌู Vector ููู ููุง ูู ุตู ุนูู ุญุฏู. ูุซูุงู ุงูุณุทุฑ ุงูุซุงูู: $ [1, 165.0, 3693.0, 70] $.
> - $ j $ ูู ุฑูู ุตุญูุญ Scalar ูุซูุงู ูุฒู ุงูุณูุงุฑู ูู ุงูุตู ุงูุซุงูุซ $ 3436.0 $.

### ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ูุฅูุญุฏุงุฑูุง

ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ุชุฃุฎุฐ ูุชูุฌู ุจูุฒู $ \boldsymbol\theta $ ู ูุฏุฎูุงุช ุนูู ุดูู ูุตูููู $ \textbf{X} $ุ ู ูุชูุญู ูุตุฑู ุงููููุฏ ุจุงูููู ููู ุฌุงููู ููู ุณูุงุฑู $ \textbf{y} $:

$$ \begin{split}
\begin{aligned}
L(\boldsymbol\theta, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_{i}(y_i - f_\boldsymbol\theta (\textbf{X}_i))^2\\
\end{aligned}
\end{split} $$

ุงูุฌุฏูุง ูุณุจูุงู ูุดุชูุฉ ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ุจุงููุณุจุฉ ู $ \boldsymbol\theta $:

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol\theta} L(\boldsymbol\theta, \textbf{X}, \textbf{y})
&= -\frac{2}{n} \sum_{i}(y_i - f_\boldsymbol\theta (\textbf{X}_i))(\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (\textbf{X}_i))\\
\end{aligned}
\end{split} $$

ูุนุฑู ุฃูุถุงู ุงู:

$$ \begin{split}
\begin{aligned}
f_\boldsymbol\theta (\textbf{x}) &= \boldsymbol\theta \cdot \textbf{x} \\
\end{aligned}
\end{split} $$

ููููู ุจุญุณุงุจ $ \nabla_{\boldsymbol\theta} f_\boldsymbol\theta (\textbf{x}) $. ุนูููุฉ ุงูุญุณุงุจ ุงุณูู ูู ุงููุชููุน ูุฃู $ \boldsymbol\theta \cdot \textbf{x} = \theta_0 x_0 + \ldots + \theta_p x_p $ ุฅุฐุงู $ \frac{\partial}{\partial \theta_0}(\boldsymbol\theta \cdot \textbf{x}) = x_0 $ ู $ \frac{\partial}{\partial \theta_1}(\boldsymbol\theta \cdot \textbf{x}) = x_1 $ ุฅูู ุขุฎุฑู:

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (\textbf{x})
&= \nabla_{\boldsymbol\theta} [ \boldsymbol\theta \cdot \textbf{x} ] \\
&= \begin{bmatrix}
     \frac{\partial}{\partial \theta_0} (\boldsymbol\theta \cdot \textbf{x}) \\
     \frac{\partial}{\partial \theta_1} (\boldsymbol\theta \cdot \textbf{x}) \\
     \vdots \\
     \frac{\partial}{\partial \theta_p} (\boldsymbol\theta \cdot \textbf{x}) \\
   \end{bmatrix} \\
&= \begin{bmatrix}
     x_0 \\
     x_1 \\
     \vdots \\
     x_p
   \end{bmatrix} \\
\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (\textbf{x}) &= \textbf{x}
\end{aligned}
\end{split} $$

ุงุฎูุฑุงูุ ูููู ุจุฅุฏุฎุงู ุงููุชูุฌู ูุญุณุงุจ ุงูุฎุทูู:

$$ \begin{split}
\begin{aligned}
\nabla_{\boldsymbol\theta} L(\boldsymbol\theta, \textbf{X}, \textbf{y})
&= -\frac{2}{n} \sum_{i}(y_i - f_\boldsymbol\theta (\textbf{X}_i))(\nabla_{\boldsymbol\theta} f_\boldsymbol\theta (\textbf{X}_i))\\
&= -\frac{2}{n} \sum_{i}(y_i - \boldsymbol\theta \cdot \textbf{X}_i)(\textbf{X}_i)\\
\end{aligned}
\end{split} $$

ุชุฐูุฑ ุฃูู ุจูุง ุงู $ y_i - \boldsymbol\theta \cdot \textbf{X}\_i $ ูู ุนุฏุฏ ู $ \textbf{X}_i $ ูู ูุชูุฌู ุฐุงุช $ p $ ุงุจุนุงุฏุ ุงูุฎุทูู $ \nabla\_{\boldsymbol\theta} L(\boldsymbol\theta, \textbf{X}, \textbf{y}) $ ูู ุงูุถุงู ูุชูุฌู ุฐุงุช $ p $ ุงุจุนุงุฏ.

ุฑุฃููุง ููุณ ูุฐุง ุงูููุน ูู ุงููุชุงุฆุฌ ุนูุฏูุง ูููุง ุจุญุณุงุจ ุฎุทูุฉ ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ููุฌุฏูุง ุงููุง ุซูุงุฆูุฉ ุงูุฃุจุนุงุฏ ุจูุง ุงู $ \boldsymbol\theta $ ูุงูุช ุซูุงุฆูุฉ ุงูุฃุจุนุงุฏ.

### ุถุจุท ุงููููุฐุฌ ุงูุฎุทู ูุน ุงููุฒูู ุงูุฅุดุชูุงูู

ูููููุง ุงูุขู ุฅุฏุฎุงู ุงูุฎุณุงุฑู ููุดุชูุชูุง ุฅูู ุฏุงูุฉ ุงููุฒูู ุงูุฅุดุชูุงูู. ูุงูุนุงุฏูุ ุณูููู ุจุชุนุฑูู ุงููููุฐุฌุ ุฏุงูุฉ ุงูุฎุณุงุฑู ู ุฏุงูุฉ ุงููุฒูู ุงูุฅุดุชูุงูููุดุชูุชูุง ูู ุจุงูุซูู:

```python
def linear_model(thetas, X):
    '''Returns predictions by a linear model on x_vals.'''
    return  X @ thetas

def mse_loss(thetas, X, y):
    return np.mean((y - linear_model(thetas, X)) ** 2)

def grad_mse_loss(thetas, X, y):
    n = len(X)
    return -2 / n * (X.T @ y  - X.T @  X @ thetas)
```

ุงูุขูุ ุจุจุณุงุทู ูููููุง ุงุฏุฎุงู ุฏูุงููุง ุฅูู ุงููุฒูู ุงูุฅุดุชูุงูู:

```python
X = (mpg_mat
     .loc[:, ['bias', 'horsepower', 'weight', 'model year']]
     .to_numpy())
y = mpg_mat['mpg'].to_numpy()

thetas = minimize(mse_loss, grad_mse_loss, X, y)
print(f'theta: {thetas} | loss: {mse_loss(thetas, X, y):.2f}')
```

```ruby
theta: [ 0.  0.  0.  0.] | cost: 610.47
theta: [ 0.    0.    0.01  0.  ] | cost: 178.95
theta: [ 0.01 -0.11 -0.    0.55] | cost: 15.78
theta: [ 0.01 -0.01 -0.01  0.58] | cost: 11.97
theta: [-4.   -0.01 -0.01  0.63] | cost: 11.81
theta: [-13.72  -0.    -0.01   0.75] | cost: 11.65
theta: [-13.72  -0.    -0.01   0.75] | cost: 11.65
```

> ุงุณุชุฎุฏู ุงููุงุชุจ ูู ุงูููุฏ ุงูุจุฑูุฌู ุงูุณุงุจู ุงูุฏุงูุฉ `minimize` ููู ูุฎุชููู ููููุงู ุนู ุงูุณุงุจููุ ุงุฌุฑู ุนูููุง ุงูุชุนุฏููุงุช ุงูุชุงููู:
>
> ```python
> from scipy.optimize import minimize as sci_min
> def minimize(loss_fn, grad_loss_fn, X, y, progress=True):
>     '''
>     ุชุณุชุฎุฏู ุฏุงูุฉ ูู ููุชุจุฉ scipy ููุชูููู ูู ุฎุณุงุฑุฉ ุงูุฏุงูู loss_fun 
>     ุจุฅุณุชุฎุฏุงู ูููุฐุฌ ูู ุงููุฒูู ุงูุฅุดุชูุงูู
>     '''
>    theta = np.zeros(X.shape[1])
>    iters = 0
>    
>    def objective(theta):
>        return loss_fn(theta, X, y)
>    def gradient(theta):
>        return grad_loss_fn(theta, X, y)
>    def print_theta(theta):
>        nonlocal iters
>        if progress and iters % progress == 0:
>            print(f'theta: {theta} | loss: {loss_fn(theta, X, y):.2f}')
>        iters += 1
>        
>    print_theta(theta)
>    return sci_min(
>        objective, theta, method='BFGS', jac=gradient, callback=print_theta,
>        tol=1e-7
>    ).x
> ```

ุจูุงุกูุง ุนูู ุงููุฒูู ุงูุฅุดุชูุงููุ ูุฃู ูููุฐุฌูุง ุงูุฎุทู ูู ูุงูุชุงูู:

$$ y = -13.72 - 0.01x_2 + 0.75x_3 $$

### ุงูุฑุณู ุงูุจูุงูู ูุชูุจุคุงุชูุง

ููู ุฃุฏู ูููุฐุฌูุงุ ููุงุญุธ ุงู ุงูุฎุณุงุฑู ููุช ุจุดูู ูุจูุฑ (ูู 610 ุญุชู 11.6). ูููููุง ุทุจุงุนุฉ ูุชุงุฆุฌ ุชููุน ุงููููุฐุฌ ุจุฌุงูุจ ุงููุชุงุฆุฌ ุงูุญูููู:

```python
reordered = ['predicted_mpg', 'mpg', 'horsepower', 'weight', 'model year']
with_predictions = (
    mpg
    .assign(predicted_mpg=linear_model(thetas, X))
    .loc[:, reordered]
)
with_predictions
```

| model year | weight | horsepower | mpg    | predicted\_mpg |        |
|:----------:|:------:|:----------:|:------:|:--------------:|:------:|
| 70         | 3504   | 130        | 18     | 15\.447125     | 0      |
| 70         | 3693   | 165        | 15     | 14\.053509     | 1      |
| 70         | 3436   | 150        | 18     | 15\.785576     | 2      |
| \.\.\.     | \.\.\. | \.\.\.     | \.\.\. | \.\.\.         | \.\.\. |
| 82         | 2295   | 84         | 32     | 32\.4569       | 389    |
| 82         | 2625   | 79         | 28     | 30\.354143     | 390    |
| 82         | 2720   | 82         | 31     | 29\.726608     | 391    |

```ruby
392 rows ร 5 columns
```

ุจูุง ุงููุง ุฃูุฌุฏูุง $ \boldsymbol\theta $ ูู ุงููุฒูู ุงูุฅุดุชูุงููุ ูููููุง ุงู ูุชุฃูุฏ ูู ุงูู ุณุทุฑ ูู ุจูุงูุงุชูุง ุงู $ \boldsymbol\theta \cdot \textbf{X}_0 $ ุชุทุงุจู ุชููุนูุง ุงูุณุงุจู:

```python
print(f'Prediction for first row: '
      f'{thetas[0] + thetas[1] * 130 + thetas[2] * 3504 + thetas[3] * 70:.2f}')
```

```ruby
Prediction for first row: 15.45
```

ูููููุง ุฑุณู ุงููุฑู ุจูู ุชููุนูุง ูุงููุชูุฌุฉ ุงูุญูููู (ุงููุชูุฌุฉ ุงูุญูููู - ุงูุชููุน):

```python
resid = y - linear_model(thetas, X)
plt.scatter(np.arange(len(resid)), resid, s=15)
plt.title('Residuals (actual MPG - predicted MPG)')
plt.xlabel('Index of row in data')
plt.ylabel('MPG');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_multiple_34_0.png'>
</p>

ูุจุฏู ูุงุถุญุงู ุงู ูููุฐุฌูุง ูุนุทู ุชููุนุงุช ููุทููู ููุซูุฑ ูู ุงูุณูุงุฑุงุชุ ุนูู ุงูุฑุบู ุงู ุจุนุถ ุงููุชุงุฆุฌ ูุงู ุงููุฑู ูููุง ุฃูุซุฑ ูู 10 ููู ููู ุฌุงููู (ุจุนุถ ุงูุณูุงุฑุงุช ูุฏููุง ุงูู ูู 10!). ูุฏ ููููุง ุงูุซุฑ ูุนุฑูุฉ ูุณุจุฉ ุงูุฎุท ุจูู ุงูุชููุน ูุงููุชูุฌุฉ ุงูุตุญูุญู ูุตุฑู ุงููููุฏ:

```python
resid_prop = resid / with_predictions['mpg']
plt.scatter(np.arange(len(resid_prop)), resid_prop, s=15)
plt.title('Residual proportions (resid / actual MPG)')
plt.xlabel('Index of row in data')
plt.ylabel('Error proportion');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_multiple_36_0.png'>
</p>

ูุธูุฑ ููุง ุงู ุงููููุฐุฌ ุนุงุฏุฉู ุงุจุนุฏ ุจุญุฏูุฏ 20% ูู ุงููููู ุงูุตุญูุญู.

### ุงุณุชุฎุฏุงู ูุงูู ุงูุจูุงูุงุช

ูุงุญุธ ุงู ูู ูุซุงููุง ุญุชู ุงูุขูุ ุงููุตูููู $ \textbf{X} $ ุชุญุชูู ุนูู ุงุฑุจุน ุนูุงููุฏ: ุฃูููุง ูุญุชูู ุนูู ุงููููู 1 ูู ุฌููุน ุงูุตูููุ ุนุงููุฏ ููุฉ ุงูุณูุงุฑู ุจุงูุญุตุงูุ ูุฒููุงุ ูุณูุฉ ุงูุตูุงุนู. ููููุ ูุณูุญ ููุง ุงููููุฐุฌ ุจุฅุณุชุฎุฏุงู ุงูุซุฑ ูู ูุฐุง ุงูุนุฏุฏ:

$$ \begin{aligned}
f_\boldsymbol\theta (\textbf{x}) &= \boldsymbol\theta \cdot \textbf{x}
\end{aligned} $$

ุนูุฏูุง ูุถูู ุงููุฒูุฏ ูู ุงูุนูุงููุฏ ููุตูููุชูุงุ ูููู ุจุชูุณูุน $ \boldsymbol\theta $ ูุชุญุชูู ุนูู ูุชุบูุฑ ููู ุนุงููุฏ ูู $ \textbf{x} $. ุจุฏูุงู ูู ุงุฎุชูุงุฑ ููุท 3 ุนูุงููุฏ ุฑูููู ูุฅุฌุฑุงุก ุงูุชูุจุคุ ููุงุฐุง ูุง ูุณุชุฎุฏู ุฌููุน ุงูุนูุงููุฏ ุงูุณุจุนูุ

```python
cols = ['bias', 'cylinders', 'displacement', 'horsepower',
        'weight', 'acceleration', 'model year', 'origin']
X = mpg_mat[cols].to_numpy()
mpg_mat[cols]
```

| origin | model year | acceleration | weight | horsepower | displacement | cylinders | bias   |        |
|:------:|:----------:|:------------:|:------:|:----------:|:------------:|:---------:|:------:|:------:|
| 1      | 70         | 12           | 3504   | 130        | 307          | 8         | 1      | 0      |
| 1      | 70         | 11\.5        | 3693   | 165        | 350          | 8         | 1      | 1      |
| 1      | 70         | 11           | 3436   | 150        | 318          | 8         | 1      | 2      |
| \.\.\. | \.\.\.     | \.\.\.       | \.\.\. | \.\.\.     | \.\.\.       | \.\.\.    | \.\.\. | \.\.\. |
| 1      | 82         | 11\.6        | 2295   | 84         | 135          | 4         | 1      | 389    |
| 1      | 82         | 18\.6        | 2625   | 79         | 120          | 4         | 1      | 390    |
| 1      | 82         | 19\.4        | 2720   | 82         | 119          | 4         | 1      | 391    |

```ruby
392 rows ร 8 columns
```

```python
thetas_all = minimize(mse_loss, grad_mse_loss, X, y, progress=10)
print(f'theta: {thetas_all} | loss: {mse_loss(thetas_all, X, y):.2f}')
```

```ruby
theta: [0. 0. 0. 0. 0. 0. 0. 0.] | loss: 610.47
theta: [-0.5  -0.81  0.02 -0.04 -0.01 -0.07  0.59  1.3 ] | loss: 11.22
theta: [-17.23  -0.49   0.02  -0.02  -0.01   0.08   0.75   1.43] | loss: 10.85
theta: [-17.22  -0.49   0.02  -0.02  -0.01   0.08   0.75   1.43] | loss: 10.85
```

ูููุงู ููุชูุฌุฉ ุงููุฒูู ุงูุฅุดุชูุงููุ ูุฃู ุงููููุฐุฌ ุงูุฎุทู ูููููุง ุชุนุฑููู ูุงูุชุงูู:

$$ y = -17.22 - 0.49x_1 + 0.02x_2 - 0.02x_3 - 0.01x_4 + 0.08x_5 + 0.75x_6 + 1.43x_7 $$

ููุงุญุธ ุงู ุฎุณุงุฑุชูุง ููุช ูู 11.6 ุจุฅุณุชุฎุฏุงู ุซูุงุซ ุนูุงููุฏ ุฅูู 10.85 ุจุฅุณุชุฎุฏุงู ุฌููุน ุงูุนูุงููุฏ ุงูุฑูููุฉ ุงูุณุจุนู ูู ุจูุงูุงุชูุง. ุณูุฑู ูุณุจุฉ ุงูุฎุทุฃ ูู ุงูุฑุณู ุงูุจูุงูู ููู ุงูุชููุนูู ุงูุณุงุจู (ุจุฅุณุชุฎุฏุงู ุซูุงุซ ุนูุงููุฏ) ูุงูุฌุฏูุฏ (ุจุฅุณุชุฎุฏุงู ุณุจุน ุนูุงููุฏ):

```python
resid_prop_all = (y - linear_model(thetas_all, X)) / with_predictions['mpg']
plt.figure(figsize=(10, 4))
plt.subplot(121)
plt.scatter(np.arange(len(resid_prop)), resid_prop, s=15)
plt.title('Residual proportions using 3 columns')
plt.xlabel('Index of row in data')
plt.ylabel('Error proportion')
plt.ylim(-0.7, 0.7)

plt.subplot(122)
plt.scatter(np.arange(len(resid_prop_all)), resid_prop_all, s=15)
plt.title('Residual proportions using 7 columns')
plt.xlabel('Index of row in data')
plt.ylabel('Error proportion')
plt.ylim(-0.7, 0.7)

plt.tight_layout();
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_multiple_42_0.png'>
</p>

ุนูู ุงูุฑุบู ุงู ุงููุฑู ุจุณูุทุ ููุงุญุธ ุงู ุงููุฑู ุงูู ุนูุฏูุง ูุณุชุฎุฏู ุงูุณุจุน ุนูุงููุฏ. ููุง ุงููููุฐุฌูู ุงูุถู ูู ุงููููุฐุฌ ุงูุซุงุจุชุ ููุง ููุถุญ ุงูุฑุณู ุงูุจูุงูู ุงูุชุงูู:

```python
constant_resid_prop = (y - with_predictions['mpg'].mean()) / with_predictions['mpg']
plt.scatter(np.arange(len(constant_resid_prop)), constant_resid_prop, s=15)
plt.title('Residual proportions using constant model')
plt.xlabel('Index of row in data')
plt.ylabel('Error proportion')
plt.ylim(-1, 1);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter13/linear_multiple_44_0.png'>
</p>

ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงูุซุงุจุช ูุตูุช ููู ูุชุงุฆุฌ ุงูุฎุทุฃ ุฅูู ุฃูุซุฑ ูู 75% ููุซูุฑ ูู ุงูุณูุงุฑุงุช!

### ููุฎุต ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ

ุชุนุฑููุง ุนูู ุงููููุฐุฌ ุงูุฎุทู ููุฅูุญุฏุงุฑ. ุนูู ุนูุณ ุงููููุฐุฌ ุงูุซุงุจุชุ ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ูุฃุฎุฐ ุฎุตุงุฆุต ูู ุงูุจูุงูุงุช ุจุงูุญุณุจุงู ุนูุฏ ุงุฌุฑุงุก ุงูุชููุนุงุชุ ููุง ูุฌุนูู ุงูุซุฑ ูุงุฆุฏุฉ ุนูุฏูุง ูููู ูุฏููุง ุนูุงูุงุช ูู ุจูุงูุงุชูุง.

ุฎุทูุงุช ุถุจุท ุงููููุฐุฌ ูู ุงูููุชุฑุถ ุงู ุชููู ูุงุถุญู ุงูุขู:
- ุงุฎุชูุงุฑ ุงููููุฐุฌ.
- ุงุฎุชูุงุฑ ุฏุงูุฉ ุงูุฎุณุงุฑุฉ.
- ุชูููู ุฏุงูุฉ ุงูุฎุณุงุฑู ุจุฅุณุชุฎุฏุงู ุงููุฒูู ุงูุฅุดุชูุงูู.

ูู ุงููููุฏ ูุนุฑูุฉ ุงู ุจุฅููุงููุง ุงูุชุนุฏูู ุนูู ุงุญุฏ ุงูููููุงุช ุฏูู ุงูุฃุฎุฑู. ูู ูุฐุง ุงูุฌุฒุกุ ุชุนุฑููุง ุนูู ุงููููุฐุฌ ุงูุฎุทู ุฏูู ุงูุชุบูุฑ ูู ุฏุงูุฉ ุงูุฎุณุงุฑู ุฃู ุงุณุชุฎุฏุงู ุฎูุงุฑุฒููุงุช ุชูููู ุงุฎุฑู. ุนูู ุงูุฑุบู ุงู ุงูููุฐุฌู ูุฏ ุชููู ูุนูุฏูุ ูููู ุงุณูู ุงูุชุฑููุฒ ุนูู ูููู ูุงุญุฏ ููุท ูู ูู ูุฑูุ ุซู ุฌูุน ุงูููููุงุช ูุน ุจุนุถูุง ุงูุจุนุถ.

## ุงููุฑุจุนุงุช ุงูุตุบุฑู - ููุธูุฑ ููุฏุณู

### ุงููุฑุจุนุงุช ุงูุตุบุฑู: ุงููููุฐุฌ ุงูุซุงุจุช

### ุงููุฑุจุนุงุช ุงูุตุบุฑู: ูููุฐุฌ ุฎุทู ุจุณูุท

### ุงูููุฑู ุงูููุฏุณูู

### ุงูุฌุจุฑ ุงูุฎุทู

### ุงููุงุก ุงูุฏุฑุงุณู

### ุนูุฏูุง ุชุนุชูุฏ ุงููุชุบูุฑุงุช ุฎุทูุงู

### ุทุฑููุชูู ููุชูููุฑ

## ุชุทุจูู ุนููู ููุฅูุญุฏุงุฑ ุงูุฎุทู

### ูุธุฑู ุนุงูู ุนูู ุงูุจูุงูุงุช

### ุชูุธูู ุงูุจูุงูุงุช

### ูุตู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุงูุฅุฎุชุจุงุฑ

### ุงุณุชูุดุงู ุงูุจูุงูุงุช ูุชุตููุฑูุง

### ุงูููุงุฐุฌ ุงูุฎุทูู ุงูุจุณูุทู

### ุชุญููู ุงููุชุบูุฑุงุช

### ูููุฐุฌ ุงูุฅูุญุฏุงุฑ ุงูุฎุทู ุงููุชุนุฏุฏ

### ุชูููู ูููุฐุฌูุง




[LinearLeastSquares]: https://towardsdatascience.com/linear-regression-using-least-squares-a4c3456e8570
[Scalar]: https://www.youtube.com/watch?v=rcDXQ-5H8mk
[Vector]: https://www.mathsisfun.com/algebra/scalar-vector-matrix.html