---
title: هندسة الخصائص
show_title: true
chapter_number: 14
chapter_text: الفصل الرابع عشر
chapter_lessons: [[0, 'مقدمة'], [1, 'بيانات وول مارت'], [2, 'التنبؤ بتقييم الآيس كريم']]
chapter_sublessons: [
    [],
    ['ضبط النموذج بإستخدام مكتبة Scikit-learn', 'استخدام One-Hot Encoding', 'طريقة One-Hot Encoding في مكتبة Scikit-learn', 'ضبط النموذج بإستخدام البيانات المُعدله', 'تقييم النموذج', 'ملخص بيانات وول مارت'],
    ['خصائص متعددة الحدود', 'الإنحدار متعدد الحدود', 'زيادة الدرجة', 'ملخص التنبؤ بتقييم الآيس كريم'],
]
layout: default
---

## مقدمة

**هندسة الخصائص Feature Engineering** تعني إنشاء وإضافة خصائص جديده للبيانات لزيادة دقة وتعقيد النموذج. 

حتى الآن، قمنا فقط بتطبيق الإنحدار الخطي بإستخدام خصائص كميه كمُدخلات، استخدمنا القيمه الكميه لمجموع الفاتوره للتنبؤ بمبلغ الإكراميه. ولكن، احتوت بيانات الإكراميات على بيانات اسمية، مثل ايام الأسبوع ونوع الوجبه. هندسة الخصائص تسمح لنا بتحويل البيانات الأسميه إلى كميه لإستخدامها في الإنحدار الخطي.

تسمح لنا هندسة الخصائص ايضاً بإستخدام نموذج الإنحدار الخطي لإجراء انحدار متعدد الحدود عن طريق إنشاء متغيرات جديده في بياناتنا.

## بيانات وول مارت

في عام 2014، قامت ول مارت بنشر بعض بيانات بيعها كجزء من مسابقه للتنبؤ بالمبيعات الأسبوعيه في فروعها. أخذنا جزء من هذه البيانات وإستخدمناها في المثال التالي:

```python
walmart = pd.read_csv('walmart.csv')
walmart
```

**MarkDown**|**Unemployment**|**Fuel\_Price**|**Temperature**|**IsHoliday**|**Weekly\_Sales**|**Date**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
No Markdown|8.106|2.572|42.31|No|24924.5|05-02-10|0
No Markdown|8.106|2.548|38.51|Yes|46039.49|12-02-10|1
No Markdown|8.106|2.514|39.93|No|41595.55|19-02-10|2
...|...|...|...|...|...|...|...
MarkDown2|6.573|3.601|62.99|No|22764.01|12-10-12|140
MarkDown2|6.573|3.594|67.97|No|24185.27|19-10-12|141
MarkDown1|6.573|3.506|69.16|No|27390.81|26-10-12|142


```ruby
143 rows × 7 columns
```

> وول مارت Walmart هي أحدى أكبر متاجر التجزئة والمنتجات اليوميه في الولايات المتحدة الأمريكية.  
> لتحميل البيانات walmart.csv [اضغط هنا]({{ site.baseurl }}/files/chapter14/walmart.csv).


تحتوي البيانات على عدد من الخصائص المثيره للإعجاب، إضافة إلى معلومات ما إذا كان الأسبوع يحتوي على إجازة في العامود `IsHoliday`، ومعدل البطاله في الأسبوع `Unemployment` وأي من العروض الخاصه التي قدمها المتجر في ذلك الأسبوع `MarkDown`.

الهدف هو بناء نموذج يتوقع المتغير `Weekly_Sales` بإستخدام باقي المعلومات في جدول البيانات. بإستخدام نموذج الإنحدار الخطي يمكننا بشكل مباشر إستخدام الأعمدة `Temperature`، `Fuel_Price` و `Unemployment` كونها تحتوي على بيانات كمية.

### ضبط النموذج بإستخدام مكتبة Scikit-learn

في الفصول السابقه تعلمنا كيف نوجد مشتقة دالة التكلفه وإستخدام النزول الإشتقاقي لضبط النموذج. لفعل ذلك، كان علينا تعريف دوال في بايثون لبناء النموذج، دالة التكلفة، مشتقة دالة التكلفة، وخوارزمية النزول الإشتقاقي. رغم أهمية ذلك لعرض وفهم المفاهيم في بناء النماذج، في هذا الفصل سنستخدم مكتبة متخصصه بتعلم الآله أسمها `scikit-learn` والتي تسمح لنا بضبط النماذج بإستخدام أكواد برمجية أقل.

مثلاً، لضبط نموذج إنحدار خطي متعدد بإستخدام البيانات الكمية في قاعدة بيانات وول مارت، نقوم أولاً ببناء مصفوفة ثنائية الأبعاد بإستخدام NumPy تحتوي على المتغيرات المستخدمه لبناء نموذج التنبؤ و مصفوفة أحادية الأبعاد تحتوي على القيم التي نريد التنبؤ عنها:

```python
numerical_columns = ['Temperature', 'Fuel_Price', 'Unemployment']
X = walmart[numerical_columns].to_numpy()
X
```

```ruby
array([[ 42.31,   2.57,   8.11],
       [ 38.51,   2.55,   8.11],
       [ 39.93,   2.51,   8.11],
       ..., 
       [ 62.99,   3.6 ,   6.57],
       [ 67.97,   3.59,   6.57],
       [ 69.16,   3.51,   6.57]])
```

```python
y = walmart['Weekly_Sales'].to_numpy()
y
```

```ruby
array([ 24924.5 ,  46039.49,  41595.55, ...,  22764.01,  24185.27,
        27390.81])
```

ثم نستدعي [كلاس](/ds-100-ar/translation-reference/) الإنحدار الخطي `LinearRegression` من مكتبة `scikit-learn` ([مزيد من التفاصيل اضغط هنا](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression))، نعرّف بالنموذج، ثم نستدعي دالة الضبط `fit` بإستخدام المتغيرات `X` للتنبؤ بقيمة `y`.

لاحظ أننا في السابق أحتجنا لإضافة عامود جديد يدوياً يحتوي على القيمة $ 1 $ للمصفوفه `X` "التحيز" لنقوم بتطبيق الإنحدار الخطي. هذه المره، `scikit-learn` ستتكفل بفعل ذلك لتختصر علينا الوقت:

```python
from sklearn.linear_model import LinearRegression

simple_classifier = LinearRegression()
simple_classifier.fit(X, y)
```

```ruby
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
```

رائع! عندما نستدعي `.fit`، مكتبة `scikit-learn` أوجدت المتغيرات التي تقلل من دالة تكلفة المربعات الصغرى. يمكننا الإطلاع على المتغيرات كالتالي:

```python
simple_classifier.coef_, simple_classifier.intercept_
```

```ruby
(array([ -332.22,  1626.63,  1356.87]), 29642.700510138635)
```

لحساب تكلفة المتوسط التربيعي، يمكننا أن نطلب من المصنف Classifier التنبؤ للقيم المدخله في `X` ومقارنة النتيجة مع البيانات الحقيقه في `y`:

```python
predictions = simple_classifier.predict(X)
np.mean((predictions - y) ** 2)
```

```ruby
74401210.603607252
```

يظهر أن الخطأ التربيعي المتوسط يبدو مرتفعاً جداً. على الأرجح يكون سبب ذلك هو المتغيرات الثلاثه الكميه التي استخدمناها وأرتباطها الضعيف بالمبيعات الأسبوعيه.

لدينا متغيران آخران من الممكن أن يكون لهما فائده في التنبؤ: عامود `IsHoliday` و `MarkDown`. مخطط الصندوق في الأسفل يوضح أن الإجازات قد يكون لها أرتباط مع المبياعات الأسبوعيه:

```python
sns.pointplot(x='IsHoliday', y='Weekly_Sales', data=walmart);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter14/feature_one_hot_14_0.png'>
</p>

يظهر ان هناك رابط بين الأنواع المختلفه للعروض في العامود `MarkDown` وبين كمية المبيعات في الأسابيع المختلفه:

```python
markdowns = ['No Markdown', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']
plt.figure(figsize=(7, 5))
sns.pointplot(x='Weekly_Sales', y='MarkDown', data=walmart, order=markdowns);
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter14/feature_one_hot_16_0.png'>
</p>

ولكن، كلا الأعمدة `IsHoliday` و `MarkDown` هي بيانات أسميه، وليست كميه، لذا لا يمكن أن نستخدمها كما هي الآن في الأنحدار.

### استخدام One-Hot Encoding

لحسن الحظ، يمكننا أن نستخدم **One-Hot Encoding** على هذه البيانات الأسمية لتحويلها لكمية. التحويل يتم كالتالي: ننشأ عامود جديد لكل قيمه مختلفه في العامود الأسمي. يحتوي كل عامود على الرقم $ 1 $ إذا كانت العامود هو تلك القيمه الموجوده في العامود الأسمي، وغير ذاك تكون القيمه $ 0 $، مثلاً في العامود `MarkDown`:

```python
walmart[['MarkDown']]
```

**MarkDown**| 
:-----:|:-----:
No Markdown|0
No Markdown|1
No Markdown|2
...|...
MarkDown2|140
MarkDown2|141
MarkDown1|142

```ruby
143 rows × 1 columns
```

يحتوي العامود على ست قيم مختلفه وهي:  No Markdown، MarkDown1، MarkDown2، MarkDown3، MarkDown4، و MarkDown5. نقوم بإنشاء عامود لكل قيمه وينتج لنا ست أعمدة جديده. ثم نقوم بتعبئة كل عامود بصفر أو واحد بنفس الطريقة التي شرحناها مسبقاً.

```python
from sklearn.feature_extraction import DictVectorizer

items = walmart[['MarkDown']].to_dict(orient='records')
encoder = DictVectorizer(sparse=False)
pd.DataFrame(
    data=encoder.fit_transform(items),
    columns=encoder.feature_names_
)
```

**MarkDown=No Markdown**|**MarkDown=MarkDown5**|**MarkDown=MarkDown4**|**MarkDown=MarkDown3**|**MarkDown=MarkDown2**|**MarkDown=MarkDown1**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
1|0|0|0|0|0|0
1|0|0|0|0|0|1
1|0|0|0|0|0|2
...|...|...|...|...|...|...
0|0|0|0|1|0|140
0|0|0|0|1|0|141
0|0|0|0|0|1|142

```ruby
143 rows × 6 columns
```

لاحظ أن أول سطر في البيانات هي No Markdown، لذا فقط آخر عامود في الجدول الذي تم أنشاءه تحتوي على الرقم $ 1 $. وأيضاً، آخر سطر في البيانات يحتوي على MarkDown1 مما جعل أو عامود يحتوي على $ 1 $.

كل سطر في الجدول يحتوي على عامود واحد لدية الرقم $ 1 $، والبقيه ستحتوي على $ 0 $. الأسم "One-Hot" يعني أن عامود واحد سيكون ذو قيمه (يحتوي على 1).


> مثال آخر تم ذكره في الفصل السابق:
>
> <p align="center"><a href="https://alioh.github.io/DSND-Notes-2/"><img src='{{ site.baseurl }}/img/chapter13/one-hot-encoding.jpeg'></a>
> </p> 
>

### طريقة One-Hot Encoding في مكتبة Scikit-learn

لنقوم بعملية One-Hot Encoding يمكننا إستخدام الكلاس [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) من مكتبة `scikit-learn`. لنستخدم هذه الكلاس، نحتاج لتحويل ال DataFrame إلى مصفوفه تحتوى على قواميس. الكلاس DictVectorizer يقوم بشكل تلقائي بعملية One-Hot Encoding للأعمدة الأسميه (والتي يجب أن تكون نصوص) ولا يقوم بتغير أي عامود يحتوي على قيم كميه: 

```python
from sklearn.feature_extraction import DictVectorizer

all_columns = ['Temperature', 'Fuel_Price', 'Unemployment', 'IsHoliday',
               'MarkDown']

records = walmart[all_columns].to_dict(orient='records')
encoder = DictVectorizer(sparse=False)
encoded_X = encoder.fit_transform(records)
encoded_X
```

```ruby
array([[  2.57,   1.  ,   0.  , ...,   1.  ,  42.31,   8.11],
       [  2.55,   0.  ,   1.  , ...,   1.  ,  38.51,   8.11],
       [  2.51,   1.  ,   0.  , ...,   1.  ,  39.93,   8.11],
       ..., 
       [  3.6 ,   1.  ,   0.  , ...,   0.  ,  62.99,   6.57],
       [  3.59,   1.  ,   0.  , ...,   0.  ,  67.97,   6.57],
       [  3.51,   1.  ,   0.  , ...,   0.  ,  69.16,   6.57]])
```

لتتبين لك الفكره والشكل الجديد للبيانات، يمكننا عرضها مع أسماء الأعمدة:

```python
pd.DataFrame(data=encoded_X, columns=encoder.feature_names_)
```

**Unemployment**|**Temperature**|**MarkDown=No Markdown**|**MarkDown=MarkDown5**|**...**|**MarkDown=MarkDown1**|**IsHoliday=Yes**|**IsHoliday=No**|**Fuel\_Price**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
8.106|42.31|1|0|...|0|0|1|2.572|0
8.106|38.51|1|0|...|0|1|0|2.548|1
8.106|39.93|1|0|...|0|0|1|2.514|2
...|...|...|...|...|...|...|...|...|...
6.573|62.99|0|0|...|0|0|1|3.601|140
6.573|67.97|0|0|...|0|0|1|3.594|141
6.573|69.16|0|0|...|1|0|1|3.506|142

```ruby
143 rows × 11 columns
```

الأعمدة الكمية `Fuel price`، `Temperature` و `Unemployment` بقيت كما هي كأرقام. الأعمدة الأسميه `IsHoliday` و `MarkDown` تم تطبيق ال One-Hot Encoding عليها. عندما نستخدم المصفوفة الجديده للبيانات لضبط نموذج الإنحدار الخطي، سنقوم بإيجاد متغير جديد لكل عامود في البيانات. بما أن المصفوفه تحتوي على 11 أعمدة، النموذج سيتنبأ ب 12 متغير بما أننا اضفنا متغير إضافي للتحيز.

### ضبط النموذج بإستخدام البيانات المُعدله

يمكننا الآن إستخدام `encoded_X` في نموذج الإنحدار الخطي:

```python
clf = LinearRegression()
clf.fit(encoded_X, y)
```

```ruby
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
```

كما ذكرنا مُسبقاً، ستكون النتيجة مكونه من 12 قيمه لكل عامود:

```python
clf.coef_, clf.intercept_
```

```ruby
(array([ 1622.11,    -2.04,     2.04,   962.91,  1805.06, -1748.48,
        -2336.8 ,   215.06,  1102.25,  -330.91,  1205.56]), 29723.135729284979)
```

يمكننا مقارنة نتائج التوقع بين كلا النماذج لنرى إذا كان هناك فرق كبير بينهما:

```python
walmart[['Weekly_Sales']].assign(
    pred_numeric=simple_classifier.predict(X),
    pred_both=clf.predict(encoded_X)
)
```

**pred\_both**|**pred\_numeric**|**Weekly\_Sales**| 
:-----:|:-----:|:-----:|:-----:
30766.79021|30768.87804|24924.5|0
31989.4104|31992.2795|46039.49|1
31460.28001|31465.22016|41595.55|2
...|...|...|...
24447.34898|23492.26265|22764.01|140
22788.04955|21826.41479|24185.27|141
21409.36746|21287.92854|27390.81|142

```ruby
143 rows × 3 columns
```

> في الجدول السابق، العامود `pred_numeric` يمثل نتائج النموذج `simple_classifier` والذي استخدم فقط الأعمدة الكميه في بياناتنا. بينما `pred_both` استخدم كامل الأعمدة.

نلاحظ ان نتائج التوقع قريبه بين النموذجان. يمكن رسم مخطط التشتت لكلا الأعمدة لتوضيح ذلك:

```python
plt.scatter(simple_classifier.predict(X), clf.predict(encoded_X))
plt.title('Predictions using all data vs. numerical features only')
plt.xlabel('Predictions using numerical features')
plt.ylabel('Predictions using all features');
```

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter14/feature_one_hot_35_0.png'>
</p>

### تقييم النموذج

لماذا ظهرت لنا النتائج هكذا؟ يمكننا عرض المتغيرات التي اعتمدها النموذجان. الجدول في الأسفل يوضح [الأوزان](/ds-100-ar/translation-reference/) المناسبه التي تعلم عليها المُصنف بإستخدام الأعمدة الكمية فقط:

```python
def clf_params(names, clf):
    weights = (
        np.append(clf.coef_, clf.intercept_)
    )
    return pd.DataFrame(weights, names + ['Intercept'])

clf_params(numerical_columns, simple_classifier)
```

**0**| 
:-----:|:-----:
-332.22118|Temperature
1626.625604|Fuel\_Price
1356.868319|Unemployment
29642.70051|Intercept

الجدول في الأسفل يوضح الأوزان المناسبه التي تعلم عليها المُصنف بعد تطبيق One-Hot Encoding على البيانات:

```python
pd.options.display.max_rows = 13
display(clf_params(encoder.feature_names_, clf))
pd.options.display.max_rows = 7
```

**0**| 
:-----:|:-----:
1622.106239|Fuel\_Price
-2.041451|IsHoliday=No
2.041451|IsHoliday=Yes
962.908849|MarkDown=MarkDown1
1805.059613|MarkDown=MarkDown2
-1748.475046|MarkDown=MarkDown3
-2336.799791|MarkDown=MarkDown4
215.060616|MarkDown=MarkDown5
1102.24576|MarkDown=No Markdown
-330.912587|Temperature
1205.564331|Unemployment
29723.13573|Intercept

> في الكود البرمجي السابق، عرف الكاتب دالة `clf_params` والتي تستقبل اسم الأعمدة و النموذج، وتنتج لنا DataFrame بقيم الأوزان لكل عامود. العامود `Intercept` هنا هو [الإنحياز](/ds-100-ar/translation-reference/).

نلاحظ أنه حتى بعد ضبط نموذج الإنحدار الخطي بإستخدام One-Hot Encoding الأوزان للأعمدة `Fuel price`، `Temperature` و `Unemployment` مشابهه بشكل كبير للبيانات قبل التعديل. جميع قيم الأوزان قليله مقارنة بالإنحياز `Intercept`، يشير ذلك إلى أن أكثر المتغيرات لا يزال ارتباطها قليل مع القيم الحقيقه للمبيعات. في الحقيقه، وزن العامود `IsHoliday` في النموذج قليل جداً مما يجعله لا يشكل فرقاً في التنبؤ. على الرغم أن بعض الأوزان في العامود `MarkDown` تبدو مرتفعه جداً، الكثير منها لم يظهر إلا قليلاً:

```python
walmart['MarkDown'].value_counts()
```

```ruby
No Markdown    92
MarkDown1      25
MarkDown2      13
MarkDown5       9
MarkDown4       2
MarkDown3       2
Name: MarkDown, dtype: int64
```

يشير ذلك أننا نحتاج لجمع المزيد من البيانات ليكون للعامود `MarkDown` تأثير على قيمة المبيعات. ( في الحقيقه، البيانات هنا هي جزء صغير من [البيانات الحقيقه الكاملة](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting) والتي نشرتها وول مارت. سيكون تدريباً مناسباً لو قمت بتجربة ضبط النموذج وتدريبه على كامل البيانات بدلاً من جزء بسيط منها).

###  ملخص بيانات وول مارت

تعلمنا كيف نستخدم One-Hot Encoding، طريقة مناسبه لتطبيق الإنحدار الخطي على البيانات الإسميه. على الرغم أن في هذا المثال تطبيق ذلك لم يأثر كثيراً على النموذج، عملياً تستخدم هذه الطريقه بشكل كبير للتعامل مع البيانات الإسميه. One-Hot Encoding تعتبر أحد المبادئ العامه في هندسة الخصائص، تأخذ مصفوفه/عامود من البيانات وتحولها إلى مصفوفات/أعمدة ذات أهميه أكبر.

## التنبؤ بتقييم الآيس كريم

### خصائص متعددة الحدود

### الإنحدار متعدد الحدود

### زيادة الدرجة

### ملخص التنبؤ بتقييم الآيس كريم



```python

```
<!-- output of python code to be added in ruby tag -->
```ruby

```



<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter6/viz_quantitative_25_0.png'>
</p>

[📝][link1]

[link1]: https://ar.wikipedia.org/wiki/%D9%85%D8%AC%D8%A7%D9%84_%D8%AB%D9%82%D8%A9
