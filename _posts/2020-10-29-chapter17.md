---
title: ุงูุชุตููู
show_title: true
chapter_number: 17
chapter_text: ุงููุตู ุงูุณุงุจุน ุนุดุฑ
chapter_lessons: [[0, 'ููุฏูุฉ'], [1, 'ุงูุงูุญุฏุงุฑ ูู ุงูุงุญุชูุงูุงุช'], [2, 'ุงููููุฐุฌ ุงูููุฌุณุชู'], [3, 'ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูููููุฐุฌ ุงูููุฌุณุชู'], [4, 'ุงุณุชุฎุฏุงู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู'], [5, 'ุชูุฑูุจ ุงูุชูุฒูุน ุงูุงุญุชูุงูู ุงูุชุฌุฑูุจู'], [6, 'ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู'], [7, 'ุชูููู ุงููููุฐุฌ ุงูููุฌุณุชู'], [8, 'ุงูุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช']]
chapter_sublessons: [
    [],
    ['ูุดุงูู ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูู ุงูุงุญุชูุงูุงุช'],
    ['ุงูุฃุนุฏุงุฏ ุงูุญููููุฉ ุฅูู ุงุญุชูุงูุงุช', 'ุงูุฏุงูุฉ ุงูููุฌุณุชูุฉ', 'ุชุนุฑูู ุงููููุฐุฌ ุงูููุฌุณุชู', 'ููุฎุต ุงููููุฐุฌ ุงูููุฌุณุชู'],
    ['ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ', 'ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ', 'ููุฎุต ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ'],
    ['ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนูู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู', 'ุชูููู ุงููุตูู', 'ูููุฐุฌ ููุฌุณุชู ูุชุนุฏุฏ ุงููุชุบูุฑุงุช', 'ููุฎุต ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู'],
    ['ุชุนุฑูู ูุชูุณุท ุชุจุงุนุฏ KL', 'ุงุณุชูุชุงุฌ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูู ุชุจุงุนุฏ KL', 'ุงูุชุจุฑูุฑ ุงูุฅุญุตุงุฆู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ', 'ููุฎุต ุชุจุฑูุฑ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ'],
    ['ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช', 'ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู', 'ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉ', 'ุงูุชุทุจูู ูู ููุชุจุฉ Scikit-learn', 'ููุฎุต ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู'],
    ['ุงูุญุณุงุณูุฉ', 'ุงูููุนูุฉ', 'ุญุฏ ูุตู ุงูุชุตููู', 'ููุญููุงุช ROC', 'AUC', 'ููุฎุต ุชูููู ุงููููุฐุฌ ุงูููุฌุณุชู'],
    ['ุชุตููู ูุงุญุฏ-ุถุฏ-ุงูุจููุฉ' ,'ุชุทุจูู ุนููู: ุจูุงูุงุช Iris', 'ุงูุชุตููู ูุชุนุฏุฏ ุงููุชุงุฆุฌ', 'ููุฎุต ุงูุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช'],
    

]
layout: default
add_line: true
---

## ููุฏูุฉ

ุญุชู ุงูุขู ุฃููููุง ูุธุฑุฉ ุนูู ููุงุฐุฌ ููุงูุญุฏุงุฑุ ุทุฑููุฉ ููููุงู ุจุชููุนุงุช ูุณุชูุฑุฉ ูุจุงูุฃุฑูุงู ุจูุงุกูุง ุนูู ุงูุจูุงูุงุช. ุงูุขู ููุชูู ุฅูู **ุงูุชุตููู Classification**ุ ููู ุทุฑููุฉ ููููุงู ุจุชููุนุงุช ุชุตููููุฉ ุจูุงุกูุง ุนูู ุงูุจูุงูุงุช. ูุซูุงูุ ูููุงุช ุชููุนุงุช ุงูุทูุณ ููุชูุฉ ุจุชููุน ูุง ุฅุฐุง ุณูููู ุบุฏุงู ููู ูุงุทุฑ ุฃู ุบูุฑ ุฐูู ุจูุงุกูุง ุนูู ุญุงู ุงูุทูุณ ุงูููู.

ูุนุงูุ ุงูุชุตููู ูุงูุงูุญุฏุงุฑ ุชุนุชุจุฑ ูู ุงูููุงุฐุฌ ุงูุฃูููุฉ ูุงูุชู ููุชููุฌูู ููุง ูู *ุงูุชุนููู ุงูููุฌููู Supervised Learning*ุ ูุงูุฐู ููู ูุชุนูู ุงููููุฐุฌ ุนู ุทุฑูู ุชูุฑูุฑ ุงูุจูุงูุงุช ููุชุงุฆุฌูุง ุนููู.

ูููููุง ุฅุนุงุฏุฉ ุชุดููู ุงูุชุตููู ุนูู ุฃูู ููุน ูู ุฃููุงุน ุงูุงูุญุฏุงุฑ. ุจุฏูุงู ูู ุฃู ูุจูู ูููุฐุฌ ููุชููุน ุฃุฑูุงูุ ููุดุฃ ูููุฐุฌ ููุชููุน ุงุญุชูุงููุฉ ุฃู ูููุฉ ูู ุงูุจูุงูุงุช ุชูุชูู ูุตูู ูุง. ูุณูุญ ููุง ุฐูู ุจุฅุนุงุฏุฉ ุงุณุชุฎุฏุงู ุชูููุงุช ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูู ุงูุงูุญุฏุงุฑ ุนูู ุงูุงุญุชูุงูุงุช ุฃู ูุง ูุณูู **ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู Logistic Regression**. [๐][LogisticRegression]

## ุงูุงูุญุฏุงุฑ ูู ุงูุงุญุชูุงูุงุช

ูู ูุฑุฉ ุงูุณูุฉุ ุชุญุณุจ ููุงุท ุงููุจุงุฑูุงุช ุนูุฏูุง ูููู ุงููุงุนุจ ุจุฅุฏุฎุงู ุงููุฑู ูู ุงูุณูุฉ. ุฃุญุฏ ุงููุงุนุจููุ ููุจุฑูู ุฌููุณุ ูุนุฑู ุจุฃูู ุฃุญุฏ ุฃูุถู ูู ูุนุจ ูุฑุฉ ุงูุณูุฉ ุจุณุจุจ ูุฏุฑุงุชู ูู ุชุณุฌูู ุงูููุงุท.

<p align="center"> 
<img src='{{ site.baseurl }}/img/chapter17/LeBron_James_(31944491583).jpg'>
</p>

ููุนุจ ููุจุฑูู ูู ุงูุฏูุฑู ุงูุฃูุฑููู ููุฑุฉ ุงูุณูุฉ ูููุญุชุฑููู (NBA). ูููุง ุจุฌูุน ุฌููุน ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ูู ุงููุจุงุฑูุงุช ุงูุฅูุตุงุฆูุฉ ูุนุงู 2017 ุจุงุณุชุฎุฏุงู ูููุน [stats.nba.com](https://stats.nba.com/).

> ูุชุญููู ุงูุจูุงูุงุช lebron.csv [ุงุถุบุท ููุง]({{ site.baseurl }}/files/chapter17/lebron.csv).

```python
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
sns.set()
sns.set_context('talk')
np.set_printoptions(threshold=20, precision=2, suppress=True)
pd.options.display.max_rows = 7
pd.options.display.max_columns = 8
pd.set_option('precision', 2)

lebron = pd.read_csv('lebron.csv')
lebron
```

**shot\_made**|**shot\_distance**|**shot\_type**|**action\_type**|**opponent**|**minute**|**game\_date**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
0|0|2PT Field Goal|Driving Layup Shot|IND|10|20170415|0
1|0|2PT Field Goal|Driving Layup Shot|IND|11|20170415|1
1|0|2PT Field Goal|Layup Shot|IND|14|20170415|2
...|...|...|...|...|...|...|...
1|1|2PT Field Goal|Driving Layup Shot|GSW|46|20170612|381
0|14|2PT Field Goal|Turnaround Fadeaway shot|GSW|47|20170612|382
1|2|2PT Field Goal|Driving Layup Shot|GSW|48|20170612|383

```ruby
384 rows ร 7 columns
```

ูู ุณุทุฑ ูู ูุฐู ุงูุจูุงูุงุช ูุญุชูู ุนูู ุงููุนูููุงุช ุงูุชุงููุฉ ุนู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ุฌููุณ:

- `game_date`: ุชุงุฑูุฎ ุงููุจุงุฑุงุฉ.
- `minute`: ุงูุฏูููุฉ ุงูุชู ุญุงูู ูููุง ุงูุชุณุฌูู (ูุฏุฉ ูู ูุจุงุฑุงุฉ ูู ูุฑุฉ ุงูุณูุฉ ุงูุฃูุฑูููุฉ 48 ุฏูููุฉ).
- `opponent`: ุงุฎุชุตุงุฑ ุงุณู ุงููุฑูู ุงูููุงูุณ.
- `action_type`: ุงูุทุฑููุฉ ุงูุชู ุชูุช ูููุง ูุญุงููุฉ ุงูุชุณุฌูู.
- `shot_type`: ููุน ุงูุฑููุฉ (ุฅูุง ุฑููุฉ ููุทุชูู ุฃู ุซูุงุซ ููุงุท).
- `shot_distance`: ูุณุงูุฉ ููุจุฑูู ุนู ุงูุณูุฉ ุนูุฏูุง ูุงู ุจูุญุงููุฉ ุงูุชุณุฌูู.
- `shot_made`: ุชููู 0 ุนูุฏูุง ุชููู ูุญุงููุฉ ุงูุชุณุฌูู ูุงุดูุฉ ู 1 ุนูุฏูุง ุชููู ูุญุงููุฉ ุงูุชุณุฌูู ูุงุฌุญุฉ.

ูุฑูุฏ ุฃู ูุณุชุฎุฏู ูุฐู ุงูุจูุงูุงุช ูุฅุฌุฑุงุก ุงูุชููุนุงุช ุนู ุงุญุชูุงููุฉ ุชุณุฌูู ููุจุฑูู ูููุฒูุฏ ูู ุงูููุงุท. ุชุนุชุจุฑ ูุฐู ูุดููุฉ *ุชุตููู Classification*ุ ูุชููุน ุตูููุ ูููุณ ุฑูู ููุง ููุนู ูู ุงูุงูุญุฏุงุฑ>

ูููููุง ุฅุนุงุฏุฉ ุตูุงุบุฉ ูุดููุฉ ุงูุชุตููู ูุฐู ุฅูู ูุดููุฉ ุงูุญุฏุงุฑ ูุชููุน ูููุง *ุงูุงุญุชูุงููุฉ Probability* ุฅุฐุง ูุงูุช ุงููุฑุฉ ุณุชุฏุฎู ูู ุงูุณูุฉ ุฃู ูุง. ูุซูุงูุ ูุชููุน ุฃู ูุญุงููุงุช ููุจุฑูู ููุชุณุฌูู ุณุชุฎุทุฃ ุงูุณูุฉ ุนูุฏูุง ุชููู ุงููุญุงููุฉ ูู ูุณุงูุฉ ุจุนูุฏุฉ.

ูููู ุจุฑุณู ูุญุงููุงุช ุงูุชุณุฌููุ ูุธูุฑ ูููุง ุงููุณุงูุฉ ุนู ุงูุณูุฉ ูู ุงููุญูุฑ $ x $ ู ูุง ุฅุฐุง ุชู ุชุณุฌูู ุชูู ุงููุญุงููุฉ ุฃู ูุง ูู ุงููุญูุฑ $ y $.

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=jitter_df(lebron, 'shot_distance', 'shot_made'),
           fit_reg=False,
           scatter_kws={'alpha': 0.3})
plt.title('LeBron Shot Make vs. Shot Distance');
```

> ุฅุณุชุฎุฏู ุงููุงุชุจ ุงูุฏุงูุฉ `jutter_df` ูุชุญููู ุงูุจูุงูุงุช ุฅูู ููู ุนุดูุงุฆูุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ูููุฉ ุนุดูุงุฆูุฉ ููุงุ ูุนุฑููุง ูุงูุชุงูู:
> 
> ```python
> def jitter_df(df, x_col, y_col):
>    x_jittered = df[x_col] + np.random.normal(scale=0, size=len(df))
>    y_jittered = df[y_col] + np.random.normal(scale=0.05, size=len(df))
>    return df.assign(**{x_col: x_jittered, y_col: y_jittered})
> ```
>

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_prob_8_0.png'>
</p>

ูููู ุฃู ูุฑู ุฃู ููุจุฑูู ูุณุฌู ุฃูุซุฑ ุนูุฏูุง ูููู ุจุญูุงูู 5 ุฃูุฏุงู ุฃู ูู ุฅูู ุงูุณูุฉ. ุนูุฏ ุถุจุท ูููุฐุฌ ุจุณูุท ููุงูุญุฏุงุฑ ุงูุฎุทู ูู ุงููุฑุจุนุงุช ุงูุตุบุฑู ุนูู ูุฐู ุงูุจูุงูุงุช ููุชุฌ ููุง ุงูุชููุนุงุช ุงูุชุงููุฉ:

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=jitter_df(lebron, 'shot_distance', 'shot_made'),
           ci=None,
           scatter_kws={'alpha': 0.4})
plt.title('Simple Linear Regression');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_prob_10_0.png'>
</p>

ูุณุชุฎุฏู ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูุชููุน ููู ุฑูููุฉ. ูููู ุนูุฏูุง ูุฑูุฏ ุชุทุจููู ุนูู ุงูุชุตูููุ ูุฑูุฏ ุชุญููู ูุฐู ุงูููู ุงูุฑูููุฉ ุฅูู ุชุตููู: ุชุณุฌูู ุงููุฑุฉ ุฃู ูุง. ูููููุง ุชุทุจูู ุฐูู ุนู ุทุฑูู ุชุญุฏูุฏ ุฎุท ูููุทุนุ ุฃู **ุญุฏ ูุตู ุงูุชุตููู Classification Threshold**. ุฅุฐุง ุชููุน ุงูุงูุญุฏุงุฑ ูููุฉ ุฃูุจุฑ ูู 0.5ุ ููุนูู ุฐูู ุฃู ุงูุชููุน ูู ุฃู ุงููุฑุฉ ุณุชุฏุฎู ุงูุณูุฉ. ุนูู ุนูุณ ุฐููุ ุฅุฐุง ุชููุน ุฃูู ูู 0.5 ูุฅู ุงููุฑุฉ ุณุชุฎุทุฃ ุงูุณูุฉ.

ุฑุณููุง ุญุฏ ุงููุตู ูู ุงูุฑุณู ุงูุจูุงูู ุจุงูููู ุงูุฃุฎุถุฑ ุงููุชูุทุน. ุจูุงุกูุง ุนูู ูุฐุง ุงูุญุฏ ุงููุงุตูุ ูุฅู ูููุฐุฌูุง ูุชููุน ุฃู ููุจุฑูู ุณูุฌู ุงููุฑุฉ ุฅุฐุง ูุงู ุนูู ุจุนุฏ 15 ูุฏู ุฃู ุฃูู ุนู ุงูุณูุฉ.

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=jitter_df(lebron, 'shot_distance', 'shot_made'),
           ci=None,
           scatter_kws={'alpha': 0.4})
plt.axhline(y=0.5, linestyle='--', c='g')
plt.title('Cutoff for Classification');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_prob_12_0.png'>
</p>

ูู ุงูุฎุทูุงุช ุงูุณุงุจูุฉุ ุญุงูููุง ุชุทุจูู ุงูุงูุญุฏุงุฑ ูุชููุน ุงุญุชูุงููุฉ ุฃู ูุฑุฉ ุณุชุตูุจ ุงููุฏู. ุฅุฐุง ูุงู ุงูุญุฏุงุฑูุง ููุชุฌ ุงุญุชูุงููุฉุ ูุฅู ุชุญุฏูุฏ ุงูุญุฏ ุงููุงุตู ุนูู 0.5 ูุนูู ุฃููุง ูููุน ุฃู ุงููุฑุฉ ุณุชุตูุจ ุงููุฏู ุนูุฏูุง ูุชููุน ุงููููุฐุฌ ูููุฉ ุฃุนูู ูู ุฐูู. ุณูุนูุฏ ูููุถูุน ุญุฏ ูุตู ุงูุชุตููู ูู ุฌุฒุก ุขุฎุฑ ูู ูุฐุง ุงููุตู.

### ูุดุงูู ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูู ุงูุงุญุชูุงูุงุช

ููุฃุณูุ ูุง ูููููุง ุงุนุชูุงุฏ ูุชุงุฆุฌ ูููุฐุฌูุง ุงูุฎุทู ุนูู ุฃููุง ุงุญุชูุงูุงุช. ุงูุงุญุชูุงูุงุช ุงูุตุญูุญุฉ ูุฌุจ ุฃู ุชููู ุจูู 0 ู 1ุ ูููู ูููุฐุฌูุง ุงูุฎุทู ูุฎุงูู ูุฐุง ุงูุดุฑุท. ูุซูุงูุ ุงุญุชูุงููุฉ ุฃู ูุณุฌู ููุจุฑูู ูุฑุฉ ูู ุนูู ุจุนุฏ 100 ูุฏู ุนู ุงูุณูุฉ ูุฌุจ ุฃู ุชููู ุฃูุฑุจ ุฅูู ุงูุตูุฑ. ููููุ ูู ุญุงูุชูุง ููุงุ ุงููููุฐุฌ ุณูุชููุน ูููุฉ ุณูุจูุฉ.

ุฅุฐุง ูููุง ุจุงูุชุนุฏูู ุนูู ูููุฐุฌูุง ุงูุฎุทู ูุชููู ุชููุนุงุชู ุนุจุงุฑุฉ ุนู ุงุญุชูุงูุงุชุ ูู ููุงุฌู ูุดููุฉ ูู ุงุณุชุฎุฏุงู ุชููุนุงุชู ูู ุงูุชุตููู. ูููููุง ุงูููุงู ุจุฐูู ุจุงุณุชุฎุฏุงู ุฏุงูุฉ ุชููุน ูุฏุงูุฉ ุฎุณุงุฑุฉ ุฌุฏูุฏุฉ. ูุทูู ุนูู ูุฐุง ุงููููุฐุฌ ุจู **ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู Logistic Regression**. 

## ุงููููุฐุฌ ุงูููุฌุณุชู

ูู ูุฐุง ุงูุฌุฒุกุ ุณูุชุนุฑู ุนูู **ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู**ุ ูููุฐุฌ ุฎุทู ูุณุชุฎุฏูุฉ ูุชููุน ุงูุงุญุชูุงูุงุช.

ููุชุฐูุฑ ุฃู ูุถุจุท ูููุฐุฌ ูุญุชุงุฌ ูุซูุงุซ ุนูุงุตุฑ: ูููุฐุฌ ูููู ุจุงูุชููุนุ ุฏุงูุฉ ุฎุณุงุฑุฉุ ูุทุฑููุฉ ูุชุญุณูู ูุชุงุฆุฌ ุงููููุฐุฌ. ุณูุณุชุฎุฏู ุงููููุฐุฌ ุงูุฐู ูุนุฑูุฉ ุงูุขูุ ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูููุฑุจุนุงุช ุงูุตุบุฑู:

 $$  \begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) &= \hat{\boldsymbol{\theta}} \cdot \textbf{x}
\end{aligned}  $$ 

ูุฏุงูุฉ ุงูุฎุณุงุฑุฉ:

 $$  \begin{split}
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_{i}(y_i - f_\boldsymbol{\theta} (\textbf{X}_i))^2\\
\end{aligned}
\end{split}  $$ 

ุณูุณุชุฎุฏู ุงููุฒูู ุงูุงุดุชูุงูู ูุฃุฏุงุฉ ูุชุญุณูู ุงููุชุงุฆุฌ. ูู ุงูุชุนุฑูู ุงูุณุงุจูุ $ X $ ุชูุซู ูุตูููุฉ ุงูุจูุงูุงุช $ n \times p $ (ููููุง $ n $ ูู ุนุฏุฏ ุงูุจูุงูุงุช ู $ p $ ุนุฏุฏ ุงูุนูุงุตุฑ / ุงูุฃุนูุฏุฉ)ุ ุชูุซู $ \textbf{x} $ ุณุทุฑ ูู $ X $ุ ู $ y $ ูุชูุฌู ูููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุง. ุงููุชูุฌู $ \hat{\boldsymbol{\theta}} $ ุงููุฒู ุงููุซุงูู ูููููุฐุฌ ู $ \boldsymbol{\theta} $ ุชูุซู ุงููุฒู ุงููุชูุณุท ุงูุฐู ุฃูุดุฆ ุฃุซูุงุก ูุญุงููุฉ ุชุญุณูู ุงููููุฐุฌ.

### ุงูุฃุนุฏุงุฏ ุงูุญููููุฉ ุฅูู ุงุญุชูุงูุงุช

ููุฑู ุฃู ูููุฐุฌูุง $ f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \hat{\boldsymbol{\theta}} \cdot \textbf{x} $ ูููู ุฃู ูุชููุน ุฃู ุฑูู ุญูููู $ \mathbb{R} $ ุจูุง ุฃูู ููุชุฌ ูุฌููุนุฉ ูู ุงูุงุฑูุงู ุฎุทูุฉ ูู $ \textbf{x} $ุ ูุงูุชู ุจููุณูุง ูููู ุฃู ุชุญุชูู ุนูู ุฃู ุฑูู ูู $ \mathbb{R} $.

ูููููุง ุจุณููู ุฑุณู ุฐูู ุจูุงููุงู ุนูุฏูุง ุชููู $ x $ ุฑูู ูุชุฏุฑุฌ. ุฅุฐุง ูุงูุช $ \hat \theta = 0.5 $ ูุฃู ุงููููุฐุฌ ุณูููู $ f_\hat{\theta} (\textbf{x}) = 0.5 x $. ูููู ูุชููุนุงุช ูุฐุง ุงููููุฐุฌ ุฃู ุชููู ุฃู ุฑูู ูู ุณุงูุจ ูุงูุง ููุงูุฉ ุญุชู ููุฌุจ ูุงูุง ููุงูุฉ:

```python
xs = np.linspace(-100, 100, 100)
ys = 0.5 * xs
plt.plot(xs, ys)
plt.xlabel('$x$')
plt.ylabel(r'$f_\hat{\theta}(x)$')
plt.title(r'Model Predictions for $ \hat{\theta} = 0.5 $');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_model_6_0.png'>
</p>

ูููุงู ุงูุชุตูููุ ูุฑูุฏ ุชูููุฏ $ f_\hat{\boldsymbol{\theta}}(\textbf{x}) $ ุจุญูุซ ุชููู ูุชุงุฆุฌูุง ุนุจุงุฑุฉ ุนู ุงุญุชูุงููุฉ. ูุนูู ุฐูู ุฃู ูุชุงุฆุฌูุง ุชููู ูู ุงููุฏู $ [0, 1] $ ุฃูุถุงูุ ูุฑูุฏ ุฃู ุชุชุทุงุจู ุงูููู ุงููุจุฑู ูู $ f_\hat{\boldsymbol{\theta}}(\textbf{x}) $ ูุน ููู ูุจุฑู ูู ุงูุงุญุชูุงููุฉ ูุงูุนูุณ ููููู ุงูุตุบุฑู ูุน ูููุฉ ุงุญุชูุงููุฉ ุตุบุฑู.

### ุงูุฏุงูุฉ ุงูููุฌุณุชูุฉ

ูุฅูุฌุงุฒ ุฐููุ ุณูุชุนุฑู ุนูู **ุงูุฏุงูุฉ ุงูููุฌุณุชูุฉ Logistic Function**ุ ููุทูู ุนูููุง ูู ุจุนุถ ุงูุฃุญูุงู **ุงูุฏุงูุฉ ุงูุณูููุฉ Sigmoid Function**: [๐][Sigmoid]

 $$  \begin{aligned}
\sigma(t) = \frac{1}{1 + e^{-t}}
\end{aligned}  $$ 

ูุชุณููู ุงููุฑุงุกุฉุ ุนุงุฏุฉ ูุง ูููู ุจุชุบูุฑ $ e^x $ ุฅูู $ \text{exp}(x) $:

 $$  \begin{aligned}
\sigma (t) = \frac{1}{1 + \text{exp}(-t)}
\end{aligned}  $$ 

ูููุง ุจุฑุณู ุงูุฏุงูุฉ ุงูุณูููุฉ ููููู ุงูุชุงููุฉ $ t \in [-10, 10] $:

```python
from scipy.special import expit
xs = np.linspace(-10, 10, 100)
ys = expit(xs)
plt.plot(xs, ys)
plt.title(r'Sigmoid Function')
plt.xlabel('$ t $')
plt.ylabel(r'$ \sigma(t) $');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_model_10_0.png'>
</p>

ููุงุญุธ ุฃู ุงูุฏุงูุฉ ุงูุณูููุฉ $ \sigma(t) $ ุชุฃุฎุฐ ุฑูู ุญูููู $ \mathbb{R} $ ูุชููู ูุชุงุฆุฌูุง ููุท ุฃุฑูุงู ุจูู 0 ู 1. ุชููู ุงูุฏุงูุฉ ุชุฏุฑูุฌูุงู ุจุงูุตุนูุฏ ุจูุงุกูุง ุนูู ุงูููู ุงููุฏุฎูุฉ $ t $ุ ุงูููู ุงููุจูุฑุฉ ูู $ t $ ูู ุงูููู ุงููุฑูุจุฉ ูู 1ุ ููุง ุฑุบุจูุงูุง ุฃู ุชุนูู. ูู ูุชู ุฐูู ุจุงูุตุฏูุฉุ ุงูุฏุงูุฉ ุงูุณูููุฉ ูููู ุงุดุชูุงููุง ูู ูุณุจุฉ ููุบุงุฑูุชููุงุช ุงูุงุญุชูุงูุงุชุ ูููู ูููุง ุจุฅุฎูุงุก ุงูุงุดุชูุงู ูุชุณููู ุงูุดุฑุญ

### ุชุนุฑูู ุงููููุฐุฌ ุงูููุฌุณุชู

ูููููุง ุงูุขู ุฃุฎุฐ ุงููููุฐุฌ ุงูุฎุทู $ \hat{\boldsymbol{\theta}} \cdot \textbf{x} $ ูุงุณุชุฎุฏุงูู ูููุฏุฎู ููุฏุงูุฉ ุงูุณูููุฉ ูุฅูุดุงุก **ุงููููุฐุฌ ุงูููุฌุณุชู**:

 $$ 
\begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \sigma(\hat{\boldsymbol{\theta}} \cdot \textbf{x})
\end{aligned}
 $$ 

ุจูุนูู ุขุฎุฑุ ูุฃุฎุฐ ูุชูุฌุฉ ุงูุงูุญุฏุงุฑ ุงูุฎุทูุ ุฃู ุฑูู ุญูููู $ \mathbb{R} $ุ ููุณุชุฎุฏูู ูู ุงูุฏุงูุฉ ุงูุณูููุฉ ูุชูููุฏ ูุชุงุฆุฌ ุงููููุฐุฌ ุงูููุงุฆูุฉ ูุชููู ูุชูุฌุฉ ุงุญุชูุงููุฉ ุตุญูุญ ูุฑูู ุจูู ุตูุฑ ููุงุญุฏ.

ููุนุฑูุฉ ุทุฑููุฉ ุนูู ุงููููุฐุฌ ุงูููุฌุณุชู ุจุดูู ุจุณูุทุ ุณูููู ุจุชูููุฏ ูููุฉ $ x $ ูุชููู ุฑูู ูุชุฏุฑุฌ ูุฑุณู ูุชูุฌุฉ ุงููููุฐุฌ ุงูููุฌุณุชู ูุนุฏุฉ ููู ูู $ \hat{\theta} $:

```python
# ูุง ุญุงุฌุฉ ูููู ุงูููุฏ ุงูุจุฑูุฌู ูุฃู ุงููุงุชุจ ุงุณุชุฎุฏูุฉ ูุจูุงุก ุงูุฑุณู ุงูุจูุงูู ุงูุชูุถูุญู
def flatten(li): return [item for sub in li for item in sub]

thetas = [-2, -1, -0.5, 2, 1, 0.5]
xs = np.linspace(-10, 10, 100)

fig, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(10, 6))
for ax, theta in zip(flatten(axes), thetas):
    ys = expit(theta * xs)
    ax.plot(xs, ys)
    ax.set_title(r'$ \hat{\theta} = $' + str(theta))


fig.add_subplot(111, frameon=False)
plt.tick_params(labelcolor='none', top='off', bottom='off',
                left='off', right='off')
plt.grid(False)
plt.xlabel('$x$')
plt.ylabel(r'$ f_\hat{\theta}(x) $')
plt.tight_layout()
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_model_14_0.png'>
</p>

ููุงุญุธ ุฃู ุงูุชุบูุฑ ูู ูููุฉ $ \hat{\theta} $ ูุบูุฑ ูู ุญูุฏุฉ ุงูููุญููุ ูููุง ุฃุจุนุฏูุง ุนู $ 0 $ุ ูููุง ุฒุงุฏุช ุญุฏุฉ ุงูููุญูู. ุชุบูุฑ ุงูุฅุดุงุฑุฉ ูู $ \hat{\theta} $ ูุน ุงูุฅุจูุงุก ุนูู ููุณ ุงููููุฉ ุงูุฑูููุฉ ููุชุฌ ููุง ููุณ ุงููุชุงุฆุฌ ููู ุจุดูู ุนูุณู.

### ููุฎุต ุงููููุฐุฌ ุงูููุฌุณุชู

ุชุนุฑููุง ุนูู ุงููููุฐุฌ ุงูููุฌุณุชูุ ุทุฑููุฉ ุฌุฏูุฏุฉ ููุชููุน ุงูุชู ุชููุชูุฌ ููุง ุชููุนุงุช ูุงุญุชูุงูุงุช. ูุจูุงุก ุงููููุฐุฌุ ูุณุชุฎุฏู ูุฎุฑุฌุงุช ุงููููุฐุฌ ุงูุฎุทู ููุฏุฎูุงุช ุฅูู ุงูุฏุงูุฉ ุงูููุฌุณุชูุฉ ุบูุฑ ุงูุฎุทูุฉ.

## ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูููููุฐุฌ ุงูููุฌุณุชู

ูููุง ุจุชุนุฑูู ุงููููุฐุฌ ุงูุฎุทู ููุงุญุชูุงูุงุชุ ุงููููุฐุฌ ุงูููุฌุณุชู:

 $$ 
\begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \sigma(\hat{\boldsymbol{\theta}} \cdot \textbf{x})
\end{aligned}
 $$ 

ููุง ูู ุงููููุฐุฌ ุงูุฎุทูุ ูุญุชูู ุงููููุฐุฌ ุนูู ูุชุบูุฑุงุช $ \hat{\boldsymbol{\theta}} $ุ ูุตูููุฉ ุชุญุชูู ุนูู ูุชุบูุฑ ูุงุญุฏ ููู ุฎุงุตูุฉ ูู $ \textbf{x} $. ุณูููู ุงูุขู ุจุญู ูุดููุฉ ุชุนุฑูู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ููุฐุง ุงููููุฐุฌ ูุงูุชู ุณุชุณูุญ ููุง ุจุถุจุท ูุชุบูุฑุงุช ุงููููุฐุฌ ููุฐู ุงูุจูุงูุงุช.

ูุง ูุฑูุฏู ูู ุฃู ูููู ุงููููุฐุฌ ุจุชููุนุงุช ูุทุงุจูุฉ ุจุดูู ูุจูุฑ ููุจูุงูุงุช. ูู ุงูุฃุณูู ูููุง ุจุฑุณู ุจูุงูู ููุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ูู ุงููุจุงุฑูุงุช ุงูุฅูุตุงุฆูุฉ ูุนุงู 2017 ุจุงุณุชุฎุฏุงู ุจุนุฏ ููู ุชุณุฏูุฏุฉ ุนู ุงูุณูุฉ:

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=lebron,
           fit_reg=False, ci=False,
           y_jitter=0.1,
           scatter_kws={'alpha': 0.3})
plt.title('LeBron Shot Attempts')
plt.xlabel('Distance from Basket (ft)')
plt.ylabel('Shot Made');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_cost_4_0.png'>
</p>

ููุงุญุธ ุงูุชุฌูุน ููุซูุฑ ูู ุงููุญุงููุงุช ุงูุชู ุชู ุชุณุฌูููุง ูุงูุชู ูุงูุช ูุฑูุจุฉ ูู ุงูุณูุฉ ูุชุฌูุน ูููู ูู ุงูุจูุงูุงุช ููุญุงููุงุช ุชู ุชุณุฌูููุง ูู ูุณุงูุงุช ุจุนูุฏุฉ ุนู ุงูุณูุฉุ ูุชููุน ุนูุฏูุง ูุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ุนูู ูุฐู ุงูุจูุงูุงุช ุฃู ุงููุชูุฌุฉ ุณูููู ูุงูุชุงูู:

```python
from scipy.special import expit

sns.lmplot(x='shot_distance', y='shot_made',
           data=lebron,
           fit_reg=False, ci=False,
           y_jitter=0.1,
           scatter_kws={'alpha': 0.3})

xs = np.linspace(-2, 32, 100)
ys = expit(-0.15 * (xs - 15))
plt.plot(xs, ys, c='r', label='Logistic model')

plt.title('Possible logistic model fit')
plt.xlabel('Distance from Basket (ft)')
plt.ylabel('Shot Made');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_cost_6_0.png'>
</p>

ุนูู ุงูุฑุบู ุฃู ุจุฅููุงููุง ุงุณุชุฎุฏุงู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุท ููุง ูุนููุง ูู ูููุฐุฌ ุงูุงูุญุฏุงุฑ ุงูุฎุทูุ ูู ููุณุช ููุงุฆูุฉ ูููููุฐุฌ ุงูููุฌุณุชู ููุตุนุจ ุชุญุณูู ูุชุงุฆุฌูุง.

### ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ุจุฏูุงู ูู ุงูุฎุทุฃ ุงูุชุฑุจูุนู ุงููุชูุณุทุ ุณูุณุชุฎุฏู **ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ Cross-Entropy Loss**. ูุชูุซู $ \textbf{X} $ ูุตูููุฉ ุงูุจูุงูุงุช $ n \times p $ุ ู $ \textbf{y} $ ูุชูุฌู ูููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุงุ ู $ f_\boldsymbol{\theta}(\textbf{x}) $ ุชูุซู ุงููููุฐุฌ ุงูููุฌุณุชู. ุชุญุชูู $ \boldsymbol{\theta} $ ุนูู ููู ุงููุชุบูุฑุงุช ุงูุญุงููุฉ. ุจุงุณุชุฎุฏุงู ูุฐุง ุงูุชุนุฑููุ ูููููุง ุชุนุฑูู ูุนุงุฏูุฉ ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุงูุชุงูู: [๐][CrossEntropyLoss]

 $$ 
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) = \frac{1}{n} \sum_i \left(- y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) \right)
\end{aligned}
 $$ 

ูููู ุฃู ุชูุงุญุธุ ููุง ูุนููุง ูุณุจูุงูุ ุฃููุง ุฃุฎุฐูุง ูุชูุณุท ุงูุฎุณุงุฑุฉ ููู ููุทุฉ ูุนููุฉ ูู ุงูุจูุงูุงุช. ูุง ูู ุฏุงุฎู ุงูุชุนุฑูู ุงูุณุงุจู ููุซู ุงูุฎุณุงุฑุฉ ูููุทุฉ ูุนููุฉ $(\textbf{X}_i, y_i)$:

 $$ 
\begin{aligned}
\ell(\boldsymbol{\theta}, \textbf{X}_i, y_i) = - y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) )
\end{aligned}
 $$ 

ููุชุฐูุฑ ุฃู ูู ูููุฉ $ y_i $ ุณุชููู ุฅูุง 0 ุฃู 1. ุฅุฐุง ูุงูุช $ y_i = 0 $ุ ูุฃูู ูุตุทูุญ ูู ุงูุฎุณุงุฑุฉ ูุณุงูู ุตูุฑ. ุฅุฐุง ูุงูุช $ y_i = 1 $ุ ูุฃู ุซุงูู ูุตุทูุญ ูู ุงูุชุนุฑูู ุงูุณุงุจู ูุณุงูู ุตูุฑ. ูุฐุงุ ููู ููุทุฉ ูู ุจูุงูุงุชูุงุ ูุฅู ููุท ุฌุฒุก ูุงุญุฏ ูู ุชุนุฑูู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุณุงูู ูู ุญุณุงุจ ูููุฉ ุงูุฎุณุงุฑุฉ ุงูููุงูุฉ.

ูููุชุฑุถ ุฃู $ y_i = 0 $ ูุงูุงุญุชูุงููุฉ ุงููุชููุนุฉ ูุงูุช $ f_\boldsymbol{\theta}(\textbf{X}_i) = 0 $ุ ูุฅู ูููุฐุฌูุง ูุงู ุชููุนู ุตุญูุญ. ุณุชููู ุงูุฎุณุงุฑุฉ ููุฐู ุงูููุทุฉ ูุงูุชุงูู:

 $$ 
\begin{aligned}
\ell(\boldsymbol{\theta}, \textbf{X}_i, y_i)
&= - y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) ) \\
&= - 0 - (1 - 0) \ln (1 - 0 ) \\
&= - \ln (1) \\
&= 0
\end{aligned}
 $$ 

ููุง ูู ูุชููุนุ ุงูุฎุณุงุฑุฉ ููุชููุน ุงูุตุญูุญ ูู $ 0 $. ููููู ุงูุชุฃูุฏ ูู ุฐูู ุนูุฏูุง ุชููู ูุชุงุฆุฌ ุชููุน ุงูุงุญุชูุงููู ุฃุจุนุฏ ูู ุงููููุฉ ุงูุญูููุฉุ ูุฅู ุงูุฎุณุงุฑุฉ ุชููู ุนุงููุฉ.

ุงูุชูููู ูู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุญุชุงุฌ ุฃู ูููู ุงููููุฐุฌ $ f_\boldsymbol{\theta}(\textbf{x}) $ ุจุฃุฏู ุงูุชููุนุงุช ุงูุตุญูุญุฉ ุงูููููุฉ. ูุฐููุ ูุฅู ุฏุงูุฉ ุงูุฎุงุณุฑุฉ ูุฐู ููุญุฏุจุฉุ ููุง ูุฌุนู ุงููุฒูู ุงูุงุดุชูุงูู ููุงุณุจ ูุชุญุณูู ุงููุชุงุฆุฌ.

### ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ูุชุทุจูู ุงููุฒูู ุงูุงุดุชูุงูู ุนูู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูููููุฐุฌ ูุฌุจ ุนูููุง ุญุณุงุจ ูุดุชูุฉ ุงูุฎุณุงุฑุฉ. ุฃููุงูุ ูููู ุจุญุณุงุจ ูุดุชูุฉ ุงูุฏุงูุฉ ุงูุณูููุฉ ุจูุง ุฃููุง ุณูุณุชุฎุฏููุง ูู ุนูููุฉ ุญุณุงุจ ุงูุงุดุชูุงู:

 $$ 
\begin{aligned}
\sigma(t) &= \frac{1}{1 + e^{-t}} \\
\sigma'(t) &= \frac{e^{-t}}{(1 + e^{-t})^2} \\
\sigma'(t) &= \frac{1}{1 + e^{-t}} \cdot \left(1 - \frac{1}{1 + e^{-t}} \right) \\
\sigma'(t) &= \sigma(t) (1 - \sigma(t))
\end{aligned}
 $$ 

ูููููุง ูุตู ูุดุชูุฉ ุงูุฏุงูุฉ ุงูุณูููุฉ ูู ุงูุฏุงูุฉ ุงูุณูููุฉ ููุณูุง.

ููุงุฎุชุตุงุฑุ ูููู ุจุชุนุฑูู $ \sigma_i = f_\boldsymbol{\theta}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) $. ุณูุญุชุงุฌ ูุฑูุจุงู ุฅูู ูุดุชูุฉ $ \sigma_i $ ููููุชุฌูุฉ $ \boldsymbol{\theta} $ ูุฐุง ุณูููู ุจุญุณุงุจุฉ ุงูุขู ุจุงุณุชุฎุฏุงู ูุงุนุฏุฉ ุงูุณูุณูุฉ: [๐][ChainRule]

 $$ 
\begin{aligned}
\nabla_{\boldsymbol{\theta}} \sigma_i
&= \nabla_{\boldsymbol{\theta}} \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) \\
&= \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) (1 - \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}))  \nabla_{\boldsymbol{\theta}} (\textbf{X}_i \cdot \boldsymbol{\theta}) \\
&= \sigma_i (1 - \sigma_i) \textbf{X}_i 
\end{aligned}
 $$ 

ูุงูุขูุ ุณููุฌุฏ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ููุชุบูุฑุงุช ุงููููุฐุฌ $ \boldsymbol{\theta} $. ูู ุชูุตูู ุญู ุงููุดุชูุฉ ูู ุงูุฃุณููุ ุฌุนููุง $ \sigma_i = f_\boldsymbol{\theta}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) $: 

 $$ 
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_i \left(- y_i \ln (f_\boldsymbol{\theta}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\boldsymbol{\theta}(\textbf{X}_i) \right) \\
&= \frac{1}{n} \sum_i \left(- y_i \ln \sigma_i - (1 - y_i) \ln (1 - \sigma_i) \right) \\
\nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= \frac{1}{n} \sum_i \left(
    - \frac{y_i}{\sigma_i} \nabla_{\boldsymbol{\theta}} \sigma_i
    + \frac{1 - y_i}{1 - \sigma_i} \nabla_{\boldsymbol{\theta}} \sigma_i \right) \\
&= - \frac{1}{n} \sum_i \left(
    \frac{y_i}{\sigma_i} - \frac{1 - y_i}{1 - \sigma_i}
\right) \nabla_{\boldsymbol{\theta}} \sigma_i \\
&= - \frac{1}{n} \sum_i \left(
    \frac{y_i}{\sigma_i} - \frac{1 - y_i}{1 - \sigma_i}
\right) \sigma_i (1 - \sigma_i) \textbf{X}_i \\
&= - \frac{1}{n} \sum_i \left(
    y_i - \sigma_i
\right) \textbf{X}_i \\
\end{aligned}
 $$ 

ุงูุชุนุฑูู ุงูุจุณูุท ูููุดุชูุฉ ูุณูุญ ููุง ุจุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ุจุงุณุชุฎุฏุงู ุงููุฒูู ุงูุงุดุชูุงูู:

 $$  \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\boldsymbol{\theta}}}  L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})  $$ 

ูุงุญูุงู ุณูุชุนูู ููุญุฏุซ ูู ุงููุนุงุฏูุฉ ูุฃููุงุน ูุฎุชููุฉ ูู ุงููุฒูู ุงูุงุดุชูุงูู ุงูุฏููุนุงุชุ ุงูุนุดูุงุฆู ูุงูุฏูุนุงุช ุงูุตุบูุฑุฉ.

### ููุฎุต ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ุจูุง ุฃู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ููุญุฏุจุฉุ ูููู ุจุชูููููุง ุจุงุณุชุฎุฏุงู ุงููุฒูู ุงูุงุดุชูุงูู ูุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ุนูู ุงูุจูุงูุงุช. ูุฏููุง ุงูุขู ุงูุนูุงุตุฑ ุงููููุฉ ููุงูุญุฏุงุฑ ุงูููุฌุณุชู: ุงููููุฐุฌุ ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูุทุฑููุฉ ูุชุญุณูู ุงููุชุงุฆุฌ. ูู ุฌุฒุก ูุงุญู ุณูุชุนูู ุฃูุซุฑ ููุนุฑูุฉ ุณุจุจ ุงุณุชุฎุฏุงููุง ููุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู

## ุงุณุชุฎุฏุงู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู

ุชุนุฑููุง ุนูู ุฌููุน ุงูุนูุงุตุฑ ุงููุทููุจุฉ ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชูุ ุฃููุงูุ ุงููููุฐุฌ ุงูููุฌุณุชู ุงููุณุชุฎุฏู ูุฅุฌุฑุงุก ุชููุนุงุช ุงูุงุญุชูุงููุงุช:

 $$  \begin{aligned}
f_\hat{\boldsymbol{\theta}} (\textbf{x}) = \sigma(\hat{\boldsymbol{\theta}} \cdot \textbf{x})
\end{aligned}  $$ 

ุซู ุฏุงูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ:

 $$  \begin{split}
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) = &= \frac{1}{n} \sum_i \left(- y_i \ln \sigma_i - (1 - y_i) \ln (1 - \sigma_i ) \right) \\
\end{aligned}
\end{split}  $$ 

ูุฃุฎูุฑุงูุ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูููุฒูู ุงูุงุดุชูุงูู:

 $$  \begin{split}
\begin{aligned}
\nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y})
&= - \frac{1}{n} \sum_i \left(
    y_i - \sigma_i
\right) \textbf{X}_i \\
\end{aligned}
\end{split}  $$ 

ูู ุงููุนุงุฏูุฉ ุงูุณุงููุฉุ ุฌุนููุง $ \textbf{X} $ ุชูุซู ูุตูููุฉ ุงูุจูุงูุงุช $ n \times p $ ุ ุชูุซู $ \textbf{x} $ ุณุทุฑ ูู $ \textbf{X} $ุ ู $ y $ ูุชูุฌู ูููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุง. ู $ f_\hat{\boldsymbol{\theta}}(\textbf{x}) $ ูู ุงููููุฐุฌ ุงูููุฌุณุชู ุงููุซุงูู ูุฐู ูุชุบูุฑุงุช ูุซุงููุฉ $ \hat{\boldsymbol{\theta}} $. ููุงุฎุชุตุงุฑุ ูุนุฑู $ \sigma_i = f_\hat{\boldsymbol{\theta}}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \hat{\boldsymbol{\theta}}) $.

### ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนูู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู

ููุนูุฏ ูููุดููุฉ ุงูุชู ูุงุฌููุงูุง ูู ุจุฏุงูุฉ ูุฐุง ุงููุตู: ููุชููุน ุฃู ูุญุงููุงุช ุงูุชุณุฌูู ูููุจุฑูู ุฌููุณ ุณุชุตูุจ ุงููุฏู. ุฃููุงู ูุญูู ุจูุงูุงุช ูุญุงููุงุช ุงูุชุตููุจ ูููุจุฑูู ูู ุงููุจุงุฑูุงุช ุงูุฅูุตุงุฆูุฉ ูุนุงู 2017:

```python
lebron = pd.read_csv('lebron.csv')
lebron
```

**shot\_made**|**shot\_distance**|**shot\_type**|**action\_type**|**opponent**|**minute**|**game\_date**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
0|0|2PT Field Goal|Driving Layup Shot|IND|10|20170415|0
1|0|2PT Field Goal|Driving Layup Shot|IND|11|20170415|1
1|0|2PT Field Goal|Layup Shot|IND|14|20170415|2
...|...|...|...|...|...|...|...
1|1|2PT Field Goal|Driving Layup Shot|GSW|46|20170612|381
0|14|2PT Field Goal|Turnaround Fadeaway shot|GSW|47|20170612|382
1|2|2PT Field Goal|Driving Layup Shot|GSW|48|20170612|383

```ruby
384 rows ร 7 columns
```

ููููู ูุธุฑุฉ ุจุดูู ุชูุงุนูู ุนูู ูุฐู ุงูุจูุงูุงุช:

```python
df_interact(lebron)
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/lebron-data-sample.gif'>
</p>

```ruby
(384 rows, 7 columns) total
```


> ุดูุฑุญุช ูุฐู ุงูุฏุงูุฉ ูู ูุตู ุณุงุจู ููุธููุชูุง ูู ุชูููู ุงููุณุชุฎุฏู ูู ุชุตูุญ ุงูุจูุงูุงุช ุจุดูู ุชูุงุนูู ูุชู ุชุนุฑูููุง ูุงูุชุงูู:
>
>```python
>%matplotlib inline
>import ipywidgets as widgets
>from ipywidgets import interact, interactive, fixed, interact_manual
>
>def df_interact(df, nrows=7, ncols=7):
>    def peek(row=0, col=0):
>        return df.iloc[row:row + nrows, col:col + ncols]
>    if len(df.columns) <= ncols:
>        interact(peek, row=(0, len(df) - nrows, nrows), col=fixed(0))
>    else:
>        interact(peek,
>                 row=(0, len(df) - nrows, nrows),
>                 col=(0, len(df.columns) - ncols))
>    print('({} rows, {} columns) total'.format(df.shape[0], df.shape[1]))
>```

ูุจุฏุฃ ุฃููุงู ุจุงุณุชุฎุฏุงู ูุณุงูุฉ ูุญุงููุฉ ุงูุชุณุฌูู ูุชููุน ูุง ุฅุฐุง ุชู ุชุณุฌูู ุงููุญุงููุฉ ุฃู ูุง. ุชููุฑ ููุง ููุชุจุฉ `scikit-learn` ุงููููุฐุฌ ุงูููุฌุณุชู ุจุดูู ุณูู ุนุจุฑ ุงูููุงุณ [sklearn.linear_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). ูุงุณุชุฎุฏุงููุ ูุจุฏุฃ ุฃููุงู ุจุฅูุดุงุก ูุตูููุฉ ุงูุจูุงูุงุช `X`ุ ูููุชุฌูุฉ ุงููุชุงุฆุฌ ุงูุชู ุงูููุทูุน ุนูููุง `y`.

```python
X = lebron[['shot_distance']].values
y = lebron['shot_made'].values
print('X:')
print(X)
print()
print('y:')
print(y)
```

```ruby
X:
[[ 0]
 [ 0]
 [ 0]
 ...
 [ 1]
 [14]
 [ 2]]

y:
[0 1 1 ... 1 0 1]
```

ููุงููุนุชุงุฏุ ุณููุณู ุจูุงูุงุชูุง ุฅูู ุจูุงูุงุช ุชุฏุฑูุจ ู ุงุฎุชุจุงุฑ:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=40, random_state=42
)
print(f'Training set size: {len(y_train)}')
print(f'Test set size: {len(y_test)}')
```

```ruby
Training set size: 344
Test set size: 40
```

ุชุฌุนู ููุชุจุฉ `scikit-learn` ุฅูุดุงุก ูุถุจุท ุงููููุฐุฌ ุนูู `X_train` ู `y_train` ุนูููุฉ ุณููุฉ ุฌุฏุงู: 

```python
from sklearn.linear_model import LogisticRegression

simple_clf = LogisticRegression()
simple_clf.fit(X_train, y_train)
```

```ruby
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
```

ูุนุฑุถ ุฃุฏุงุก ุงููููุฐุฌ ูู ุฑุณู ุจูุงููุ ุณูุชุนุฑุถ ุงูููุงุท ุงูุฃุตููุฉ ูุชููุนุงุช ุงููููุฐุฌ ููุงุญุชูุงููุฉ:

```python
sns.lmplot(x='shot_distance', y='shot_made',
           data=lebron,
           fit_reg=False, ci=False,
           y_jitter=0.1,
           scatter_kws={'alpha': 0.3})

xs = np.linspace(-2, 32, 100)
ys = simple_clf.predict_proba(xs.reshape(-1, 1))[:, 1]
plt.plot(xs, ys)

plt.title('LeBron Training Data and Predictions')
plt.xlabel('Distance from Basket (ft)')
plt.ylabel('Shot Made');
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_log_reg_16_0.png'>
</p>

### ุชูููู ุงููุตูู

ุฅุญุฏู ุงูุทุฑู ูุชูููู ุฃุฏุงุก ุงููููุฐุฌ ูู ุจููุงุณ ุฏูุฉ ุงูุชููุนุงุช: ูุง ูู ูุณุจุฉ ุงูุชููุนุงุช ุงูุตุญูุญุฉุ

```python
simple_clf.score(X_test, y_test)
```

```ruby
0.6
```

ูุจุฏู ุฃู ุฃุฏุงุก ุงููููุฐุฌ ูุชุฏูู ููููุงู ุจุฏูุฉ 0.6 ุนูู ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ. ุฅุฐุง ูุงู ูููุฐุฌูุง ุจุงูุชููุน ุนูู ูู ุงูููุงุท ุจุดูู ุนุดูุงุฆูุ ุณูุชููุน ูุชูุฌุฉ ุงูุฏูุฉ ุณุชููู 0.50. ุจุงูุฃุตุญุ ุฅุฐุง ูุงู ูููุฐุฌูุง ุจุจุณุงุทุฉ ุจุชููุน ูู ูุญุงููุฉ ูููุจุฑููุ ุณูุญุตู ุนูู ููุณ ูุณุจุฉ ุงูุฏูุฉ:

```python
# ุญุณุงุจ ุงูุฏูุฉ ุฅุฐุง ูุงู ุงูุชููุน 1
np.count_nonzero(y_test == 1) / len(y_test)
```

```ruby
0.6
```

ููุฐุง ุงููููุฐุฌุ ุงุณุชุฎุฏููุง ูุชุบูุฑ ูุงุญุฏ ูู ุนุฏุฏ ูุฎุชูู ูู ุงููุชุบูุฑุงุช ูู ูุฐู ุงูุจูุงูุงุช. ูู ุงููููุฐุฌ ุงูููุฌุณุชู ูุชุนุฏุฏ ุงููุชุบูุฑุงุชุ ุณูุญุตู ุนูู ูุชุงุฆุฌ ุฃูุซุฑ ุฏูุฉ ุจุงุณุชุฎุฏุงู ุฃูุซุฑ ูู ูุชุบูุฑ.

### ูููุฐุฌ ููุฌุณุชู ูุชุนุฏุฏ ุงููุชุบูุฑุงุช

ุงูุฒูุงุฏุฉ ูู ุนุฏุฏ ุงููุชุบูุฑุงุช ุงูุฑูููุฉ ูู ุงููููุฐุฌ ุณูู ุฌุฏุงู. ุนูู ุงูุนูุณุ ูููุชุบูุฑุงุช ูู ุงูููุน ุงูููุนู/ุงูุชุตููููุฉุ ูุญุชุงุฌ ูุชุทุจูู One-hot encoding. ูู ุงูููุฏ ุงูุจุฑูุฌู ุงูุชุงููุ ุฃุถููุง ุงููุฒูุฏ ูู ุงููุชุบูุฑุงุช ูููููุฐุฌ ููู `minute`ุ `opponent`ุ `action_type` ู `shot_type` ุจุงุณุชุฎุฏุงู ููุงุณ `DictVectorizer` ูู ููุชุจุฉ `scikit-learn` ูุชุทุจูู `One-hot encoding` ุนูู ุงููุชุบูุฑุงุช ุงูููุนูุฉ:

```python
from sklearn.feature_extraction import DictVectorizer

columns = ['shot_distance', 'minute', 'action_type', 'shot_type', 'opponent']
rows = lebron[columns].to_dict(orient='row')

onehot = DictVectorizer(sparse=False).fit(rows)
X = onehot.transform(rows)
y = lebron['shot_made'].values

X.shape
```

```ruby
(384, 42)
```

ุณูููู ูุฑุฉ ุฃุฎุฑู ุจุชูุณูู ุงูุจูุงูุงุช ุฅูู ุจูุงูุงุช ุชุฏุฑูุจ ู ุงุฎุชุจุงุฑ:

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=40, random_state=42
)
print(f'Training set size: {len(y_train)}')
print(f'Test set size: {len(y_test)}')
```

```ruby
Training set size: 344
Test set size: 40
```

ุฃุฎูุฑุงูุ ูููู ุจุถุจุท ุงููููุฐุฌ ูุฑุฉ ุฃุฎุฑู ููุชุญูู ูู ุงูุฏูุฉ:

```python
clf = LogisticRegression()
clf.fit(X_train, y_train)
print(f'Test set accuracy: {clf.score(X_test, y_test)}')
```

```ruby
Test set accuracy: 0.725
```

ุฏูุฉ ูุฐุง ุงููููุฐุฌ ุฃูุซุฑ ุจู 12% ูู ุงููููุฐุฌ ุงูุณุงุจู ุงูุฐู ูุณุชุฎุฏู ูุชุบูุฑ ูุงุญุฏ. ูู ุฌุฒุก ูุงุญูุ ุณูุณุชุฎุฏู ูุฒูุฏุงู ูู ุงูุฃุฏูุงุช ูุชูููู ุฃุฏุงุก ุงููููุฐุฌ.

### ููุฎุต ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู

ูููุง ุจุชุทููุฑ ุนูููุงุช ุญุณุงุจูุฉ ุฑูุงุถูุฉ ูุญุงุณูุจูุฉ ูุงุณุชุฎุฏุงู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ูู ุงูุชุตููู. ูุณุชุฎุฏู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุจุดูู ูุจูุฑ ูุณูููุชู ููุงุนููุชู ูู ุงูุชููุนุงุช.

## ุชูุฑูุจ ุงูุชูุฒูุน ุงูุงุญุชูุงูู ุงูุชุฌุฑูุจู

ูู ูุฐุง ุงูุฌุฒุก ูู ุงููุตูุ ุณูุชุนุฑู ุนูู **ุชุจุงุนุฏ KL (KL divergence)** ููุธูุฑ ููู ุฃู ุงูุชูููู ูู ูุชูุณุท ุงูุชุจุงุนุฏ KL ูู ุงูุชุตููู ุฐู ุงููุชุงุฆุฌ ุงูุซูุงุฆูุฉ (Binary 0/1) ููุงุซู ูุงุณุชุฎุฏุงู ุชูููู ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ. [๐][KLdivergence]

ุจูุง ุฃู ุงููุชุงุฆุฌ ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนุจุงุฑุฉ ุนู ุงุญุชูุงูุงุชุ ุงููููุฐุฌ ุงูููุฌุณุชู ููุชุฌ ููุง ููุนุงู ูุนูู ูู ุชูุฒูุน ุงูุงุญุชูุงูุงุช. ุจุดูู ุฎุงุตุ ุจูุงุกูุง ุนูู ุงููุชุบูุฑุงุช ุงููุซุงููุฉ $ \hat{\boldsymbol{\theta}} $ุ ูุฃูู ูููู ุจุชูููู ุงุญุชูุงููุฉ ุฃู ุงููุชูุฌุฉ $ y $ ุณุชููู $ 1 $ ููููุฉ ุงุฏุฎููุงูุง ูููููุฐุฌ $ \textbf{x} $.

ูุซูุงูุ ูููุชุฑุถ ุฃู $ x $ ูููู ุฑูููุฉ ุชุณุฌู ุงุญุชูุงููุฉ ุณููุท ุฃูุทุงุฑ ุงูููู ู $ y = 1 $ ุชุนูู ุฃู ุงูุณูุฏ ุฏู ูุญุชุงุฌ ูุฃุฎุฐ ูุธูุชู ูุนู ููุนูู. ุงููููุฐุฌ ุงูููุฌุณุชู ุฐู ุงููุชุบูุฑุงุช ุงูุฑูููุฉ $ \hat{\theta} $ ูุชููุน ุงุญุชูุงููุฉ ุฅุญุชูุงุฌ ุงูุณูุฏ ุฏู ูุฃุฎุฐ ูุธูุชู ูุนู ุฅูู ุงูุนูู ุจูุงุกูุง ุนูู ุชููุน ุณููุท ุงูุฃูุทุงุฑ ูุฐุง ุงูููู: $ \hat{P_\theta}(y = 1 \| x) $.

ุฌูุน ุจูุงูุงุช ุงุณุชุฎุฏุงู ุงูุณูุฏ ุฏู ููุธูุชู ูููุฑ ููุง ุทุฑููุฉ ูุจูุงุก ุชูุฒูุน ุฅุญุชูุงูู ุชุฌุฑูุจู $ P(y = 1 \| x) $. ูุซูุงูุ ุฅุฐุง ูุงู ููุงู ุฎูุณ ุฃูุงู ูุงูุช ูููุง ุงุญุชูุงููุฉ ุฃู ุญุงูุฉ ุงูุทูุณ ุณุชููู ูุงุทุฑ ูู $ x = 0.60 $ ููุงู ุงูุณูุฏ ุฏู ุจุฃุฎุฐ ูุธูุชู ูุฑู ูุงุญุฏุฉุ ูุฃู $ P(y = 1 \| x = 0.60) = 0.20 $. ูููููุง ุญุณุงุจ ุชูุฒูุน ููุงุซู ููุงุญุชูุงููุฉ ููู ูููุฉ $ x $ ุชุธูุฑ ูู ุจูุงูุงุชูุง. ุจุดูู ุทุจูุนูุ ุจุนุฏ ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู ูุฑูุฏ ุงู ุชููู ุชููุนุงุช ูููุฐุฌูุง ูุฑูุจุฉ ุฌุฏุงู ุฅูู ุงูุชูุฒูุน ุงูุงุญุชูุงูู ุงูุชุฌุฑูุจู ูู ุงูุจูุงูุงุช. ูุนูู ุฐููุ ููู ุงูููู $ x $ ูู ุงูุจูุงูุงุชุ ูุฑูุฏ:

 $$  \hat{P_\theta}(y = 1 \| x) \approx P(y = 1 | x)  $$ 

ุฃุญุฏ ุทุฑู ุงูููุงุณ ุงูุฃูุซุฑ ุงุณุชุฎุฏุงูุงู ูุชุญุฏูุฏ ูุฏู ูุฑุจ ูุชุงุฆุฌ ุชูุฒูุนุงุช ุงูุงุญุชูุงูุงู ูู **ุชุจุงุนุฏ ูููุจุงู - ููุจููุฑ KullbackโLeibler divergence** ุฃู ุชุจุงุนุฏ KL.

### ุชุนุฑูู ูุชูุณุท ุชุจุงุนุฏ KL

ูููู ุชุจุงุนุฏ KL ุจุญุณุงุจ ุงููุฑู ุจูู ุชูุฒูุน ุงุญุชูุงููุฉ $ \hat{P_\boldsymbol{\theta}} $ ุงูุชู ูุงู ุจุญุณุงุจูุง ุงููููุฐุฌ ุงูููุฌุณุชู ุจุงููุชุบูุฑุงุช $ \boldsymbol{\theta} $ ูุน ุงูุชูุฒูุน ุงูุญูููู ููููุงุท $ P $ ูู ุงูุจูุงูุงุช. ูููู ุจุญุณุงุจ ูุฏู ุนุฏู ุฏูุฉ ุชููุนุงุช ุงููููุฐุฌ ุงูููุฌุณุชู ูุชูุฒูุนุงุช ุงูุจูุงูุงุช.

ุชุจุงุนุฏ KL ูุชุตููู ุซูุงุฆู ูุชูุฒูุนูู $ P $ ู $ \hat{P_\boldsymbol{\theta}} $ ูููุทุฉ ูุงุญุฏุฉ $(\textbf{x}, y)$ ูู:

 $$  D(P || \hat{P_\boldsymbol{\theta}}) = P(y = 0 | \textbf{x}) \ln \left(\frac{P(y = 0 | \textbf{x})}{\hat{P_\boldsymbol{\theta}}(y = 0 | \textbf{x})}\right) + P(y = 1 | \textbf{x}) \ln \left(\frac{P(y = 1 | \textbf{x})}{\hat{P_\boldsymbol{\theta}}(y = 1 | \textbf{x})}\right)  $$ 

ุชุจุงุนุฏ KL ููุณ ูุชูุงุณูุ ูุซูุงู ุชุจุงุนุฏ $ \hat{P_\boldsymbol{\theta}} $ ุนู $ P $ ููุณ ููุณ ุชุจุงุนุฏ $ P $ ุนู $ \hat{P_\boldsymbol{\theta}} $: 

 $$  D(P || \hat{P_\boldsymbol{\theta}}) \neq D(\hat{P_\boldsymbol{\theta}} || P)  $$ 

ุจูุง ุฃู ูุฏููุง ูู ุงุณุชุฎุฏุงู $ \hat{P_\boldsymbol{\theta}} $ ููุชููุน ุงูุชูุฑูุจู ูู $ P $ุ ููุญู ููุชููู ุจู $ D(P \\| \hat{P_\boldsymbol{\theta}}) $.

ุงูููู ุงููุซุงููุฉ ูู $ \boldsymbol{\theta} $ุ ูุงูุชู ุฃุดุฑูุง ููุง ุจู $ \hat{\boldsymbol{\theta}} $ุ ุชููู ูู ูุชูุณุท ุชุจุงุนุฏ KL ูุฌููุน ููุงุท ุงูุจูุงูุงุช $ n $:

 $$  \text{Average KL Divergence} = \frac{1}{n} \sum_{i=1}^{n} \left(P(y_i = 0 | \textbf{X}_i) \ln \left(\frac{P(y_i = 0 | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = 0 | \textbf{X}_i)}\right) + P(y_i = 1 | \textbf{X}_i) \ln \left(\frac{P(y_i = 1 | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = 1 | \textbf{X}_i)}\right)\right) $$ 

 $$  \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\boldsymbol{\theta}}} (\text{Average KL Divergence})  $$ 

ูู ุงููุนุงุฏูุฉ ุงูุณุงุจูุฉุ ุงูููุทุฉ $i^{\text{th}} $ ูู ููุงุท ุงูุจูุงูุงุช ุฃุดูุฑ ููุง ุจู ($ \textbf{X}_i $, $ y_i $) ูููุง $ \textbf{X}_i $ ูู ุงูุณุทุฑ $i^{\text{th}} $ ูู ุงูุจูุงูุงุช $n \times p$ ูู ูุตูููุฉ ุงูุจูุงูุงุช $ \textbf{X} $ ู $ y_i $ ูู ุงููุชุงุฆุฌ ุงูุชู ุณุจู ุฃู ุฃุทูุน ุนูููุง.

ูุง ูุนุงูุจ ุชุจุงุนุฏ KL ุงูููู ุงูุดุงุฐุฉ ูุงููุงุฏุฑ ุญุฏูุซูุง ูู $ P $. ุฅุฐุง ุชููุน ุงููููุฐุฌ ุงุญุชูุงููุฉ ุนุงููุฉ ูุญุฏุซ ูุงุฏุฑ ุงูุญุฏูุซุ ูุฅู ูููููุง $ P(k) $ ู $ \ln \left(\frac{P(k)}{\hat{P_\boldsymbol{\theta}}(k)}\right) $ ุงูุชุจุงุนุฏ ุจููููุง ูููู. ููููุ ุฅุฐุง ุชููุน ุงููููุฐุฌ ุงุญุชูุงููุฉ ุถุฆููุฉ ูุญุฏุซ ูุซูุฑ ุงูุญุฏูุซุ ูุฅู ุงูุชุจุงุนุฏ ููู ุนุงูู. ูููู ุฃู ูุณุชูุชุฌ ุฃู ุงููููุฐุฌ ุงูููุฌุณุชู ุงูุฐู ูููู ุจุชููุนุงุช ุตุญูุญุฉ ูุฃุญุฏุงุซ ูุซูุฑุฉ ุงูุญุฏูุซ ูุฏูุฉ ุชุจุงุนุฏ ูููู ูู $ P $ ุนูู ุนูุณ ูููุฐุฌ ูุชููุน ุฃุญุฏุงุซ ูุงุฏุฑุฉ ุงูุญุฏูุฏ ูููู ูุฎุชูู ุจุดูู ูุจูุฑ ูู ุงูุฃุญุฏุงุซ ูุซูุฑุฉ ุงูุญุฏูุซ.

### ุงุณุชูุชุงุฌ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูู ุชุจุงุนุฏ KL

ุชุชุดุงุจู ุจุดูู ูุจูุฑ ุงููุนุงุฏูุฉ ุงูุณุงุจูุฉ ูุชุจุงุนุฏ KL ูุน ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ. ุณูุนุฑุถ ุงูุขู ูู ุจุนุถ ุงูุนูููุงุช ุงูุฑูุงุถูุฉ ุงูุฌุจุฑูุฉ ุฃู ุชูููู ูุชูุณุท ุชุจุงุนุฏ KL ูุดุงุจู ุชูููู ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ.

ุจุงุณุชุฎุฏุงู ุฎุตุงุฆุต ุงูููุบุงุฑูุชูุงุชุ ูููููุง ุฅุนุงุฏุฉ ูุชุงุจุฉุ ูููููุง ุฅุนุงุฏุฉ ุงููุชุงุจุฉ ูุงูุชุงูู:

 $$ P(y_i = k | \textbf{X}_i) \ln \left(\frac{P(y_i = k | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = k | \textbf{X}_i)}\right) = P(y_i = k | \textbf{X}_i) \ln P(y_i = k | \textbf{X}_i) - P(y_i = k | \textbf{X}_i) \ln \hat{P_\boldsymbol{\theta}}(y_i = k | \textbf{X}_i) $$ 

ูุงุญุธ ุจูุง ุฃู ุงููุตุทูุญ ุงูุฃูู ูุง ูุนุชูุฏ ุนูู $ \boldsymbol{\theta} $ุ ูุฃูู ูุง ูุคุซุฑ ุนูู $ \displaystyle\arg \min_{\substack{\boldsymbol{\theta}}} $ ููููู ุญุฐูู ูู ุงููุนุงุฏูุฉ. ุงููุนุงุฏูุฉ ุงููุงุชุฌุฉ ุจุนุฏ ุฐูู ุญู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูููููุฐุฌ $ \hat{P_\boldsymbol{\theta}} $:

 $$  \text{Average Cross-Entropy Loss} = \frac{1}{n} \sum_{i=1}^{n} - P(y_i = 0 | \textbf{X}_i) \ln \hat{P_\theta}(y_i = 0 | \textbf{X}_i) - P(y_i = 1 | \textbf{X}_i) \ln \hat{P_\theta}(y_i = 1 | \textbf{X}_i) $$ 

 $$  \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\theta}} (\text{Average Cross-Entropy Loss})  $$ 

ุจูุง ุฃู $y_i$ ูู ูููู ูุนุฑููุฉุ ูุฅู ุงุญุชูุงููุฉ $y_i = 1$ุ $P(y_i = 1 \| \textbf{X}_i)$ ุชุณุงูู $y_i$ ู $P(y_i = 0 \| \textbf{X}_i)$ ุชุณุงูู $1 - y_i$. ุชูุฒูุน ุงุญุชูุงููุงุช ุงููููุฐุฌ $ \hat{P_\boldsymbol{\theta}} $ ูุนุทุงุฉ ูู ูุชุงุฆุฌ ุงูุฏุงูุฉ ุงูุณูููุฉ ุงูุชู ุณุจู ุฃู ุชุนุฑููุง ุนูููุง ูู ุฌุฒุฆูุฉ ุณุงุจูุฉ. ุจุนุฏ ุงูููุงู ุจุชูู ุงูุชุนููุถุงุช ูู ุงููุนุงุฏูุฉุ ูุตู ุฅูู ูุนุงุฏูุฉ ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ:

 $$  \text{Average Cross-Entropy Loss} = \frac{1}{n} \sum_i \left(- y_i \ln (f_\hat{\boldsymbol{\theta}}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\hat{\boldsymbol{\theta}}(\textbf{X}_i) \right)  $$ 

 $$  \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\theta}} (\text{Average Cross-Entropy Loss})  $$ 

### ุงูุชุจุฑูุฑ ุงูุฅุญุตุงุฆู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ูุฏู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ุฃูุถุงู ุฃุณุณ ุฃุณุงุณูุฉ ูู ุนูู ุงูุฅุญุตุงุก. ุจูุง ุฃู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ูุชููุน ุงุญุชูุงูุงุชุ ูู ุณููู ููุง ูููุฐุฌ ููุฌุณุชู ูููููุง ุฃู ูุณุฃูุ "ูุง ูู ุงุญุชูุงููุฉ ุฃู ูุฐุง ุงููููุฐุฌ ูููู ููุง ุชูู ุงููุฌููุนุฉ ูู ุงูุจูุงูุงุช ุงูุชู ุณุจู ุฃู ุงุทูุน ุนูููุง $ y $ุ" ูููููุง ุจุดูู ุทุจูุนู ุงูุชุนุฏูู ูู ุงููุชุบูุฑุงุช ูููููุฐุฌ ุญุชู ุชููู ุงุญุชูุงููุฉ ุญุตูููุง ุนูู ุจูุงูุงุชูุง ููุชุงุฆุฌ ูู ุงููููุฐุฌ ุนุงููุฉ ุฌุฏุงู. ุนูู ุงูุฑุบู ูู ุฃููุง ูู ูุซุจุช ุฐูู ูู ูุฐุง ุงููุตูุ ูููู ุชุทุจูู ุฐูู ูุดุงุจู ููุชูููู ูู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉุ ูุฐุง ุงูุชูุณูุฑ ุงูุฅุญุตุงุฆู ูู *ุฃูุตู ุงุญุชูุงู maximum likelihood* ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ.
### ููุฎุต ุชุจุฑูุฑ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ

ูููู ุงูููู ุงู ูุชูุณุท ุชุจุงุนุฏ KL ูู ูุชูุณุท ุงููุฑู ุงูููุบุงุฑุชูู ุจูู ุชูุฒูุนุงู $ P $ ู $ \hat{P_\boldsymbol{\theta}} $ ุชู ูุฒููุง ุจุงุณุชุฎุฏุงู $ P $. ุงูุชูููู ูู ูุชูุณุท ุชุจุงุนุฏ KL ุฃูุถุงู ูููู ูู ูุชูุณุท ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ. ูููููุง ุงูุชูููู ูู ุชุจุงุนุฏ ูููุฐุฌ ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนู ุทุฑูู ุงุฎุชูุงุฑ ุงููุชุบูุฑุงุช ุงูุชู ุชุตูู ุงูุจูุงูุงุช ุงูุดุงุฆุนุฉ ุจุดูู ุตุญูุญ.

## ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู

ุชุญุฏุซูุง ูู ุฌุฒุก ุณุงุจู ุนู **ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช Batch Gradient Descent**ุ ุฅุญุฏู ุงูุฎูุงุฑุฒููุงุช ุงูุชู ุชููู ุจุชุญุฏูุซ ูููุฉ $ \boldsymbol{\theta} $ ุจุดูู ูุชูุฑุฑ ุญุชู ูููุฉ ุงููุชุบูุฑ $ \boldsymbol{\hat\theta} $ ุงูุชู ุชููู ูู ุงูุฎุณุงุฑุฉ. ู ุฃูุถุงูู ุชุญุฏุซูุง ุนู **ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู Stochastic Gradient Descent** ู **ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉ Mini-Batch Gradient Descent**ุ ููููุง ุทูุฑู ุชุณุชููุฏ ูู ุงููุธุฑูุฉ ุงูุฅุญุตุงุฆูุฉ ูุงูุญูุณุจุฉ ุงูููุชูุงุฒูุฉ ููุชูููู ูู ุงูููุช ูุชุฏุฑูุจ ุฎูุงุฑุฒููุฉ ุงููุฒูู ุงูุงุดุชูุงูู. ูู ูุฐุง ุงูุฌุฒุกุ ุณูุทุจู ูุฐู ุงูููุงููู ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ููุฃุฎุฐ ุฃูุซูุฉ ุนูู ุฐูู ุจุงุณุชุฎุฏุงู ุฏูุงู ููุชุจุฉ `scikit-learn`.

### ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช

ุฏุงูุฉ ุงูุชุญุฏูุซ ุงูุนุงูุฉ ูู ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช ูุนุทุงุฉ ูุงูุชุงูู:

 $$ 
\boldsymbol{\theta}^{(t+1)} = \boldsymbol{\theta}^{(t)} - \alpha \cdot \nabla_\boldsymbol{\theta} L(\boldsymbol{\theta}^{(t)}, \textbf{X}, \textbf{y})
 $$ 

ูู ุงูุงูุญุฏุงุฑ ุงูุฎุทูุ ูุณุชุฎุฏู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุฏุงูุฉ ุฎุณุงุฑุฉ:

 $$ 
L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) = \frac{1}{n} \sum_{i=1}^{n} \left(-y_i \ln \left(f_{\boldsymbol{\theta}} \left(\textbf{X}_i \right) \right) - \left(1 - y_i \right) \ln \left(1 - f_{\boldsymbol{\theta}} \left(\textbf{X}_i \right) \right) \right)
 $$ 

ุงูุงุดุชูุงู ูุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูู
 $$  \nabla_{\boldsymbol{\theta}} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) = -\frac{1}{n}\sum_{i=1}^n(y_i - \sigma_i)\textbf{X}_i  $$ . ุชุนููุถ ุฐูู ูู ุฏุงูุฉ ุงูุชุญุฏูุซ ูุณูุญ ููุง ุจุฅูุฌุงุฏ ุฎูุงุฑุฒููุฉ ุงููุฒูู ุงูุงุดุชูุงูู ุงูุฎุงุตุฉ ููุงูุญุฏุงุฑ ุงูููุฌุณุชู. ุจุฌุนู  $$  \sigma_i = f_\boldsymbol{\theta}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \boldsymbol{\theta})  $$ :


 $$ 
\begin{align}
\boldsymbol{\theta}^{(t+1)} &= \boldsymbol{\theta}^{(t)} - \alpha \cdot \left(- \frac{1}{n} \sum_{i=1}^{n} \left(y_i - \sigma_i\right) \textbf{X}_i \right) \\
&= \boldsymbol{\theta}^{(t)} + \alpha \cdot \left(\frac{1}{n} \sum_{i=1}^{n} \left(y_i - \sigma_i\right) \textbf{X}_i \right)
\end{align}
 $$ 

- $ \boldsymbol{\theta}^{(t)} $ ูู ุงููููุฉ ุงูุญุงููุฉ ุงูููุฏุฑุฉ ูู $ \boldsymbol{\theta} $ ูู ุงูุชูุฑุงุฑ $t$.
- $ \alpha$ ูู ูุนุฏู ุงูุชุนูู.
- $-\frac{1}{n} \sum_{i=1}^{n} \left(y_i - \sigma_i\right) \textbf{X}_i$ ูู ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ.
- $ \boldsymbol{\theta}^{(t+1)} $ ูู ุงููููุฉ ุงูููุฏุฑุฉ ุงูุชุงููุฉ ูู $ \boldsymbol{\theta} $ ูุงูุชู ุชู ุญุณุงุจูุง ุจุทุฑุญ ูุชูุฌุฉ ุถุฑุจ $ \alpha$ ู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ุงูุชู ุชู ุญุณุงุจูุง ูู $ \boldsymbol{\theta}^{(t)} $.

### ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู

ููุฑุจ ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู ูู ูุดุชูุฉ ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูู ุฌููุน ุงูููุงุท ุจุงุณุชุฎุฏุงู ูุณุชุดูู ุงูุฎุณุงุฑุฉ ูููุทุฉ ูุงุญุฏุฉ. ุฏุงูุฉ ุงูุชุญุฏูุซ ุงูุนุงูุฉ ูุงูุชุงููุ ููููุง $ \ell(\boldsymbol{\theta}, \textbf{X}_i, y_i)$ ูู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูููุทุฉ ูุงุญุฏุฉ: [๐][StochasticGradientDescent]

 $$ 
\boldsymbol{\theta}^{(t+1)} = \boldsymbol{\theta}^{(t)} - \alpha \nabla_\boldsymbol{\theta} \ell(\boldsymbol{\theta}, \textbf{X}_i, y_i)
 $$ 

ุจุงูุนูุฏุฉ ูููุซุงู ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชูุ ูููู ุจุชูุฑูุจ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุฌููุน ุงูููุงุท ุจุงุณุชุฎุฏุงู ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูููุทุฉ ูุงุญุฏุฉ. ูุธูุฑ ุฐูู ูู ุงููุนุงุฏูุฉ ุงูุชุงููุฉุ ูุงูุชู ูููุง $ \sigma_i = f_{\boldsymbol{\theta}}(\textbf{X}_i) = \sigma(\textbf{X}_i \cdot \boldsymbol{\theta}) $:

 $$ 
\begin{align}
\nabla_\boldsymbol{\theta} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) &\approx \nabla_\boldsymbol{\theta} \ell(\boldsymbol{\theta}, \textbf{X}_i, y_i)\\
&= -(y_i - \sigma_i)\textbf{X}_i
\end{align}
 $$ 

ุนูุฏูุง ูููู ุจุชุนููุถ ุงูุชูุฑูุจ ุฅูู ุงููุนุงุฏูุฉ ุงูุนุงูุฉ ูููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆูุ ุชุชููู ููุง ุฏุงูุฉ ุงูุชุญุฏูุซ ูููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู ููุงูุญุฏุงุฑ ุงูููุฌุณุชู:

 $$ 
\begin{align}
\boldsymbol{\theta}^{(t+1)} &= \boldsymbol{\theta}^{(t)} - \alpha \nabla_\boldsymbol{\theta} \ell(\boldsymbol{\theta}, \textbf{X}_i, y_i) \\
&= \boldsymbol{\theta}^{(t)} + \alpha \cdot (y_i - \sigma_i)\textbf{X}_i
\end{align}
 $$ 

### ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉ

ุจุดูู ููุงุซูุ ูููููุง ุชูุฑูุจ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ูุฌููุน ุงูููุงุท ุจุงุณุชุฎุฏุงู ุนููุฉ ุนุดูุงุฆูุฉ ูู ุงูุจูุงูุงุชุ ุชุนุฑู ุฃูุถุงู ุจุงูุฏูุนุงุช ุงูุตุบูุฑุฉ. [๐][MiniBatchGradientDescent]

 $$ 
\nabla_\boldsymbol{\theta} L(\boldsymbol{\theta}, \textbf{X}, \textbf{y}) \approx \frac{1}{|\mathcal{B}|} \sum_{i\in\mathcal{B}}\nabla_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta}, \textbf{X}_i, y_i)
 $$ 

ูููู ุจุชุนููุถ ูุฐุง ุงูุชูุฑูุจ ููุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉุ ููุชุฌ ุนู ุฐูู ุฏุงูุฉ ุงูุชุญุฏูุซ ูููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉ ููุงูุญุฏุงุฑ ุงูููุฌุณุชู:

 $$ 
\begin{align}
\boldsymbol{\theta}^{(t+1)} &= \boldsymbol{\theta}^{(t)} - \alpha \cdot -\frac{1}{|\mathcal{B}|} \sum_{i\in\mathcal{B}}(y_i - \sigma_i)\textbf{X}_i \\
&= \boldsymbol{\theta}^{(t)} + \alpha \cdot \frac{1}{|\mathcal{B}|} \sum_{i\in\mathcal{B}}(y_i - \sigma_i)\textbf{X}_i
\end{align}
 $$ 

### ุงูุชุทุจูู ูู ููุชุจุฉ Scikit-learn

ุงูููุงุณ [`SGDClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) ูู ููุชุจุฉ `scikit-learn` ูุณุงุนุฏ ุนูู ุชูููุฐ ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆูุ ูููููุง ุงุณุชุฎุฏุงูู ุจุชุญุฏูุฏ `loss=log`. ุจูุง ุฃู `scikit-learn` ูุง ุชุญุชูู ุนูู ูููุฐุฌ ูุชุทุจูู ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช ุตุบูุฑุฉุ ุณูููู ุจููุงุฑูุฉ ุฃุฏุงุก `SGDClassifier` ูุน [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) ุนูู ุจูุงูุงุช ุงูุจุฑูุฏ ุงูุฅููุชุฑููู `emails_sgd.csv`. ุณูุฎุชุตุฑ ุฌุฒุฆูุฉ ุงุฎุชูุงุฑ ุงูุฎุตุงุฆุต ููู ูุดุฑุญูุง:

> ูุชุญููู ุงูุจูุงูุงุช emails_sgd.csv [ุงุถุบุท ููุง]({{ site.baseurl }}/files/chapter17/emails_sgd.csv).


```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier


# ุชุญููู ุงูุจูุงูุงุช
emails = pd.read_csv('emails_sgd.csv').sample(frac=0.5)

# ุฅุฎุชูุงุฑ ุงูุฎุตุงุฆุต ุซู ุชุญููููุง ูููู ุฑูููุฉ
X, y = emails['email'], emails['spam']
X_tr = CountVectorizer().fit_transform(X)

# ุชูุณูู ุงูุจููุงุงุช ูุชุฏุฑูุจ ูุฅุฎุชุจุงุฑ
X_train, X_test, y_train, y_test = train_test_split(X_tr, y, random_state=42)

y_train = y_train.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)

# ุถุจุท ุงููููุฐุฌุงู
log_reg = LogisticRegression(tol=0.0001, random_state=42)
stochastic_gd = SGDClassifier(tol=0.0001, loss='log', random_state=42)
```

```python
%%time

from sklearn.metrics import accuracy_score, precision_score, recall_score

log_reg.fit(X_train, y_train)
log_reg_pred = log_reg.predict(X_test)
print('Logistic Regression')
print('  Accuracy:  ', accuracy_score(y_test, log_reg_pred))
print('  Precision: ', precision_score(y_test, log_reg_pred))
print('  Recall:    ', recall_score(y_test, log_reg_pred))
print()
```

```ruby
Logistic Regression
  Accuracy:   0.9913793103448276
  Precision:  0.974169741697417
  Recall:     0.9924812030075187

CPU times: user 3.2 s, sys: 0 ns, total: 3.2 s
Wall time: 3.26 s
```

```python
%%time

stochastic_gd.fit(X_train, y_train)
stochastic_gd_pred = stochastic_gd.predict(X_test)
print('Stochastic GD')
print('  Accuracy:  ', accuracy_score(y_test, stochastic_gd_pred))
print('  Precision: ', precision_score(y_test, stochastic_gd_pred))
print('  Recall:    ', recall_score(y_test, stochastic_gd_pred))
print()
```

```ruby
Stochastic GD
  Accuracy:   0.9808429118773946
  Precision:  0.9392857142857143
  Recall:     0.9887218045112782

CPU times: user 93.8 ms, sys: 31.2 ms, total: 125 ms
Wall time: 119 ms
```

ุงููุชุงุฆุฌ ุงูุณุงุจูุฉ ุชุธูุฑ ุฃู ุงููููุฐุฌ `SGDClassifier` ุงุณุชุทุงุน ุฅูุฌุงุฏ ูุชูุฌุฉ ูู ููุช ุฃูู ูู `LogisticRegression`. ุนูู ุงูุฑุบู ูู ุฃู ูุชุงุฆุฌ ุชูููู ุงููููุฐุฌ `SGDClassifier` ุฃุณูุฃ ููููุงูุ ุฅูุง ุฃููุง ูุณุชุทูุน ุชุญุณูู ุฃุฏุงุฉ ุงููููุฐุฌ `SGDClassifier` ุนุจุฑ ุถุจุท ุงูุฎุตุงุฆุต. ุฃูุถุงูุ ูุฐู ูู ุงูููุงูุถุงุช ุงูุชู ุนุงุฏุฉ ูุง ููุงุฌููุง ุนุงูู ุงูุจูุงูุงุช. ุจูุงุกูุง ุนูู ุงููุถุนุ ูููู ุนุงูู ุงูุจูุงูุงุช ุจุฅุนุทุงุก ูููุฉ ุฃุนูู ูุณุฑุนุฉ ุฅูุฌุงุฏ ุงููุชุงุฆุฌ ุนู ุฃุฏุงุก

### ููุฎุต ุถุจุท ุงููููุฐุฌ ุงูููุฌุณุชู

ูุณุชุฎุฏู ุนููุงุก ุงูุจูุงูุงุช ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู ููุชูููู ูู ุชูููุฉ ุงูุชุดุบูู ูุงูููุช. ูููููุง ูุดุงูุฏุฉ ุฐูู ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชูุ ุจูุง ุฃู ุนูููุง ููุท ุญุณุงุจ ูุดุชูุฉ ุฎุณุงุฑุฉ ุงูุงูุชุฑูุจูุง ุงูุชูุงุทุนูุฉ ููููุฉ ูุงุญุฏุฉ ูู ูู ุชูุฑุงุฑ ุจุฏูุงู ูู ูู ุงูููู ูู ุงููุฒูู ุงูุงุดุชูุงูู ุจุฏูุนุงุช. ูู ุงููุซุงู ุงูุณุงุจู ุนูุฏ ุงุณุชุฎุฏุงู `scikit-learn` ูุงููููุฐุฌ `SGDClassifier`ุ ุฑุฃููุง ุฃู ุงููุฒูู ุงูุงุดุชูุงูู ุงูุนุดูุงุฆู ูุงูุช ูุชุงุฆุฌ ุฃุฏุงุกู ุฃุณูุฃ ุจุนุถ ุงูุดูุกุ ูููู ูุฃู ุฃูุถู ูู ูุงุญูุฉ ุงูููุช ูุงูุณุฑุนุฉ ุจุดูู ูุจูุฑ. ูู ุจูุงูุงุช ุจุญุฌู ูุจูุฑ ู ููุงุฐุฌ ุฃูุซุฑ ุชุนููุฏุงูุ ุงููุฑู ูู ุงูููุช ูุณุฑุนุฉ ุฅูุฌุงุฏ ุงููุชุงุฆุฌ ูุฏ ูููู ุฃูุจุฑ ุจูุซูุฑ ูุจุฐูู ูููู ุฃูุซุฑ ุฃูููุฉ.

## ุชูููู ุงููููุฐุฌ ุงูููุฌุณุชู

ุนูู ุงูุฑุบู ูู ุงุณุชุฎุฏุงููุง ููุฏูุฉ Accuracy ูุชูููู ุฃุฏุงุฉ ุงููููุฐุฌ ุงูููุฌุณุชู ูู ุงูุฌุฒุก ุงูุณุงุจูุ ุงุณุชุฎุฏุงู ุงูุฏูุฉ ููุท ูุณุจุจ ุจุนุถ ุงููุดุงูู ุงูุชู ุณูุชุทุฑู ููุง ูู ูุฐุง ุงูุฌุฒุก ูู ุงููุตู. ููุจุฏุก ูู ุงูุชุญุฏุซ ุนู ูุฐู ุงููุดุงููุ ุณูุชุนุฑู ุนูู ุฃุฏุงุฉ ุฃุฎุฑู ูููุงุณ ุฃุฏุงุก ุงููููุฐุฌ: **ุงููุณุงุญุฉ ุฃุณูู ุงูููุญูู Area Under Curve (AUC)**. [๐][ROCAUC] 

ูููุชุฑุถ ุฃู ูุฏููุง ุจูุงูุงุช 1000 ุจุฑูุฏ ุฅููุชุฑููู ูุชู ุชุญุฏูุฏูุง ุฅุฐุง ูุงูุช ุฑุณุงุฆู ุจุฑูุฏ ูุฒุนุฌุฉ ุฃู ูุง ููุฏููุง ูู ุจูุงุก ูููุฐุฌ ูููุฑู ุจูู ุงูุฑุณุงุฆู ุงูุฌุฏูุฏุฉ ุงูุชู ุชุตู ููุง ูุง ุฅุฐุง ูุงูุช ูุฒุนุฌุฉ ุฃู ูุง. ููุณุชุนุฑุถ ุงูุจูุงูุงุช:

> ูุชุญููู ุงูุจูุงูุงุช selected_emails.csv [ุงุถุบุท ููุง]({{ site.baseurl }}/files/chapter17/selected_emails.csv).

```python
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import pandas as pd

emails=pd.read_csv('selected_emails.csv', index_col=0)

emails
```

**spam**|**body**| 
:-----:|:-----:|:-----:
0|\n Hi Folks,\n \n I've been trying to set a bu...|0
0|Hah. I guess she doesn't want everyone to kno...|1
0|This article from NYTimes.com \n has been sent...|2
...|...|...
1|<html>\n <head>\n <meta http-equiv="Conten...|997
1|<html>\n <head>\n </head>\n <body>\n \n <cente...|998
1|\n <html>\n \n <head>\n <meta http-equiv=3D"Co...|999

```ruby
1000 rows ร 2 columns
```

ูู ุณุทุฑ ูุญุชูู ุนูู ูุญุชูู ุฑุณุงูุฉ ุงูุจุฑูุฏ ุงูุฅููุชุฑููู ูู ุงูุนููุฏ `body` ููุง ุฅุฐุง ูุงูุช ุฑุณุงูุฉ ุงูุจุฑูุฏ ูุฒุนุฌุฉ ุฃู ูุง ูู ุงูุนููุฏ `spam`ุ ููู `0` ูุนูู ุฃู ุงูุฑุณุงูุฉ ุณูููุฉ ู `1` ูุนูู ุฃู ุงูุฑุณุงูุฉ ููุฒุนุฌุฉ.

ููุจุฏุฃ ุจุชูููู ุฃุฏุงุก 3 ููุงุฐุฌ ูุฎุชููุฉ:
- `ham_only`: ูููู ูู ุฑุณุงูุฉ ุจุฑูุฏ ุจุฃููุง ุบูุฑ ูุฒุนุฌุฉ "ham".
- `spam_only`: ูููู ูู ุฑุณุงูุฉ ุจุฑูุฏ ุจุฃููุง ูุฒุนุฌุฉ "spam".
- `words_list_model`: ูุชููุน ุงูุฑุณุงูุฉ ูุฒุนุฌุฉ ุฃู ูุง ุจูุงุกูุง ุนูู ุชููุฑ ูููุงุช ูุนููุฉ ูู ูุญุชูุงูุง.

ูููุชุฑุถ ุฃู ูุฏููุง ูุตูููุฉ ูููููุงุช `words_list` ูุชููุน ุฃููุง ุชุณุชุฎุฏู ูุซูุฑุงู ูู ุงูุฑุณุงุฆู ุงููุฒุนุฌุฉ: "ุฑุฌุงุกูุง please"ุ "ุฃุถุบุท click"ุ "ูุงู money"ุ "ุชุฌุงุฑุฉ business"ุ ู "ุญุฐู remove". ูุจูู ูููุฐุฌ `words_list_model` ุจุงุณุชุฎุฏุงู ุงูุฎุทูุงุช ุงูุชุงููุฉ: ุชุญููู ูู ุฑุณุงูุฉ ุจุฑูุฏ ุฅูู ูุตูููุฉ ูู ุงูุฎุตุงุฆุตุ ุจุนุฏ ูุตู ุงููููุงุช ูุญุฏุฏ ุงููููุฉ ุฅูู 1 ูู ุญุงู ููุฌุฏุช ุงููููุฉ ูู ูุงุฆูุฉ ุงููููุงุช `words_list` ู 0 ุฅุฐุง ูู ุชูู ููุฌูุฏุฉ. ูุซูุงูุ ุนูุฏูุง ูุณุชุฎุฏู ุงูุฎูุณ ูููุงุช ุงูุณุงุจูุฉ ูุฅุฐุง ูุตูุช ููุง ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ูุญุชูุงูุง โplease remove by tomorrowโุ ูุฅู ูุตูููุฉ ุงูุฎุตุงุฆุต ุงููุงุชุฌุฉ ุณุชููู $ [1, 0, 0, 0, 1] $. ุชุทุจูู ุฐูู ููุชุฌ ููุง ูุตูููุฉ ุฎุตุงุฆุต $ \textbf{X} $ ุฐุงุช ุญุฌู `1000 X 5`.

ุงูููุฏ ุงูุจุฑูุฌู ุงูุชุงูู ูุธูุฑ ุฏูุฉ ุงูููุงุฐุฌ. ุชู ุชุฌุงูู ุดุฑุญ ุฌุฒุฆูุฉ ุฅูุดุงุก ุงูููุงุฐุฌ ูุชุฏุฑูุจูุง ููุงุฎุชุตุงุฑ:

```python
# ุชุญุฏูุฏ ูููุงุช ุงูุฑุณุงุฆู ุงููุฒุนุฌุฉ
words_list = ['please', 'click', 'money', 'business', 'remove']

X = pd.DataFrame(words_in_texts(words_list, emails['body'].str.lower())).values
y = emails['spam'].values

# ูุตู ุงูุจูุงูุงุช ูุชุฏุฑูุจ ูุฅุฎุชุจุงุฑ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, random_state=41, test_size=0.2
)

# ุถุจุท ุงููููุฐุฌ
words_list_model = LogisticRegression(fit_intercept=True)
words_list_model.fit(X_train, y_train)

y_prediction_words_list = words_list_model.predict(X_test)
y_prediction_ham_only = np.zeros(len(y_test))
y_prediction_spam_only = np.ones(len(y_test))


print(f'ham_only test set accuracy: {np.round(accuracy_score(y_prediction_ham_only, y_test), 3)}')
print(f'spam_only test set accuracy: {np.round(accuracy_score(y_prediction_spam_only, y_test), 3)}')
print(f'words_list_model test set accuracy: {np.round(accuracy_score(y_prediction_words_list, y_test), 3)}')
```

```ruby
ham_only test set accuracy: 0.96
spam_only test set accuracy: 0.04
words_list_model test set accuracy: 0.96
```

> ูู ุงููุซุงู ุงูุณุงุจูุ ุนุฑู ุงููุงุชุจ ุงูุฏุงูุฉ `words_in_texts` ูุงูุชู ุชุณุชูุจู ุงููููุงุช ูุงููุต ููุชุบูุฑุงุช ุนูู ุดูู ูุตูููุงุชุ ููุชูุฌุชูุง ูุตูููุฉ ูู 0 ู 1ุ 0 ูู ุญุงู ูู ุชูู ุงููููุฉ ููุฌูุฏุฉ ูู ุงููุตุ ู 1 ูู ุญุงู ูุงูุช ููุฌูุฏุฉ:
>
> ```python
>def words_in_texts(words, texts):
>    indicator_array = np.array([texts.str.contains(word) * 1 for word in words]).T
>
>    return indicator_array
> ```
>

ุงููููุฐุฌ `words_list_model` ูุงู ุชุตูููู ุตุญูุญ ุจูุณุจุฉ 96% ุนูู ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ. ุนูู ุงูุฑุบู ูู ุฃู ุงูุฏูุฉ ููุฐุง ุงููููุฐุฌ ุชุจุฏู ุนุงููุฉุ ุฅูุง ุฃู ุงููููุฐุฌ `ham_only` ุญุตู ุนูู ููุณ ุงููุชูุฌุฉ ุนู ุทุฑูู ุชุญุฏูุฏ ูู ุงูุฑุณุงุฆู ูุฑุณุงุฆู ุบูุฑ ูุฒุนุฌุฉ. ูุณุจุจ ุฐูู ุจุนุถ ุงููุดุงูู ูุฃู ุงููุชุงุฆุฌ ูุฐู ุชูุถุญ ุฃู ุจุฅููุงููุง ุงูุญุตูู ุนูู ููุณ ุงููุชุงุฆุฌ ุฏูู ุงุณุชุฎุฏุงู ูููุฐุฌ ูููุชุฑุฉ ุงูุฑุณุงุฆู.

ููุง ุชุธูุฑ ูุชุงุฆุฌ ุงูุฏูุฉ ุงูุณุงุจูุฉุ ูุฏ ุชุถูููุง ุจุนุถ ูุชุงุฆุฌ ุฃุฏุงุก ุงูููุงุฐุฌ. ูููููุง ุงูุชุฃูุฏ ูู ุฏูุฉ ุชููุนุงุช ุงููููุฐุฌ ุจุดูู ุฃุฏู ุจุงุณุชุฎุฏุงู **ูุตูููุฉ ุงูุฏูุฉ Confusion Matrix**. ูุตูููุฉ ุงูุฏูุฉ ููููุฐุฌ ุซูุงุฆู ุงููุชุงุฆุฌ (0/1) ูู ุฎุฑูุทุฉ ุญุฑุงุฑูุฉ heatmap ุฐุงุช ููุงุณุงุช 2ร2 ุชุญุชูู ุนูู ูุชุงุฆุฌ ุงูุชููุนุงุช ูู ูุญูุฑ ู ุงููุชุงุฆุฌ ุงูุญููููุฉ ูู ุงููุญูุฑ ุงูุขุฎุฑ.

ูู ูููุฉ ูู ูุตูููุฉ ุงูุฏูุฉ ุนุจุงุฑุฉ ุนู ุงููุชุงุฆุฌ ุงููุญุชููุฉ ูููููุฐุฌ. ุฅุฐุง ุชู ุฅุฏุฎุงู ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ูุฒุนุฌุฉ ุฅูู ุงููููุฐุฌุ ูุฅู ูุฏููุง ุงุญุชูุงูุงู:

- **True Positive (TP)** (ุงููููุฉ ุงููุณุงุฑ ูู ุงูุฃุนูู): ุชููุน ุงููููุฐุฌ ูุงู ุตุญูุญ ููุฑุณุงูุฉ ุจุชุญุฏูุฏูุง ููุฒุนุฌุฉ.
- **False Negative (FN)** (ุงููููุฉ ุงููููู ูู ุงูุฃุนูู): ุชููุน ุงููููุฐุฌ ูุงู ุฎุงุทุฆ ุจุชููุนูุง ูุฑุณุงูุฉ ุบูุฑ ูุฒุนุฌุฉุ ููููุง ูู ุงูููุชุฑุถ ุฃู ูุชู ุชุตููููุง ูุฑุณุงูุฉ ูุฒุนุฌุฉ. ูู ุญุงูุชูุงุ ุชููุน ุฎุงุทุฆ ูุนูู ุฃู ุฑุณุงูุฉ ูุฒุนุฌุฉ ุชู ุชุญุฏูุฏูุง ูุฑุณุงูุฉ ุบูุฑ ูุฒุนุฌุฉ ููุตูุช ุฅูู ุตูุฏูู ุจุฑูุฏูุง ุงูุฑุฆูุณู Inbox.

ุจููุณ ุงูุทุฑููุฉุ ุฅุฐุง ุชู ุฅุฏุฎุงู ุฑุณุงูุฉ ุจุฑูุฏ ุฃููุชุฑููู ุบูุฑ ูุฒุนุฌุฉ ุฅูู ุงููููุฐุฌุ ุณูููู ูุฏููุง ุงุญุชูุงูุงู:
- **False Positive (FP)** (ุงููููุฉ ุงููุณุงุฑ ูู ุงูุฃุณูู): ุชููุน ุงููููุฐุฌ ูุงู ุฎุงุทุฆ ุจุชุญุฏูุฏ ุงูุฑุณุงูุฉ ูุฑุณุงูุฉ ูุฒุนุฌุฉ ููู ุนูุณ ุฐูู ููููุง ูุตููุฉ ูุบูุฑ ูุฒุนุฌุฉ. ูู ุญุงูุชูุงุ ูุฐุง ุงูุชุตููู ูุนูู ุฃู ุงูุฑุณุงูุฉ ุณุชุตู ุฅูู ุงูุจุฑูุฏ ุงููุฒุนุฌ ูู ุจุฑูุฏูุง ุงูุฅููุชุฑููู ููู ุชุตู ููุจุฑูุฏ ุงูุฑุฆูุณู Inbox.
- **True Negative (TN)** (ุงููููุฉ ุงููููู ูู ุงูุฃุณูู): ุชููุน ุงููููุฐุฌ ูุงู ุตุญูุญ ููุฑุณุงูุฉ ุจุชุญุฏูุฏูุง ูุบูุฑ ูุฒุนุฌุฉ.

> ุณุจู ุฃู ุดุฑุญุช ูุฐุฉ ุงูููุงููู ูู ุชุฏูููุฉ ุนูู ุงูุฑุงุจุท ุงูุชุงูู: [ููุง](https://alioh.github.io/DSND-Notes-6/)ุ ูููู ุฅุฎุชุตุงุฑ ุงูุดุฑุญ ูู ุงูุฌุฏูู ุงูุชุงูู:
>
> <p align='center'>
> <img src='{{ site.baseurl }}/img/chapter17/confusion_matrix.png'>
> </p>
>
> ูุน ุงูุงุฎุฐ ุจุงูุฅุนุชุจุงุฑ ุฃู ุงูุดูู ุงูููุงุฆู ูุฏ ูุฎุชูู ููุชู ุนูุณ ุงูุฃุนูุฏุฉ Yes/No ูุซูุงู.

ุชูููุฉ ุงูุชููุน ุงูุฎุงุทุฆ False Positive ู False Negative ุชุนุชูุฏ ุนูู ูุง ูุนูู ุนููู. ูู ุชุตููู ุฑุณุงุฆู ุงูุจุฑูุฏ ุงูุฅููุชุฑูููุ ุงูุชุตููู ุงูุฎุงุทุฆ False Positive ูููู ุจุชุญุฏูุฏ ุฑุณุงุฆู ุจุฑูุฏ ุฅููุชุฑูููุฉ ูููุฉ ููุฒุนุฌุฉ ูุจุงูุชุงูู ูุชู ุชุฌุงูููุง ูุนุฏู ูุถุนูุง ูู ุงูุจุฑูุฏ ุงูุฑุฆูุณูุ ูุฐุง ูู ุฃุณูุฃ ูู False Negative ูุงูุฐู ููู ุชูุถุน ุงูุฑุณุงุฆู ุงููุฒุนุฌุฉ ูู ุงูุจุฑูุฏ ุงูุฑุฆูุณู. ูู ุงููุฌุงู ุงูุทุจู ูุซูุงูุ ุงูุชููุน ุงูุฎุงุทุฆ False Negative ูู ุชุดุฎูุต ุงุฎุชุจุงุฑ ูุง ูุฏ ูููู ุฃูุซุฑ ุฃูููุฉ ูู ุงูุชููุน ุงูุฎุงุทุฆ False Positive.

ุณูุณุชุฎุฏู ุฏุงูุฉ ูุตูููุฉ ุงูุฏูุฉ [Confusion Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) ูู ููุชุจุฉ `scikit-learn` ูุฅูุดุงุก ูุตูููุฉ ุงูุฏูุฉ ููููุงุฐุฌ ุงูุซูุงุซุฉ ุจุงุณุชุฎุฏุงู ุจูุงูุงุช ุงูุชุฏุฑูุจ. ูุชุงุฆุฌ ุงููููุฐุฌ `ham_only` ูุงูุชุงูู:

```python
from sklearn.metrics import confusion_matrix

class_names = ['Spam', 'Ham']

ham_only_cnf_matrix = confusion_matrix(y_train, ham_only_y_pred, labels=[1, 0])

plot_confusion_matrix(ham_only_cnf_matrix, classes=class_names,
                      title='ham_only Confusion Matrix')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_13_0.png'>
</p>


> ุงุณุชุฎุฏู ุงููุงุชุจ ุงูุฏุงูุฉ `plot_confusion_matrix` ูููุณุงุนุฏุฉ ุนูู ุงูุฑุณู ูุงููุชุบูุฑ `ham_only_y_pred` ูุชุญุฏูุฏ ุฌููุน ุงูููู ูุบูุฑ ูุฒุนุฌุฉ ูุนุฑูููุง ูุงูุชุงูู:
>
> ```python
>def plot_confusion_matrix(cm, classes,
>                          normalize=False,
>                          title='Confusion matrix',
>                          cmap=plt.cm.Blues):
>    """
>    ุชุฑุณู ูุฐู ุงูุฏุงูุฉ ูุตูููุฉ ุงูุฏูุฉ
>    ูููู ุชุจุณูุท ุงููุชุงุฆุฌ ุจุงุณุชุฎุฏุงู ุงููุชุบูุฑ `normalize=True`.
>    """
>    import itertools
>    if normalize:
>        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
>
>    plt.imshow(cm, interpolation='nearest', cmap=cmap)
>    plt.title(title)
>    plt.colorbar()
>    tick_marks = np.arange(len(classes))
>    plt.xticks(tick_marks, classes, rotation=45)
>    plt.yticks(tick_marks, classes)
>
>    fmt = '.2f' if normalize else 'd'
>    thresh = cm.max() / 2.
>    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
>        plt.text(j, i, format(cm[i, j], fmt),
>                 horizontalalignment="center",
>                 color="white" if cm[i, j] > thresh else "black")
>
>    plt.tight_layout()
>    plt.ylabel('True label')
>    plt.xlabel('Predicted label')
>    plt.grid(False)
>
>ham_only_y_pred = np.zeros(len(y_train))
>spam_only_y_pred = np.ones(len(y_train))
>words_list_model_y_pred = words_list_model.predict(X_train)
>```
>

ููุฌูุน ูู ุงูุฑุณู ุงูุจูุงูู ุงูุณุงุจู ูุฌููุน ุงููุชุงุฆุฌ ูู ุงูุตููู ูุจูุงูุงุช ุงูุชุฏุฑูุจ ููุฑู ุฅุฐุง ุชู ุชุตููููุง ูู ุงูุชุตููู ุงูุฐู ุชูุชูู ุฅููู: 
- True label = spam (ุงูุณุทุฑ ุงูุฃูู): ูุฌููุน ุงูุฑุณุงุฆู ุงูุชู ุชู ุชููุนูุง ููุฒุนุฌุฉ ููู ูุนูุงู ูุฒุนุฌุฉ True Positive (0)ุ ูุงููุชุงุฆุฌ ุงูุชู ุชู ุชููุนูุง ูุบูุฑ ูุฒุนุฌุฉ ููู ูู ุงูุญูููุฉ ูุฒุนุฌุฉ False Negative (42)ุ ูุธูุฑ ูุฐูู ุฃู ููุงู 42 ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ูุฒุนุฌุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ.
- True label = ham (ุงูุณุทุฑ ุงูุซุงูู): ูุฌููุน ุงูุฑุณุงุฆู ุงูุชู ุชููุนูุง ููุฒุนุฌุฉ ููู ูู ุงูุญูููุฉ ุบูุฑ ูุฒุนุฌุฉ False Positive (0)ุ ูููููุง ุชููุนุงุช ุงูุฑุณุงุฆู ุงูุชู ูุงูุช ุบูุฑ ูุฒุนุฌุฉ ููู ูุนูุงู ุบูุฑ ูุฒุนุฌุฉ True Negative (758)ุ ูุนูู ุฐูู ุฃู ููุงู 758 ุฑุณุงูุฉ ุจุฑูุฏ ุบูุฑ ูุฒุนุฌุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ.

ููุฌูุน ูู ุงูุฑุณู ุงูุจูุงูู ุงูุณุงุจู ูุฌููุน ุงููุชุงุฆุฌ ูู ุงูุฃุนูุฏุฉ ูุจูุงูุงุช ุงูุชุฏุฑูุจ ููุฑู ุฃุฏุงุก ุงููููุฐุฌ ูู ุชููุน ุชุตููููุง ุงูุฐู ุชูุชูู ุฅููู: 
- Predicted label = spam (ุงูุนููุฏ ุงูุฃูู): ูุฌููุน ุชููุนุงุช ุงูุฑุณุงุฆู ุงูุชู ุชู ุชููุนูุง ููุฒุนุฌุฉ ููู ูุนูุงู ูุฒุนุฌุฉ True Positive (0)ุ ูุฌููุน ุชููุนุงุช ุงูุฑุณุงุฆู ุงูุชู ุชููุนูุง ููุฒุนุฌุฉ ููู ูู ุงูุญูููุฉ ุบูุฑ ูุฒุนุฌุฉ False Positive (0) ูุธูุฑ ุฃู ุชููุนุงุช `ham_only` ุฃูู ูุง ููุฌุฏ ุฃู ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ูุฒุนุฌุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ.
- Predicted label = ham (ุงูุนููุฏ ุงูุซุงูู): ูุฌููุน ุงูุชููุนุงุช ุงูุชู ุชู ุชููุนูุง ูุบูุฑ ูุฒุนุฌุฉ ููู ูู ุงูุญูููุฉ ูุฒุนุฌุฉ False Negative (42)ุ ูุฌููุน ุชููุนุงุช ุงูุฑุณุงุฆู ุงูุชู ูุงูุช ุบูุฑ ูุฒุนุฌุฉ ููู ูุนูุงู ุบูุฑ ูุฒุนุฌุฉ True Negative (758) ูุธูุฑ ุฃู ุชููุนุงุช `ham_only` ุฃู ููุงู 800 ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ุบูุฑ ูุฒุนุฌุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ.

ูุฑู ุฃู ุงููููุฐุฌ `ham_only` ูุฏูุฉ ุฏูุฉ ุนุงููุฉ $ \left(\frac{758}{800} \approx .95\right) $ ูุฃู ููุงู 758 ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ุบูุฑ ูุฒุนุฌุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูู ุฃุตู 800.

```python
spam_only_cnf_matrix = confusion_matrix(y_train, spam_only_y_pred, labels=[1, 0])

plot_confusion_matrix(spam_only_cnf_matrix, classes=class_names,
                      title='spam_only Confusion Matrix')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_15_0.png'>
</p>

ูู ุงูุฌุงูุจ ุงูุขุฎุฑุ ุงููููุฐุฌ `spam_only` ูุงูุช ุชููุนุงุชู ุฃู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุง ุชุญุชูู ุนูู ุฃู ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ุบูุฑ ูุฒุนุฌุฉ `ham`ุ ูููุง ูู ูุงุถุญ ูู ูุตูููุฉ ุงูุฏูุฉ ุงููุชูุฌุฉ ุฃุจุนุฏ ูุง ุชููู ุนู ุงูุญูููุฉ ูุงูุชู ูููุง 758 ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ุบูุฑ ูุฒุนุฌุฉ.

ููููู ูุธุฑุฉ ุนูู ุงููููุฐุฌ ุงูุฐู ููููุง `words_list_model` ููุชูุฌุฉ ูุตูููุฉ ุงูุฏูุฉ:

```python
words_list_model_cnf_matrix = confusion_matrix(y_train, words_list_model_y_pred, labels=[1, 0])

plot_confusion_matrix(words_list_model_cnf_matrix, classes=class_names,
                      title='words_list_model Confusion Matrix')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_17_0.png'>
</p>

ูุฌููุน ุงูุตููู ูุทุงุจู ูุชูู ูู ุงููุชุงุฆุฌ ูู ูุตูููุงุช ุงูุฏูุฉ ููููุงุฐุฌ `ham_only` ู `spam_only` ููุง ูู ูุชููุน ูุฃู ุงููุชุงุฆุฌ ุงูุญููููุฉ ูููุฌููุน ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูู ุชุชุบูุฑ ูููุง ุชุบูุฑ ุงููููุฐุฌ.

ูู ุจูู ุงู 42 ุฑุณุงูุฉ ุจุฑูุฏ ูุฒุนุฌุ ุชููุน ุงููููุฐุฌ `words_list_model` ุจุดูู ุตุญูุญ 18 ุฑุณุงูุฉุ ููุฐุง ุฃุฏุงุก ุณูุฆ. ุฏูุชู ุงูุนุงููุฉ ูุงูุช ุจุณุจุจ ุงูุนุฏุฏ ุงููุจูุฑ ุงููุชููุน ูููุชุงุฆุฌ ุงูุตุญูุญุฉ ููุฑุณุงุฆู ุงูุบูุฑ ูุฒุนุฌุฉ True Negativeุ ูุนุชุจุฑ ุฐูู ุบูุฑ ูุงูู ูุฃูู ูุง ููู ุจุงูุบุฑุถ ูู ููุชุฑุฉ ุฑุณุงุฆู ุงูุจุฑูุฏ ุงููุฒุนุฌุฉ.

ุจูุงูุงุช ุฑุณุงุฆู ุงูุจุฑูุฏ ุงูุฅููุชุฑููู ูู ูุซุงู ุนูู **ุจูุงูุงุช ุฐุงุช ุชุตููู ุบูุฑ ุงููุชูุงุฒู Class-imbalanced dataset**ุ ูููุง ุงููุซูุฑ ูู ุงูุชุตูููุงุช ุชูุชูู ูุชุตููู ุฃูุซุฑ ูู ุงูุขุฎุฑ. ูู ุญุงูุฉ ุจูุงูุงุช ุงูุจุฑูุฏ ุงูุฅููุชุฑูููุ ูุฅู ุงููุซูุฑ ูู ุงูุฑุณุงุฆู ุชู ุชุตููููุง ูุบูุฑ ูุฒุนุฌุฉ. ูุซุงู ุขุฎุฑ ููุชุดุฑ ูู ูู ุจูุงูุงุช ุงูุชุดุงู ุงูุฃูุฑุงุถ ุนูุฏูุง ูููู ุงูุชุดุงุฑ ุงููุฑุถ ูู ุงููุฌุชูุน ุงูุฅุญุตุงุฆู ูููู. ูุณุจุฉ ุงูุญุตูู ุนูู ูุชูุฌุฉ ุฃู ุงููุฑูุถ ููุณ ูุฏูุฉ ุงููุฑุถ ุนูุฏ ุฅุฌุฑุงุก ุงููุญุต ุงูุทุจู ุฃุนูู ุณุจุจ ุฃู ุงููุซูุฑ ูู ุงููุฑุถู ููุณ ูุฏููู ุงููุฑุถุ ุนุฏู ูุฏุฑุชู ุนูู ูุดู ุงููุฑุถู ุจุฐูู ุงููุฑุถ ูุธูุฑ ุนุฏู ูุงุฆุฏุฉ ุงููููุฐุฌ. [๐][ImbalancedClassification]

ููุชูู ุงูุขู ุฅูู ุงูุญุณุงุณูุฉ ูุงูููุนูุฉุ ุทุฑู ููุงุณ ููุงุณุจุฉ ููุจูุงูุงุช ุฐุงุช ุงูุชุตููู ุบูุฑ ุงููุชูุงุฒู.
### ุงูุญุณุงุณูุฉ

ุชุณูู **ุงูุญุณุงุณูุฉ Sensitivity** ุฃูุถุงู ุจู **ูุนุฏู ุงูุชููุน ูุงููุชูุฌุฉ ุงูุฅูุฌุงุจูุงู True Positive Rate** ูููุณ ูุณุจุฉ ุงูุจูุงูุงุช ุงูุชู ุชูุชูู ุฅูู ุงูุชุตููู ุงูุฅูุฌุงุจู ูุชููุนูุง ุงููููุฐุฌ ุจุดูู ุตุญูุญ: [๐][SensitivitySpecificity]

 $$  \text{Sensitivity} = \frac{TP}{TP + FN}  $$ 

ูู ุญุฏูุซูุง ุงูุณุงุจู ุนู ูุตูููุงุช ุงูุฏูุฉุ ููุฌุจ ุนููู ุงูุขู ุฃู ุชููู ูุฏ ุชุนุฑูุช ุนูู ุงููุตุทูุญุงุช $TP + FN$ ููู ูุฌููุน ุงูููู ูู ุงูุตู ุงูุฃููุ ููู ุชุณุงูู ุงููุฌููุน ุงูุญูููู ููุจูุงูุงุช ุงูุชู ุชูุชูู ููุชุตููู ุงูุฅูุฌุงุจู Positive Class. ุงุณุชุฎุฏุงู ูุตูููุงุช ุงูุฏูุฉ ูุณูู ุนูููุง ููุงุฑูุฉ ุงูุญุณุงุณูุฉ ูู ุงูููุงุฐุฌ:

- `ham_only`: $ \frac{0}{0 + 42} = 0$
- `spam_only`: $ \frac{42}{42 + 0} = 1$
- `words_list_model`: $ \frac{18}{18 + 24} \approx .429$

ุจูุง ุฃู ุงููููุฐุฌ `ham_only` ูู ูููู ููู ุฃู ูููู ุตุญูุญุฉ ูู ุงูุนููุฏ True Positiveุ ูุญุตู ุนูู ุฃุณูุฃ ุงููุชุงุฆุฌ 0 ูู ุงูุญุณุงุณูุฉ. ุนูู ุงูุฌุงูุจ ุงูุขุฎุฑุ ุงููููุฐุฌ `spam_only` ูุงูุช ุงูุฏูุฉ ููู ููููุฉ ุฌุฏุงู ุฅูุง ุงูู ุญุณุจ ุนูู ุฃูุถู ุงููุชุงุฆุฌ ูู ุงูุญุณุงุณูุฉ 1 ูุฃูู ุชููุน ุฌููุน ุฑุณุงุฆู ุงูุจุฑูุฏ ุงููุฒุนุฌุฉ ุจุดูู ุตุญูุญ. ุงููุชูุฌุฉ ุงููุชุฏููุฉ ูููููุฐุฌ `words_list_model` ุชุนูู ุฃูู ุนุงุฏุฉ ูุง ููุดู ูู ุชููุน ุฑุณุงุฆู ุงูุจุฑูุฏ ุงูุฅููุชุฑููู ููุฒุนุฌุฉุ ูููู ุนูู ุงูุนูุณุ ุงููููุฐุฌ ุฃูุถู ุจูุซูุฑ ูู ุงููููุฐุฌ `ham_only`.

### ุงูููุนูุฉ

ุชุณูู **ุงูููุนูุฉ Specificity** ุฃูุถุงู ุจู **ูุนุฏู ุงูุชููุน ูุงููุชูุฌุฉ ุงูุณูุจูุงู True Negative Rate** ูููุณ ูุณุจุฉ ุงูุจูุงูุงุช ุงูุชู ุชูุชูู ุฅูู ุงูุชุตููู ุงูุณูุจู ูุชููุนูุง ุงููููุฐุฌ ุจุดูู ุตุญูุญ: [๐][SensitivitySpecificity]

 $$  \text{Specificity} = \frac{TN}{TN + FP}  $$  

ุงููุตุทูุญ $TN + FP$ ูุณุงูู ุงููุฌููุน ุงูุญูููู ููุจูุงูุงุช ุงูุชู ุชูุชูู ููุชุตููู ุงูุณูุจู Negative Class. ูุฑุฉ ุฃุฎุฑูุ ุงุณุชุฎุฏุงู ูุตูููุงุช ุงูุฏูุฉ ูุณูู ุนูููุง ููุงุฑูุฉ ุงูููุนูุฉ ูู ุงูููุงุฐุฌ:

- `ham_only`: $ \frac{758}{758 + 0} = 1$
- `spam_only`: $ \frac{0}{0 + 758} = 0$
- `words_list_model`: $ \frac{752}{752 + 6} \approx .992$

ููุง ูู ุงูุญุณุงุณูุฉุ ุงููุชุงุฆุฌ ูู 0 ุฅูู 1 ูู ุงูุฃุณูุฃ ุฅูู ุงูุฃูุถู. ูุงุญุธ ุฃู `ham_only` ุญุตู ุนูู ุฃูุถู ุงููุชุงุฆุฌ ูู ุงูููุนูุฉ ู ุฃุณูุฃ ุงููุชุงุฆุฌ ูู ุงูุญุณุงุณูุฉุ ุจูููุง `spam_only` ุญุตู ุนูู ุฃุณูุฃ ุงููุชุงุฆุฌ ูู ุงูููุนูุฉ ูุงูุฃูุถู ูู ุงูุญุณุงุณูุฉ. ุจูุง ุฃู ูุฐู ุงูููุงุฐุฌ ุชุชููุน ูุชูุฌุฉ ูุงุญุฏุฉ ููุทุ ูุฃููุง ุชุตูู ุฌููุน ุงูููู ูู ุงูุชุตููู ุงูุขุฎุฑ ุจุดูู ุฎุงุทุฆุ ูุธูุฑ ุฐูู ูู ุงูููู ุงูุนุงููุฉ ููููุนูุฉ ูุงูุญุณุงุณูุฉ. ุงููุฑู ูู ุงููุชุงุฆุฌ ูู ุงููููุฐุฌ `words_list_model` ุฃูู.

ุนูู ุงูุฑุบู ุฃู ุงูุญุณุงุณูุฉ ูุงูุชุตููู ุชุนุฑููุง ุนูู ุฎุตุงุฆุต ูุฎุชููุฉ ูู ุงููููุฐุฌุ ูุญุชุงุฌ ุฃู ูุฑุจุท ุชูู ุงููุชุงุฆุฌ ูู ุฃุฏุงุชุง ุงูุชูููู ูุน ุจุนุถูุง ุงูุจุนุถ ุจุงุณุชุฎุฏุงู ุญุฏ ูุตู ุงูุชุตููู
### ุญุฏ ูุตู ุงูุชุตููู

ูููุฉ **ุญุฏ ูุตู ุงูุชุตููู Classification Threshold** ุชุญุฏุฏ ุฅู ุชุตููู ุชูุชูู ุฅููู ูููุฉ ูุงุ ุงูููู ุนูู ุงูุฌุงูุจูู ุงููุฎุชูููู ูู ุญุฏ ุงููุตู ูุชู ูุฎุชูู ุชุตููููุง ุนู ุจุนุถูุง. ููุชุฐูุฑ ุฃู ุงููุชุงุฆุฌ ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ุนุจุงุฑุฉ ุนู ุงุญุชูุงููุงุช ุฅุฐุง ูุงูุช ุงูููุทุฉ ุชูุชูู ุฅูู ุงูุชุตููู ุงูุฅูุฌุงุจู. ุฅุฐุง ูุงูุช ุงูุงุญุชูุงููุฉ ุฃูุจุฑ ูู ุญุฏ ุงููุตูุ ูุฃููุง ุชูุชูู ุฅูู ุงูุชุตููู ุงูุฅูุฌุงุจูุ ุฅุฐุง ูุงูุช ุฃูู ูู ุญุฏ ุงููุตูุ ูุฃููุง ุชูุชูู ุฅูู ุงูุชุตููู ุงูุณูุจู. ูู ูุซุงููุงุ ููุฌุนู $f_{\hat{\theta}} $ ูููุฐุฌูุง ุงูููุฌุณุชู ู $ C $ ูู ุญุฏ ุงููุตู. ุฅุฐุง ูุงูุช $f_{\hat{\theta}}(x) > C$ุ ูุฅู $x$ ุชุตูู ุฑุณุงูุฉ ุจุฑูุฏ ูุฒุนุฌุ ุฅุฐุง ูุงูุช $f_{\hat{\theta}}(x) < C$ุ ูุฅู $ x $ ุชุตูู ูุฑุณุงูุฉ ุบูุฑ ูุฒุนุฌุฉ. ุชูุตู ููุชุจุฉ `scikit-learn` ุนูุฏ ุชุนุงุฏู ุงููุชูุฌุฉ ูุน ุญุฏ ุงููุตู ููุชุตููู ุงูุณูุจูุ ุฅุฐุงู ุนูุฏูุง ุชููู $f_{\hat{\theta}}(x) = C$ุ ูุฅู $ x $ ูุชู ุชุตููููุง ูุฑุณุงูุฉ ุบูุฑ ูุฒุนุฌุฉ. [๐][ClassificationThreshold]

ูููููุง ุชูููู ุฃุฏุงุก ุงููููุฐุฌ ูุน ุญุฏ ุงููุตู $ C $ ุจุงุณุชุฎุฏุงู ูุตูููุฉ ุงูุฏูุฉ. ูุตูููุฉ ุงูุฏูุฉ ูููููุฐุฌ `words_list_model` ุงูุชู ุณุจู ุฃู ุนุฑุถูุงูุง ุชุณุชุฎุฏู ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ ูุญุฏ ุงููุตู ูู ููุชุจุฉ `scikit learn` ููู $C = .50$. 

ุงูุฑูุน ูู ุญุฏ ุงููุตู ุฅูู $C = .70$ุ ูุนูู ุฃููุง ูุตูู ุฑุณุงูุฉ ุงูุจุฑูุฏ ุงูุฅููุชุฑููู $ x $ ููุฒุนุฌุฉ ุนูุฏูุง ุชููู ุงูุงุญุชูุงููุฉ $f_{\hat{\theta}}(x)$ ุฃุนูู ูู $ .70 $ุ ุงููุชุงุฆุฌ ููุตูููุฉ ุงูุฏูุฉ ุนูุฏูุง ูููู ุญุฏ ุงููุตู $.70 $ ูุงูุชุงูู:

```python

# ุฅูุฌุงุฏ ุงุญุชูุงููุงุช ุงูุชููุน
words_list_prediction_probabilities = words_list_model.predict_proba(X_train)[:, 1]

# ุนูุฏูุง ุชููู ุงูุงุญุชูุงููุฉ ุฃูุจุฑ ูู .70 ูุญุฏุฏ ุฑุณุงูุฉ ุงูุจุฑูุฏ ูุฑุณุงูุฉ ูุฒุนุฌุฉุ ูุงูุนูุณ ุบูุฑ ุฐูู
words_list_predictions = [1 if pred >= .70 else 0 for pred in words_list_prediction_probabilities]

# ุฅูุดุงุก ูุตูููุฉ ุงูุฏูุฉ
high_classification_threshold = confusion_matrix(y_train, words_list_predictions, labels=[1, 0])

# ุฑุณู ูุตูููุฉ ุงูุฏูุฉ
plot_confusion_matrix(high_classification_threshold, classes=class_names,
                      title='words_list_model Confusion Matrix $C = .70$')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_22_0.png'>
</p>

ุนูุฏ ุฑูุน ุญุฏ ุงููุตู ูุชุญุฏูุฏ ูุง ุฅุฐุง ูุงูุช ุฑุณุงูุฉ ุงูุจุฑูุฏ ุงูุฅููุชุฑููู ูุฒุนุฌุฉ ุฃู ูุงุ ููุฌุฏ 13 ุฑุณุงูุฉ ุจุฑูุฏ ูุฒุนุฌุฉ ุชู ุชุญุฏูุฏูุง ุจุดูู ุตุญูุญ ุนูุฏูุง ูุงูุช $C = 0.50$ ูุงูุขู ูู ูุตููุฉ ุจุดูู ุฎุทุฃ:

 $$  \text{Sensitivity } (C = .70) = \frac{5}{42} \approx .119 \\
\text{Specificity } (C = .70) = \frac{757}{758} \approx .999
 $$ 

ุนูุฏ ุงูููุงุฑูุฉ ุจุงููููุฉ ุงูุงูุชุฑุงุถูุฉุ ูููุฉ ุญุฏ ูุตู ุฃุนูู ุนูุฏ $C = .70$ ุชุฒูุฏ ูู ุงูููุนูุฉ ูุชููู ูู ุงูุญุณุงุณูุฉ.

ุงูุชูููู ูู ุญุฏ ุงููุตู ุฅูู $C = .30$ุ ูุนูู ุฃู ุฃู ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู $ x $ ุชุตูู ููุฒุนุฌุฉ ุนูุฏูุง ุชููู ุงูุงุญุชูุงููุฉ $f_{\hat{\theta}}(x)$ ุฃูุจุฑ ูู $ .30 $ุ ูุชูุฌุฉ ูุตูููุฉ ุงูุฏูุฉ ูุงูุชุงูู:

```python
# ุนูุฏูุง ุชููู ุงูุงุญุชูุงููุฉ ุฃูุจุฑ ูู .30 ูุญุฏุฏ ุฑุณุงูุฉ ุงูุจุฑูุฏ ูุฑุณุงูุฉ ูุฒุนุฌุฉุ ูุงูุนูุณ ุบูุฑ ุฐูู
words_list_predictions = [1 if pred >= .30 else 0 for pred in words_list_prediction_probabilities]

# ุฅูุดุงุก ูุตูููุฉ ุงูุฏูุฉ
low_classification_threshold = confusion_matrix(y_train, words_list_predictions, labels=[1, 0])

# ุฑุณู ูุตูููุฉ ุงูุฏูุฉ
plot_confusion_matrix(low_classification_threshold, classes=class_names,
                      title='words_list_model Confusion Matrix $C = .30$')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_24_0.png'>
</p>

ุนูุฏ ุงูุชูููู ูู ุญุฏ ุงููุตู ูุฑุณุงุฆู ุงูุจุฑูุฏ ุงูุฅููุชุฑููู ุงููุฒุนุฌุฉุ ุชู ุชุตููู 6 ุฑุณุงุฆู ุจุฑูุฏ ุฅููุชุฑููู ูุฒุนุฌุฉ ูุงูุช ูุตููุฉ ุจุดูู ุฎุงุทุฆ ุนูุฏูุง ูุงูุช $C = .50$ ููู ุงูุขู ูุตููุฉ ุจุดูู ุตุญูุญ. ููููุ ููุงู ุนุฏุฏ ุฃูุจุฑ ูู ุงูููู ุงูุณูุจูุฉ ูู ุงูุญูููุฉ ูุชู ุชููุนูุง ุฅูุฌุงุจูุงู False Positive:

 $$  \begin{split} \text{Sensitivity } (C = .30) = \frac{24}{42} \approx .571 \\
\text{Specificity } (C = .30) = \frac{738}{758} \approx .974
\end{split}
 $$ 

ุจุงูููุงุฑูุฉ ูุน ุงููููุฉ ุงูุงูุชุฑุงุถูุฉุ ุญุฏ ูุตู ุฃูู ุนูุฏ $C = .30$ ุฒุงุฏ ูู ุงูุญุณุงุณูุฉ ูููู ูู ุงูููุนูุฉ.

ูููู ุจุงูุชุนุฏูู ูู ูุชุงุฆุฌ ุงูุญุณุงุณูุฉ ูุงูููุนูุฉ ูููููุฐุฌ ุนู ุทุฑูู ุชุนุฏูู ุญุฏ ุงููุตู. ุนูู ุงูุฑุบู ุฃููุง ูุฑุบุจ ูู ุงูุญุตูู ุนูู ุฃูุถู ุงููุชุงุฆุฌ ูู ุงูุญุณุงุณูุฉ ูุงูููุนูุฉุ ูููู ุฃู ูุฑู ูู ูุตูููุงุช ุงูุฏูุฉ ุจุญุฏูุฏ ูุตู ูุฎุชููุฉ ุฃู ููุงู ููุงูุถุฉ ุชุญุฏุซ. ุงูุฒูุงุฏุฉ ูู ุงูุญุณุงุณูุฉ ุชุคุฏู ุฅูู ุงูููุต ูู ุงูููุนูุฉ ูุงูุนูุณ.

### ููุญููุงุช ROC

ูููููุง ุญุณุงุจ ุงูุญุณุงุณูุฉ ูุงูููุนูุฉ ุฃูููุง ูุงูุช ูููุฉ ุญุฏ ุงููุตู ุจูู 0 ู 1 ูุฑุณููุง. ูู ูููุฉ ูุญุฏ ุงููุตู $ C $ ูุฑุชุจุทุฉ ุจุงูุญุณุงุณูุฉ ูุงูููุนูุฉ ูุนูุง. **ููุญูู ุฎุตุงุฆุต ุชุดุบูู ุงูููุณุชููุจูู ROC (Receiver Operating Characteristic) Curve** ูุฎุชูู ุจุนุถ ุงูุดูุกุ ุจุฏูุงู ูู ุฑุณู ุงูููุทุฉ (ุงูุญุณุงุณูุฉ ุุงูููุนูุฉ)ุ ูุฑุณู (ุงูุญุณุงุณูุฉุ 1-ุงูููุนูุฉ)ุ ููููุง 1-ุงูููุนูุฉ ูุนุฑูุฉ ุจูุนุฏู ุงูููู ุงูุณูุจูุฉ ุงูุชู ุชู ุชููุนูุง ุฅูุฌุงุจูุงู False Positive: [๐][ROCAUC]

 $$  \text{False Positive Rate } = 1 - \frac{TN}{TN + FP} = \frac{TN + FP - TN}{TN + FP} = \frac{FP}{TN + FP}  $$ 

ููุทุฉ ูู ููุญูู ROC ุชูุซู ุงูุญุณุงุณูุฉ ููุนุฏู ุงูููู ุงูุณูุจูุฉ ุงูุชู ุชู ุชููุนูุง ุฅูุฌุงุจูุงู False Positive ุงููุฑุชุจุทุฉ ุจูููุฉ ุญุฏ ุงููุตู.

ููุญูู ROC ููููุฐุฌ `words_list_model` ูููู ุญุณุงุจูุง ุจุงุณุชุฎุฏุงู ุฏุงูุฉ [ููุญูู ROC](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) ูู ููุชุจุฉ `scikit-learn`:

```python
from sklearn.metrics import roc_curve

words_list_model_probabilities = words_list_model.predict_proba(X_train)[:, 1]
false_positive_rate_values, sensitivity_values, thresholds = roc_curve(y_train, words_list_model_probabilities, pos_label=1)

plt.step(false_positive_rate_values, sensitivity_values, color='b', alpha=0.2,
         where='post')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('Sensitivity')
plt.title('words_list_model ROC Curve')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_28_1.png'>
</p>

ูุงุญุธ ุฃููุง ููููุง ุงูุชูููุง ูู ุงููุณุงุฑ ุฅูู ุงููููู ุนุจุฑ ุงูููุญููุ ุชุฒูุฏ ุงูุญุณุงุณูุฉ ูุชูู ุงูููุนูุฉ. ุจุดูู ุนุงูุ ุฃูุถู ุญุฏ ูููุตู ุชุชูุงุนู ุนูุฏูุง ุชุชููู ุงูุญุณุงุณูุฉ ูุงูููุนูุฉ ุนุงููุฉ (ูููุฉ ุฃูู ููุนุฏู ุงูููู ุงูุณูุจูุฉ ุงูุชู ุชู ุชููุนูุง ุฅูุฌุงุจูุงู False Positive)ุ ูุฐุง ุงูููุงุท ูู ุงูุฃุนูู ูุณุงุฑุงู ูู ุงูููุงุท ุงููุซุงููุฉ.

ูููุธุฑ ุจุดูู ุฃูุจุฑ ููุฒูุงูุง ุงูุฃุฑุจุนุฉ ูู ุงูุฑุณู ุงูุจูุงูู ุงูุณุงุจู:
- (0, 0): ุงูููุนูุฉ $ 1 = $ุ ูุนูู ุฃู ุฌููุน ุงูุจูุงูุงุช ูู ุงูุชุตููู ุงูุณูุจู ุชู ุชุตููููุง ุจุดูู ุตุญูุญุ ูููู ุงูุญุณุงุณูุฉ $ 0 = $ุ ุฅุฐุงู ุงููููุฐุฌ ูุง ูุญุชูู ุนูู ููู ุฅูุฌุงุจูุฉ ูุชู ุชููุนูุง ุฅูุฌุงุจูุงู True Positive. ุญุฏ ุงููุตู ุนูุฏ ุงูููุทุฉ (0, 0) ููู $ C = 1.0 $ุ ููู ูุทุงุจู ููุชุงุฆุฌ ุงููููุฐุฌ `ham_only` ุจูุง ุฃูู ูุง ูููู ูุฃู ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ุฃู ุชุญุตู ุนูู ุงุญุชูุงููุฉ ุฃุนูู ูู $ 1.0 $.
- (1, 1): ุงูููุนูุฉ $ 0 = $ุ ูุนูู ุฃู ุงููููุฐุฌ ูุง ูุญุชูู ุชููุนุงุช ุณูุจูุฉ ูุชู ุชููุนูุง ุณูุจูุงู True Negativeุ ูููู ุงูุญุณุงุณูุฉ $ 1 = $ุ ูุนูู ุฃู ุฌููุน ุงูุจูุงูุงุช ูู ุงูุชุตููู ุงูุฅูุฌุงุจู ุชู ุชุตููููุง ุจุดูู ุตุญูุญ. ุงููุตู ุนูุฏ ุงูููุทุฉ (1, 1) ููู $ C = 0.0 $ุ ููู ูุทุงุจู ููุชุงุฆุฌ ุงููููุฐุฌ `spam_only` ุจูุง ุฃูู ูุง ูููู ูุฃู ุฑุณุงูุฉ ุจุฑูุฏ ุฅููุชุฑููู ุฃู ุชุญุตู ุนูู ุงุญุชูุงููุฉ ุฃุนูู ูู $ 0.0 $.
- (0, 1): ููุงููุง ุงูููุนูุฉ ูุงูุญุณุงุณูุฉ $ 1 = $ุ ูุนูู ุนุฏู ูุฌูุฏ ุชููุนุงุช ุฅูุฌุงุจูุฉ ููุชุงุฆุฌ ุณูุจูุฉ False Positive ุฃู ุชููุนุงุช ุณูุจูุฉ ููุชุงุฆุฌ ุฅูุฌุงุจูุฉ False Negative. ูููุฐุฌ ุฐู ููุญูู ROC ูุณุงูู (0, 1) ูุฏูุฉ ูููุฉ ูุซุงููุฉ ูุญุฏ ูุตู $ C $ ูููููุฐุฌ.
- (1, 0): ููุงููุง ุงูููุนูุฉ ูุงูุญุณุงุณูุฉ $ 0 = $ุ ูุนูู ุนุฏู ูุฌูุฏ ุชููุนุงุช ุฅูุฌุงุจูุฉ ููุชุงุฆุฌ ุฅูุฌุงุจูุฉ True Positive ุฃู ุชููุนุงุช ุณูุจูุฉ ููุชุงุฆุฌ ุณูุจูุฉ True Negative. ูููุฐุฌ ุฐู ููุญูู ROC ูุณุงูู (1, 0) ูุฏูุฉ ูููุฉ ูุญุฏ ูุตู $ C $ ูุชููุน ุฏุงุฆููุง ูุชุงุฆุฌ ุฎุงุทุฆุฉ ูุฌููุน ุงูุจูุงูุงุช.

ุงููููุฐุฌ ุงูุฐู ูุชููุน ุงูุชุตููู ุจุดูู ุนุดูุงุฆู ูููู ููู ุงูููุญูู ROC ุฎุท ูุณุชููู ูุงุฆู ุชููู ููู ุงูููุงุท ูููุง ุงูุญุณุงุณูุฉ ููุนุฏู ุงูููู ุงูุณูุจูุฉ ุงูุชู ุชู ุชููุนูุง ุฅูุฌุงุจูุงู False Positive ูุชุณุงููุฉ:

```python
plt.step(np.arange(0, 1, 0.001), np.arange(0, 1, 0.001), color='b', alpha=0.2,
         where='post')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('Sensitivity')
plt.title('Random Classifier ROC Curve')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_30_1.png'>
</p>

ุงููููุฐุฌ ุงูุนุดูุงุฆู ุงูุฐู ูุชููุน ุงูุงุญุชูุงููุฉ $ p $ ููููุฉ ููุฏุฎูุฉ $ x $ ุณูุชููุน ุชููุนุงุช ุฅูุฌุงุจูุฉ ููุชุงุฆุฌ ุฅูุฌุงุจูุฉ True Positive ุฃู ุชููุนุงุช ุฅูุฌุงุจูุฉ ููุชุงุฆุฌ ุณูุจูุฉ False Positive ูู $ p $ุ ูุฐุง ุงูุญุณุงุณูุฉ ู ููุนุฏู ุงูุชููุนุงุช ุงูุฅูุฌุงุจูุฉ ูุงููุชุงุฆุฌ ุงูุณูุจูุฉ False Positive ูุชุณุงููุงู.

ูุฑูุฏ ุฃู ูููู ููุญูู ROC ูู ุงููููุฐุฌ ุฃุนูู ูู ุฎุท ุงููููุฐุฌ ุงูุนุดูุงุฆูุ ููุตู ุงูุขู ูููููู AUC. 

### AUC

**ุงููุณุงุญุฉ ุฃุณูู ุงูููุญูู Area Under Curve (AUC)** ูู ุงููุณุงุญุฉ ุฃุณูู ููุญูู ROC ูุชุนูู ูุฃุฏุงุฉ ูุชูุฎูุต ุฃุฏุงุก ุงููููุฐุฌ. ุงููุณุงุญุฉ ุฃุณู ุงูููุญูู ูููููุฐุฌ `words_list_model` ุชู ุฑุณููุง ูู ุงูุฃุณูู ููููู ุญุณุงุจูุง ุจุงุณุชุฎุฏุงู ุฏุงูุฉ [AUC](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) ูู ููุชุจุฉ `scikit-learn`: [๐][ROCAUC]

```python
plt.fill_between(false_positive_rate_values, sensitivity_values, step='post', alpha=0.2,
                 color='b')

plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('Sensitivity')
plt.title('words_list_model ROC Curve')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_sensitivity_specificity_33_1.png'>
</p>

```python
from sklearn.metrics import roc_auc_score

roc_auc_score(y_train, words_list_model_probabilities)
```

```ruby
0.9057984671441136
```

ูููู ุชูุณูุฑ AUC ุนูู ุฃููุง ุงุญุชูุงููุฉ ุฃู ูููู ุงููููุฐุฌ ุจุชุนููู ูููุฉ ุนุงููุฉ ููุงุญุชูุงููุฉ ูููุทุฉ ูุฎุชุงุฑุฉ ุจุดูู ุนุดูุงุฆู ุชูุชูู ููุชุตููู ุงูุฅูุฌุงุจู ูู ููุทุฉ ูุฎุชุงุฑุฉ ุจุดูู ุนุดูุงุฆู ุชูุชูู ููุชุตููู ุงูุณูุจู. ุงููููุฉ ุงููุซุงููุฉ ูู AUC ูู 1 ูููู ูููุง ุงููููุฐุฌ ูุซุงูู (ููุญูู ROC ุณูููู (0, 1)). ุญุตูู ุงููููุฐุฌ `words_list_model` ุนูู ูุณุงุญุฉ ุฃุณูู ุงูููุญูู AUC ุชุณุงูู 0.906 ูุนูู ุฃู ุงููููุฐุฌ ูู ุงููุญุชูู ุฃู ูุชููุน ุงูุฑุณุงุฆู ุงููุฒุนุฌุฉ ููุฒุนุฌุฉ ุจูุณุจุฉ 90.6% ุฃูุซุฑ ูู ุชููุนู ุงูุฑุณุงุฆู ุงูุณูููุฉ ููุฒุนุฌุฉ.

ุนูุฏ ุงูุชุญูู ูู ุฐููุ ุงููุณุงุญุฉ ุฃุณูู ุงูููุญูู AUC ูููููุฐุฌ ุงูุนุดูุงุฆู ุชุณุงูู 0.5ุ ุนูู ุงูุฑุบู ุฃู ุฐูู ุฃูุถุงู ูุงุจู ููุชุบูุฑ ุจุดูู ูููู ุจูุงุกูุง ุนูู ุงูุนุดูุงุฆูุฉ. ุงููููุฐุฌ ุงููุนุงู ูุงููููุฏ ุชููู ููู AUC ุฃุนูู ุจูุซูุฑ ูู 0.5ุ ูุงูุชู ุญูููุง ุงููููุฐุฌ `words_list_model`. ุฅุฐุง ูุงูุช ุงููุณุงุญุฉ ุฃุณูู ุงูููุญูู ุฃูู ูู 0.5ุ ูุฅู ุงููููุฐุฌ ุฃุฏุงุกู ุฃุณูุฃ ูู ุฃุฏุงุก ุงูุชููุนุงุช ุงูุนุดูุงุฆูุฉ.

### ููุฎุต ุชูููู ุงููููุฐุฌ ุงูููุฌุณุชู

ุงููุณุงุญุฉ ุฃุณูู ุงูููุญูู AUC ูู ุฃุฏุงุฉ ูุชููู ุงูููุงุฐุฌ ูู ุงูุจูุงูุงุช ุฐุงุช ุงูุชุตููู ุงูุบูุฑ ูุชูุงุฒู. ุจุนุฏ ุชุฏุฑูุจ ุงููููุฐุฌุ ูู ุงูููุงุฑุณุงุช ุงูููุชุงุฒุฉ ูู ุฅูุฌุงุฏ ููุญูู ROC ูุญุณุงุจ AUC ูุชุญุฏูุฏ ุงูุฎุทูุฉ ุงูุชุงููุฉ. ุฅุฐุง ูุงู AUC ุนุงููุ ูุณุชุฎุฏู ููุญูู ROC ูุชุญุฏูุฏ ุฃูุถู ูููุฉ ูุญุฏ ุงููุตู. ููููุ ุฅุฐุง ูุงูุช ูููุฉ AUC ุบูุฑ ูุฑุถูุฉุ ููู ุงูุฃูุถู ุงูููุงู ุจุงููุฒูุฏ ูู ุงูุชุญููู ุงูุงุณุชูุดุงูู ููุจูุงูุงุช ู ุฅุฎุชูุงุฑ ููู ุฃูุถู ููุฎุตุงุฆุต ููุชุญุณูู ูู ุฃุฏุงุก ุงููููุฐุฌ.

## ุงูุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช

ุญุชู ุงูุขู ูููู ุงููููุฐุฌ ุจุชุตููู ุซูุงุฆู ูููุง ุงููุชุงุฆุฌ ูุงุญุฏ ูู ูุชูุฌุชููุ ูุซูุงูุ ุตูููุง ุงูุฑุณุงุฆู ููุฒุนุฌุฉ ุฃู ุบูุฑ ูุฒุนุฌุฉ. ููููุ ุงููุซูุฑ ูู ูุดุงูู ูู ุนูู ุงูุจูุงูุงุช ุชุญุชูู ุนูู **ุชุตูููุงุช ููุชุนุฏุฏุฉ ุงูุชุตูููุงุช Multiclass Classification**ุ ููู ูุฑูุฏ ุฃู ูุตูู ูุชุงุฆุฌ ุงูุจุฑูุฏ ุงูุฅููุชุฑููู ุฅูู ูุงุญุฏ ูู ุนุฏุฉ ุชุตูููุงุช. ูุซูุงูุ ุชุญุฏูุฏ ุฑุณุงุฆู ุงูุจุฑูุฏ ูุง ุฅุฐุง ูุงูุช ุนุงุฆููุฉุ ูู ุงูุฃุตุฏูุงุกุ ุฎุงุต ุจุงูุนูู ุฃู ุงูุฅุนูุงูุงุช ูุงูุนุฑูุถ. ูุญู ูุฐุง ุงูููุน ูู ุงููุดุงููุ ูุณุชุฎุฏู ุทุฑููุฉ ุฌุฏูุฏุฉ ูุทูู ุนูููุง **ุชุตููู ูุงุญุฏ-ุถุฏ-ุงูุจููุฉ One-vs-Rest (OvR) classification**. [๐][MulticlassMultilabel]

### ุชุตููู ูุงุญุฏ-ุถุฏ-ุงูุจููุฉ

ูู ูุฐุง ุงูููุน ูู ุงูุชุตููู (ูุทูู ุนููู ุฃูุถุงู ูุงุญุฏ-ุถุฏ-ุงูุฌููุน One-vs-All ุฃู OvA)ุ ูููู ุจุชูุณูู ูุดููุฉ ุงูุชุตููู ุงููุชุนุฏุฏ ุงูุชุตูููุงุช ุฅูู ูุดููุฉ ูู ุนุฏุฉ ุชุตูููุงุช ุซูุงุฆูุฉ ุงููุชุงุฆุฌ. ูุซูุงูุ ูููู ุฃู ุชุธูุฑ ููุง ูุชุงุฆุฌ ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุงูุชุงูู:

```python
shapes = pd.DataFrame(
    [[1.3, 3.6, 'triangle'], [1.6, 3.2, 'triangle'], [1.8, 3.8, 'triangle'],
     [2.0, 1.2, 'square'], [2.2, 1.9, 'square'], [2.6, 1.4, 'square'],
     [3.2, 2.9, 'circle'], [3.5, 2.2, 'circle'], [3.9, 2.5, 'circle']],
    columns=['$x_1$', '$x_2$', '$y$']
)

sns.lmplot('$x_1$', '$x_2$', data=shapes, hue='$y$', markers=['^', 's', 'o'], fit_reg=False)
plt.xlim(1.0, 4.0)
plt.ylim(1.0, 4.0);
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_6_0.png'>
</p>

ูุฏููุง ูู ุฑุณู ูููุฐุฌ ูุชุนุฏุฏ ุงูุชุตููู ูููู ุจุชููุน ุงููุชุงุฆุฌ ูู ุซูุงุซ `triange`ุ `square` ุฃู `circle` ุนูุฏ ุชูุฑูุฑ ุงูููู $x_1$ ู $x_2$ ุฅููู. ุฃููุงู ูููู ุจุจูุงุก ูููุฐุฌ ุซูุงุฆู ุจุฃุณู `lr_triangle` ูููู ุจุชููุน ุงููุชุงุฆุฌ ูุง ุฅุฐุง ูุงูุช ููุซูุซุงุช `triangle` ุฃู ูุง:

```python
plot_binary(shapes, 'triangle')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_8_0.png'>
</p>

> ุฅุณุชุนุงู ุงููุงุชุจ ุจุฏุงูุฉ ุนุฑููุง ุจุฃุณู `plot_binary` ููุณุงุนุฏุชู ุนูู ุฅุธูุงุฑ ุงููุชุงุฆุฌ ูู ุฑุณู ุจูุงููุ ูุนุฑููุง ูุงูุชุงูู:
>
> ```python
> 
> markers = {'triangle':['^', sns.color_palette()[0]], 
>            'square':['s', sns.color_palette()[1]],
>            'circle':['o', sns.color_palette()[2]]}
> 
> def plot_binary(data, label):
>     data_copy = data.copy()
>     data_copy['$y$ == ' + label] = (data_copy['$y$'] == label).astype('category')
>     
>     sns.lmplot('$x_1$', '$x_2$', data=data_copy, hue='$y$ == ' + label, hue_order=[True, False], 
>                markers=[markers[label][0], 'x'], palette=[markers[label][1], 'gray'],
>                fit_reg=False)
>     plt.xlim(1.0, 4.0)
>     plt.ylim(1.0, 4.0);
> ```
>

ุจููุณ ุงูุทุฑููุฉุ ูููู ุจุจูุงุก ูููุฐุฌ `lr_square` ู `lr_circle` ููุชุตูููุงุช ุงูุฃุฎุฑู:

```python
plot_binary(shapes, 'square')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_10_0.png'>
</p>

```python
plot_binary(shapes, 'circle')
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_11_0.png'>
</p>

ูุนูู ุฃู ุงููุชุงุฆุฌ ูู ุงูุฏุงูุฉ ุงูุณูููุฉ ูู ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู ูู ุนุจุงุฑุฉ ุนู ุงุญุชูุงููุฉ ูููุฉ ุจูู 0 ู 1. ูุญู ุงูุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช ูุฏููุงุ ูุจุญุซ ุนู ุงุญุชูุงููุฉ ุงูุฌุงูุจ ุงูุฅูุฌุงุจู ูู ูู ูููุฐุฌ ููุฎุชุงุฑ ุงูุชุตููู ุงูุฃุนูู ุฅูุฌุงุจูุฉ. ูุซูุงูุ ูู ุฅุฐุง ุฅุทูุนูุง ุนูู ุงูููู ุงูุชุงููุฉ:

$x_2$ | $x_1$
---   | ---
2.5   | 3.2

ุณูููู ุงููููุฐุฌ ุจุฅุฏุฎุงู ูุฐู ุงูููู ุฅูู ูู ุงูููุงุฐุฌ ุงูุณุงุจูุฉ `lr_triangle`ุ `lr_square`ุ ู `lr_circle`. ูููู ุจุฅูุฌุงุฏ ุงููููุฉ ุงูุงุญุชูุงููุฉ ุงูุฅูุฌุงุจูุฉ ููู ูู ุงูููุงุฐุฌ ุงูุซูุงุซุฉ:

```python
from sklearn.linear_model import LogisticRegression

lr_triangle = LogisticRegression(random_state=42)
lr_triangle.fit(shapes[['$x_1$', '$x_2$']], shapes['$y$'] == 'triangle')
proba_triangle = lr_triangle.predict_proba([[3.2, 2.5]])[0][1]

lr_square = LogisticRegression(random_state=42)
lr_square.fit(shapes[['$x_1$', '$x_2$']], shapes['$y$'] == 'square')
proba_square = lr_square.predict_proba([[3.2, 2.5]])[0][1]

lr_circle = LogisticRegression(random_state=42)
lr_circle.fit(shapes[['$x_1$', '$x_2$']], shapes['$y$'] == 'circle')
proba_circle = lr_circle.predict_proba([[3.2, 2.5]])[0][1]
```

`lr_circle` | `lr_square`   | `lr_triangle`
---           | ---           | ---
0.497612      |      0.285079 | 0.145748

ุจูุง ุฃู ุงูุงุญุชูุงููุฉ ุงูุฅูุฌุงุจูุฉ ุงูุฃุนูู ูู ูุฏู `lr_circle`ุ ูุฅู ุงููููุฐุฌ ูุชุนุฏุฏ ุงูุชุตูููุงุช ุณูุชููุน ุฃู ุงููููุฉ ุงูุชู ุงุทูุน ุนูููุง ุชูุชูู ุฅูู ุงูุชุตููู `circle`.

### ุชุทุจูู ุนููู: ุจูุงูุงุช Iris

ุชุนุชุจุฑ [ุจูุงูุงุช Iris](https://archive.ics.uci.edu/ml/datasets/iris) ุฅุญุฏู ุฃุดูุฑ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูู ุนูู ุงูุจูุงูุงุช ูุชุนูู ููุงููู ุชุนูู ุงูุขูุฉ. ููุงู ุซูุงุซ ุชุตูููุงุชุ ูู ูุงุญุฏุฉ ุชูุซู ุฃุญุฏ ุฃููุงุน ุฃุฒูุงุฑ ุงูุณูุณู Iris:
- Iris-setosa
- Iris-versicolor
- Iris-virginica

ููุงู ุฃุฑุจุน ุฎุตุงุฆุต ูุชููุฑุฉ ูู ุงูุจูุงูุงุช:
- Sepal length (cm) ุทูู ูุฃุณ ุงูุฒูุฑุฉ (ุจุงูุณูุชููุชุฑ).
- Sepal width (cm) ุนุฑุถ ูุฃุณ ุงูุฒูุฑุฉ (ุจุงูุณูุชููุชุฑ).
- Petal length (cm) ุทูู ุจุชูุฉ ุงูุฒูุฑุฉ (ุจุงูุณูุชููุชุฑ).
- Petal width (cm) ุนุฑุถ ุจุชูุฉ ุงูุฒูุฑุฉ (ุณูุชููุชุฑ).

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_petal_sepal.png'>
</p>

ุณูููู ุจุฅูุดุงุก ูููุฐุฌ ูุชุนุฏุฏ ุงูุชุตูููุงุช ูููู ุจุชููุน ููุน ุงูุฒูุฑุฉ ุจูุงุกูุง ุนูู ุงูุฎุตุงุฆุต ุงูุฃุฑุจุนุฉ. ุฃููุงูุ ูููู ุจูุฑุงุกุฉ ุงูุจูุงูุงุช:

```python
iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',
                  header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])

iris
```

**species**|**petal\_width**|**petal\_length**|**sepal\_width**|**sepal\_length**| 
:-----:|:-----:|:-----:|:-----:|:-----:|:-----:
Iris-setosa|0.2|1.4|3.5|5.1|0
Iris-setosa|0.2|1.4|3|4.9|1
Iris-setosa|0.2|1.3|3.2|4.7|2
...|...|...|...|...|...
Iris-virginica|2|5.2|3|6.5|147
Iris-virginica|2.3|5.4|3.4|6.2|148
Iris-virginica|1.8|5.1|3|5.9|149

```ruby
150 rows ร 5 columns
```

```python
X, y = iris.drop('species', axis=1), iris['species']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)
```

ุจุนุฏ ุชูุณูู ุงูุจูุงูุงุช ุฅูู ุจูุงูุงุช ุชุฏุฑูุจ ู ุงุฎุชุจุงุฑุ ูููู ุจุถุจุท ุงููููุฐุฌ ูุชุนุฏุฏ ุงูุชุตูููุงุช ุนูู ุจูุงูุงุช ุงูุชุฏุฑูุจ. ุจุดูู ุชููุงุฆูุ ูููู ูููุฐุฌ ุงูุงูุญุฏุงุฑ ุงูููุฌุณุชู [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) ูู ููุชุจุฉ `scikit-learn` ุจุชุญุฏูุฏ ูููุฉ ุงููุชุบูุฑ `multi_class='ovr'`ุ ูุงูุชู ุชููู ุจุฅูุดุงุก ูููุฐุฌ ุซูุงุฆู ููู ุชุตููู ูุฎุชูู:

```python
lr = LogisticRegression(random_state=42)
lr.fit(X_train, y_train)
```

```ruby
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
```

ูููู ุจุงูุชููุน ุจุงุณุชุฎุฏุงู ุจูุงูุงุช ุงูุงุฎุชุจุงุฑุ ุซู ูุณุชุฎุฏู ูุตูููุฉ ุงูุฏูุฉ ูุชูููู ุงููุชุงุฆุฌ:

```python
y_pred = lr.predict(X_test)
plot_confusion_matrix(y_test, y_pred)
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_21_0.png'>
</p>

> ุฅุณุชุฎุฏู ุงููุงุชุจ ุงูุฏุงูุฉ `plot_confusion_matrix` ูุงูุชู ุนุฑููุง ููุณุงุนุฏุชู ูุนุฑุถ ูุชูููู ุงููุชุงุฆุฌ ุนูู ุดูู ูุตูููุฉ ุงูุฏูุฉ:
>
> ```python
> def plot_confusion_matrix(y_test, y_pred):
>    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cbar=False, cmap=matplotlib.cm.get_cmap('gist_yarg'))
>    plt.ylabel('Observed')
>    plt.xlabel('Predicted')
>    plt.xticks([0.5, 1.5, 2.5], ['iris-setosa', 'iris-versicolor', 'iris-virginica'])
>    plt.yticks([0.5, 1.5, 2.5], ['iris-setosa', 'iris-versicolor', 'iris-virginica'], rotation='horizontal')
>    ax = plt.gca()
>    ax.xaxis.set_ticks_position('top')
>    ax.xaxis.set_label_position('top')
> ```

ูุธูุฑ ูู ูุตูููุฉ ุงูุฏูุฉ ุงูุณุงุจูุฉ ุฃู ุงููููุฐุฌ ุฃุฎุทุฃ ูู ุงูุชููุน ูุฑุชูู ููุชุตููู `Iris-versicolor` ูุชููุนูุง ูุชุตููู `Iris-virginica`. ุนูุฏ ุงูุชุญูู ูู ุงูุฎุตุงุฆุต `sepal_length` ู `sepal_width`ุ ูุณุชุทูุน ุฃู ูุฑู ุณุจุจ ุญุฏูุซ ุฐูู:

```python
sns.lmplot(x='sepal_length', y='sepal_width', data=iris, hue='species', fit_reg=False);
```

<p align='center'>
<img src='{{ site.baseurl }}/img/chapter17/classification_multiclass_23_0.png'>
</p>

ุชุชุฏุงุฎู ุงููุซูุฑ ูู ุงูููุงุท ูู ููุชุตูููุงุช `Iris-versicolor` ู `Iris-virginica`. ุนูู ุงูุฑุบู ุฃู ุงูุฎุตุงุฆุต ุงูุฃุฎุฑู (`petal_width` ู `petal_length`) ุชูุฏู ูุนูููุงุช ุฃูุซุฑ ููุชูุฑูู ุจูู ุงูุชุตูููุงูุ ุฅูุง ุฃู ุงููููุฐุฌ ุฃุฎุทุฃ ูู ุชุตููู ููุนูู ูู ุงูุฒููุฑ.

ููุง ูู ุงูุนุงูู ุงูุญููููุ ุชุญุฏุซ ุงูุชุตูููุงุช ุงูุฎุทุฃ ุนูุฏูุง ูููู ุชุตูููุงู ูุชุดุงุจูุงู ูู ุงูุฎุตุงุฆุต. ูุตูููุงุช ุงูุฏูุฉ ูููุฏุฉ ููููุง ุชุทูุนูุง ุนูู ุงูุฃุฎุทุงุก ุงูุชู ููุน ูููุง ุงููููุฐุฌุ ุฃูุถุงู ุชูุฏู ููุง ุฃููุงุฑ ุนู ุฃู ููุน ูู ุงูุฎุตุงุฆุต ูุญุชุงุฌ ุฃู ููุฌุฏูุง ูู ุฃุฌู ุชุญุณูู ุฃุฏุงุก ุงููููุฐุฌ.

### ุงูุชุตููู ูุชุนุฏุฏ ุงููุชุงุฆุฌ

ููุน ุขุฎุฑ ูู ูุดุงูู ุงูุชุตููู ูู **ุงูุชุตููู ูุชุนุฏุฏ ุงููุชุงุฆุฌ Multilabel Classification**ุ ูููู ูููู ูููุชูุฌุฉ ุฃูุซุฑ ูู ุชุตููู. ูุซุงู ูุฐูู ูู ูุธุงู ูุชุตููู ุงููููุงุช: ุงูููู ูุฏ ูููู ุฐู ุฅูุฌุงุจู ุฃู ุณูุจูุ ุฐู ูุญุชูู ุฏููู ุฃู ุบูุฑ ุฏูููุ ู ูุชูุชุญ ุฃู ูุญุงูุธ. ูุดููุฉ ูุชุนุฏุฏุฉ ุงููุชุงุฆุฌ ูุฏ ุชููู ุฃูุถุงู ูุชุนุฏุฏุฉ ุงูุชุตูููุงุชุ ูุฏ ูุฑุบุจ ุฃู ูููู ูุธุงู ุงูุชุตููู ูููููุงุช ูุฏููุง ููุฑู ุจูู ูุงุฆูุฉ ูู ุงูุฃููุงุนุ ุฃู ูุญุฏุฏ ุงููุบุฉ ุงูุชู ููุชุจ ูููุง ุงูููู. [๐][MulticlassMultilabel]

ูููู ุฃู ูุทุจู ุงูุชุตููู ูุชุนุฏุฏ ุงููุชุงุฆุฌ ุจุจุณุงุทุฉ ุนุจุฑ ุชุฏุฑูุจ ููุงุฐุฌ ูููุตูุฉ ููู ููุน ูู ุงููุชุงุฆุฌ. ูุชุตููู ููุทุฉ ูุงุ ูููู ุจุฌูุน ุฌููุน ูุชุงุฆุฌ ุชููุนุงุช ุงูููุงุฐุฌ.

### ููุฎุต ุงูุชุตููู ูุชุนุฏุฏ ุงูุงุญุชูุงูุงุช

ูุดุงูู ุงูุชุตููู ูุฏ ุชููู ุตุนุจุฉ. ูู ุจุนุถ ุงูุฃุญูุงูุ ูุญุชุงุฌ ูู ุงููุดููุฉ ููุชูุฑูู ุจูู ุฃูุซุฑ ูู ุชุตูููุ ููู ุจุนุถ ุงูุฃุญูุงู ูุฏ ูุฑูุฏ ุชุนูู ุฃูุซุฑ ูู ูุชูุฌุฉ ููู ูููุฉ ูุทูุน ุนูููุง ุงููููุฐุฌ. ูุณุชุนูู ุจูุง ูุนุฑูู ุนู ุงูููุงุฐุฌ ุซูุงุฆูุฉ ุงููุชุงุฆุฌ ูุจูุงุก ุฃูุธูุฉ ุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช ูุงููุชุงุฆุฌ ูุงูุชู ูุงุฏุฑุฉ ุนูู ุฃุฏุงุก ุชูู ุงูููุงู.


[LogisticRegression]: https://www.youtube.com/watch?v=yIYKR4sgzI8
[Sigmoid]: https://www.youtube.com/watch?v=WcDtwxi7Ick
[ChainRule]: https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction
[ImbalancedClassification]: https://machinelearningmastery.com/what-is-imbalanced-classification/
[ROCAUC]: https://www.youtube.com/watch?v=OAl6eAyP-yo
[SensitivitySpecificity]: https://intellipaat.com/blog/confusion-matrix-python/
[CrossEntropyLoss]: https://machinelearningmastery.com/cross-entropy-for-machine-learning/
[KLdivergence]: https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8
[ClassificationThreshold]: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/
[MiniBatchGradientDescent]: https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/
[StochasticGradientDescent]: https://www.youtube.com/watch?v=hMLUgM6kTp8
[MulticlassMultilabel]: https://stats.stackexchange.com/questions/11859/what-is-the-difference-between-multiclass-and-multilabel-problem

